[
["ejemplo-asia.html", "Sección 5 Ejemplo Asia", " Sección 5 Ejemplo Asia library(bnlearn) library(pander) pander(head(asia)) A S T L B E X D no yes no no yes no no yes no yes no no no no no no no no yes no no yes yes yes no no no no yes no no yes no no no no no no no yes no yes no no no no no yes El Conjunto de datos Asia contiene las siguientes variables: D (disnea), un factor con dos niveles yes and no. T (tuberculosis), un factor con dos niveles yes and no. L (cancer pulmonar), un factor con dos niveles yes and no. B (bronquitis), un factor con dos niveles yes and no. A (visita a Asia), un factor con dos niveles yes and no. S (fumador), un factor con dos niveles yes and no. X (rayos-X del Catastro toraxico), un factor con dos niveles yes and no. E (tuberculosis contra cancer de pulmón/bronquitis), un factor con dos niveles yes and no. Para referencia posterior, la “verdadera” estructura de la red se muestra en seguida Red Asia And for later reference, the ‘true’ network structure is shown below: Asia Data Set Structure "],
["preparacion-de-la-red.html", "5.1 Preparación de la red", " 5.1 Preparación de la red Antes de trabajar con el conjunnto de datos Asia mostraremos un ejemplo de como crear una estructura de red sencilla desde cero. Podríamos empezar por crear bien una red vacía (sin arcos) o una red aleatoria (arcos que unen aleatoriamente los nodos), pero no haremos nada de eso (en el sitio de blearn se puede encontrar como hacerlo). Lo que haremos es crear una estructura de red particular, según nuestro antojo. Esto puede ser el caso cuando se tiene suficiente confianza en conocer la “verdader” estructura de la red. #create an empty DAG with nodes dag= empty.graph(LETTERS[c(1,19,20,12,2,5,24,4)]) #assign the DAG structure, from to asia.structure = matrix(c(&quot;A&quot;, &quot;S&quot;, &quot;S&quot;, &quot;T&quot;, &quot;T&quot;,&quot;L&quot;, &quot;L&quot;,&quot;B&quot;, &quot;B&quot;, &quot;E&quot;,&quot;E&quot;, &quot;X&quot;,&quot;X&quot;,&quot;D&quot;), ncol = 2, byrow = TRUE, dimnames = list(NULL, c(&quot;from&quot;, &quot;to&quot;))) pander(asia.structure) from to A S S T T L L B B E E X X D #now asign the structure to the empty graph using arcs, which makes it a bnlearn object arcs(dag) &lt;- asia.structure dag ## ## Random/Generated Bayesian network ## ## model: ## [A][S|A][T|S][L|T][B|L][E|B][X|E][D|X] ## nodes: 8 ## arcs: 7 ## undirected arcs: 0 ## directed arcs: 7 ## average markov blanket size: 1.75 ## average neighbourhood size: 1.75 ## average branching factor: 0.88 ## ## generation algorithm: Empty plot(dag) Si optamos por usar arcos no dirigidos entonces podemos hacer esto. dag2 = empty.graph(LETTERS[c(1,19,20,12)]) asia.structure2 = matrix(c(&quot;A&quot;, &quot;S&quot;, &quot;S&quot;, &quot;A&quot;, &quot;T&quot;,&quot;L&quot;, &quot;L&quot;, &quot;T&quot;), ncol = 2, byrow = TRUE, dimnames = list(NULL, c(&quot;from&quot;, &quot;to&quot;))) arcs(dag2) = asia.structure2 plot(dag2) Cuando ejecutamos estos comandos, automáticamente se realizan una serie de verificaciones para evitar faltas a los requerimientos en la estructuración de la red. Las fallas detectadas se reportarán mediante mensajees de error. La principal verificación de faltas es contra la falta de nodos, la presencia de ciclos y circuitos. Este otro ejemplo muestra una estructura de red derivada de “opinión experta”, a la que añadimos estimadores justo en las distribuciones de probabilidad condicional conjunta del nodo. Expert1 = matrix(c(0.4, 0.6), ncol = 2, dimnames = list(NULL, c(&quot;BAJO&quot;, &quot;ALTO&quot;))) dag ## ## Random/Generated Bayesian network ## ## model: ## [A][S|A][T|S][L|T][B|L][E|B][X|E][D|X] ## nodes: 8 ## arcs: 7 ## undirected arcs: 0 ## directed arcs: 7 ## average markov blanket size: 1.75 ## average neighbourhood size: 1.75 ## average branching factor: 0.88 ## ## generation algorithm: Empty Expert1 ## BAJO ALTO ## [1,] 0.4 0.6 Expert2 = c(0.5, 0.5, 0.4, 0.6, 0.3, 0.7, 0.2, 0.8) dim(Expert2) = c(2, 2, 2) dimnames(Expert2) = list(&quot;C&quot; = c(&quot;CIERTO&quot;, &quot;FALSO&quot;), &quot;A&quot; = c(&quot;BAJO&quot;, &quot;ALTO&quot;), &quot;B&quot; = c(&quot;BUENO&quot;, &quot;MALO&quot;)) Expert2 ## , , B = BUENO ## ## A ## C BAJO ALTO ## CIERTO 0.5 0.4 ## FALSO 0.5 0.6 ## ## , , B = MALO ## ## A ## C BAJO ALTO ## CIERTO 0.3 0.2 ## FALSO 0.7 0.8 "],
["aprendizaje-de-la-estructura-de-la-red.html", "5.2 Aprendizaje de la estructura de la red", " 5.2 Aprendizaje de la estructura de la red Además de poder crear la estructura de un red manualmente, también es posible crearla a partir de los datos mediante algoritmos de aprendizaje de la estructura. Hay tres tipos principalees de algoritmos de aprendizaje de la estructura de una red: basados en restricciones, basados en puntajes e híbridos (alguna mezcla de los dos anteirores). E usuario puede especifica un criterio de valoración AIC (Akaike Information Criterion), BIC (Bayesian Information Criterion) o BDE (Bayesian Dirichlet) para la determinación de la mejor estructura de la red. Los algoritmos usan diferentes técnicas para iterar en torno a las varias estructuras posibles de una red y entonces elige la mejor, dependiendo de la calificación que produzca. El método de calificación usado por defecto con los algorítmmos basados en puntajes o los bpibridos es el BIC. Basado en restricciones No se utiliza ninguna estructura de modelo de arranque/inicio con estos algoritmos. Los algoritmos construyen la estructura buscando dependencias condicionales entre las variables. bnlearn incluye los siguientes algoritmos basados en restricciones: Grow-Shrink (GS) Asociación Incremental Markov Blanket (IAMB) Asociación Incremental Rápida (Fast-IAMB) Asociación Incremental Interleaved (Inter-IAMB) Max-Min Parents &amp; Children (MMPC) Hiton-PC semi-intercalada (SI-HITON-PC) Basado en la puntuación: El usuario aprovecha su conocimiento del sistema para crear una red, codifica su confianza en la red e ingresa los datos. El algoritmo luego estima la estructura del modelo más probable. bnlearn incluye los siguientes algoritmos basados en puntuación: Escalada de Colina (HC) Tabu Search (Tabu) Híbrido: Mezcla de métodos basados en restricciones y basados en puntajes. bnlearn incluye los siguientes algoritmos híbridos: Max-Min Hill Climbing (MMHC) Maximización restringida general de 2 fases (RSMAX2) Primero, un ejemplo del aprendizaje basado en contraint que utiliza el algoritmo de la Manta de Markov de la Asociación Incremental (IAMB): iambex &lt;- iamb(asia) #structure learning iambex ## ## Bayesian network learned via Constraint-based methods ## ## model: ## [A][S][T][L][X][D][B|S:D][E|T:L] ## nodes: 8 ## arcs: 4 ## undirected arcs: 0 ## directed arcs: 4 ## average markov blanket size: 1.50 ## average neighbourhood size: 1.00 ## average branching factor: 0.50 ## ## learning algorithm: IAMB ## conditional independence test: Mutual Information (disc.) ## alpha threshold: 0.05 ## tests used in the learning procedure: 180 ## optimized: FALSE plot(iambex) Ahora, un ejemplo de aprendizaje basado en la puntuación usando el algoritmo de escalada simple (HC): hcex &lt;- hc(asia) hcex ## ## Bayesian network learned via Score-based methods ## ## model: ## [A][S][T][L|S][B|S][E|T:L][X|E][D|B:E] ## nodes: 8 ## arcs: 7 ## undirected arcs: 0 ## directed arcs: 7 ## average markov blanket size: 2.25 ## average neighbourhood size: 1.75 ## average branching factor: 0.88 ## ## learning algorithm: Hill-Climbing ## score: BIC (disc.) ## penalization coefficient: 4.258597 ## tests used in the learning procedure: 77 ## optimized: TRUE mmex &lt;- mmhc(asia) mmex ## ## Bayesian network learned via Hybrid methods ## ## model: ## [A][S][T][X][L|S][B|S][E|T:L][D|B] ## nodes: 8 ## arcs: 5 ## undirected arcs: 0 ## directed arcs: 5 ## average markov blanket size: 1.50 ## average neighbourhood size: 1.25 ## average branching factor: 0.62 ## ## learning algorithm: Max-Min Hill-Climbing ## constraint-based method: Max-Min Parent Children ## conditional independence test: Mutual Information (disc.) ## score-based method: Hill-Climbing ## score: BIC (disc.) ## alpha threshold: 0.05 ## penalization coefficient: 4.258597 ## tests used in the learning procedure: 264 ## optimized: TRUE plot(mmex) ### Redes por puntajes A continuación se muestran ejemplos de las puntuaciones de AIC y BDE para la mejor red en el algoritmo de escalada simple (HC), aplicando el algorítmmo de aprendizaje basado en la puntuación que se muestra más arriba. score(hcex,asia,type=&quot;aic&quot;) #getting aic value for full network ## [1] -11051.9 score(hcex,asia,type=&quot;bde&quot;) #getting bde value for full network ## [1] -11095.79 Los resultados del algoritmo anterior también proporcionan un buen ejemplo de lo que sucede cuando la “mejor” estructura de red, no contiene arcos para todos los nodos. La red del algoritmo basado en puntuaciones es la más cercana a la red “verdadera”, pero el nodo A no está conectado a la red. Podemos investigar por qué este es el caso con el nodo A. Por ejemplo, del modelo verdadero sabemos que el nodo A influye en el nodo T. Calculemos la puntuación de A a T, y luego de T a A. #setting arcs to get actual scores from individual relationships eq.net = set.arc(hcex, &quot;A&quot;, &quot;T&quot;) #setting arcs to get actual scores from individual relationships eq.net1 = set.arc(hcex,&quot;T&quot;, &quot;A&quot;) puntaje_net = score(eq.net, asia, type=&quot;aic&quot;) #retriving score puntaje_net1 = score(eq.net1, asia, type=&quot;aic&quot;) #retriving score plot(eq.net) plot(eq.net1) Con estos comandos obtenemos el puntaje que está sociado con relaciones particulares: Red puntaje “net” -11051.09 “net1” -11051.09 Vemos que cuando establecemos el arco de A a T, o de T a A, obtenemos la misma puntuación de red (-11051.09). Por lo tanto, la relación entre A y T se denomina “puntuación equivalente”, ya que cualquier dirección proporciona la misma puntuación de red equivalente. Cambiar la dirección del vínculo entre dos nodos no cambia la puntuación de red. Por otro lado, si cambiamos la dirección de la flecha entre otros dos nodos que incluyen otras interconexiones en la red, veremos el cambio de la puntuación de la red. Por ejemplo, si cambiamos la relación entre los nodos L y E: eq.net = set.arc(hcex, &quot;L&quot;, &quot;E&quot;) eq.net1 = set.arc(hcex,&quot;E&quot;, &quot;L&quot;) score(eq.net, asia, type=&quot;aic&quot;) ## [1] -11051.9 plot(eq.net) plot(eq.net1) puntaje_net = score(eq.net1,asia, type=&quot;aic&quot;) puntaje_net1 = score(eq.net1,asia, type=&quot;aic&quot;) El resultado de este cambio es el siguiente: Red puntaje “net” -11271.589 “net1” -11271.589 Vemos que la puntuación de la red disminuye cuando invertamos la dirección entre los nodos L y E. En este punto, dado que los algoritmos no han podido determinar la relación de A a T (u otros nodos), es posible que queramos recurrir a la literatura, la opinión “experta”, la teoría de la ecología, etc. para argumentar la mejor relación entre el nodo A y el nodo T o el resto de la estructura. "],
["aprendizaje-de-parametros-o-estructuracion-de-la-red.html", "5.3 “Aprendizaje de parámetros” o “estructuración de la red”", " 5.3 “Aprendizaje de parámetros” o “estructuración de la red” El comando bn.fit genera estimaciones de parámetros para las tablas de probabilidad condicionales en cada nodo. Sin embargo, el comando bn.fit requiere que la estructura de red represente un DAG (gráfico acíclico dirigido), “de lo contrario no se pueden estimar sus parámetros porque la factorización de la distribución de probabilidad global de los datos en los locales (uno para cada variable en el modelo) no se conoce completamente”. Por lo tanto, los arcos no dirigidos deben establecerse antes de la estimación de parámetros. Vemos en la estructura anterior estimada que el nodo “A” no está conectado a la estructura de red. Por lo tanto, antes de aplicar bn.fit, debemos establecer un arco direccional para A. debido a la opinión “experta”, el conocimiento del sistema, o estudios previos, vamos a establecer un arco entre A y T. El método predeterminado para la estimación de parámetros es el de máxima verosimilitud (MLE). #creating a new DAG with the A to T relationship(based on our previous knowledge that goint to asia effects having tuberculosis) hcex1 = set.arc(hcex, from = &quot;A&quot;, to = &quot;T&quot;) plot(hcex1) Ahora podemos ejecutar el comando bn.fit para obtener los estimadores de los parámetros: # fitting the network with conditoinal probability tables fit = bn.fit(hcex1, asia) fit ## ## Bayesian network parameters ## ## Parameters of node A (multinomial distribution) ## ## Conditional probability table: ## no yes ## 0.9916 0.0084 ## ## Parameters of node S (multinomial distribution) ## ## Conditional probability table: ## no yes ## 0.497 0.503 ## ## Parameters of node T (multinomial distribution) ## ## Conditional probability table: ## ## A ## T no yes ## no 0.991528842 0.952380952 ## yes 0.008471158 0.047619048 ## ## Parameters of node L (multinomial distribution) ## ## Conditional probability table: ## ## S ## L no yes ## no 0.98631791 0.88230616 ## yes 0.01368209 0.11769384 ## ## Parameters of node B (multinomial distribution) ## ## Conditional probability table: ## ## S ## B no yes ## no 0.7006036 0.2823062 ## yes 0.2993964 0.7176938 ## ## Parameters of node E (multinomial distribution) ## ## Conditional probability table: ## ## , , L = no ## ## T ## E no yes ## no 1 0 ## yes 0 1 ## ## , , L = yes ## ## T ## E no yes ## no 0 0 ## yes 1 1 ## ## ## Parameters of node X (multinomial distribution) ## ## Conditional probability table: ## ## E ## X no yes ## no 0.956587473 0.005405405 ## yes 0.043412527 0.994594595 ## ## Parameters of node D (multinomial distribution) ## ## Conditional probability table: ## ## , , E = no ## ## B ## D no yes ## no 0.90017286 0.21373057 ## yes 0.09982714 0.78626943 ## ## , , E = yes ## ## B ## D no yes ## no 0.27737226 0.14592275 ## yes 0.72262774 0.85407725 Podemos recuperar la probabilidad condicional de un nodo específico mediante el operador usual “$”: fit$L ## ## Parameters of node L (multinomial distribution) ## ## Conditional probability table: ## ## S ## L no yes ## no 0.98631791 0.88230616 ## yes 0.01368209 0.11769384 fit$D ## ## Parameters of node D (multinomial distribution) ## ## Conditional probability table: ## ## , , E = no ## ## B ## D no yes ## no 0.90017286 0.21373057 ## yes 0.09982714 0.78626943 ## ## , , E = yes ## ## B ## D no yes ## no 0.27737226 0.14592275 ## yes 0.72262774 0.85407725 Si lo queremos, podemos también visualizar la tabla de probabilidad condicional mmediante gráficas de barras: bn.fit.barchart(fit$D) ## Loading required namespace: lattice o, si lo preferimos, como una gráfica de puntos: bn.fit.dotplot(fit$D) In addition to maximum likelihood, parameter estimation can be done performed with Bayesian methods - but currently only with discrete data. Below is an example with the Asia dataset. The same bn.fit command line is used, but the method is specified as ‘bayes’. fit1 = bn.fit(hcex1, asia, method = &quot;bayes&quot;) fit1 ## ## Bayesian network parameters ## ## Parameters of node A (multinomial distribution) ## ## Conditional probability table: ## no yes ## 0.9915017 0.0084983 ## ## Parameters of node S (multinomial distribution) ## ## Conditional probability table: ## no yes ## 0.4970006 0.5029994 ## ## Parameters of node T (multinomial distribution) ## ## Conditional probability table: ## ## A ## T no yes ## no 0.991479278 0.947058824 ## yes 0.008520722 0.052941176 ## ## Parameters of node L (multinomial distribution) ## ## Conditional probability table: ## ## S ## L no yes ## no 0.98622008 0.88223017 ## yes 0.01377992 0.11776983 ## ## Parameters of node B (multinomial distribution) ## ## Conditional probability table: ## ## S ## B no yes ## no 0.7005633 0.2823494 ## yes 0.2994367 0.7176506 ## ## Parameters of node E (multinomial distribution) ## ## Conditional probability table: ## ## , , L = no ## ## T ## E no yes ## no 9.999730e-01 3.105590e-03 ## yes 2.699638e-05 9.968944e-01 ## ## , , L = yes ## ## T ## E no yes ## no 3.831418e-04 2.941176e-02 ## yes 9.996169e-01 9.705882e-01 ## ## ## Parameters of node X (multinomial distribution) ## ## Conditional probability table: ## ## E ## X no yes ## no 0.956538171 0.006072874 ## yes 0.043461829 0.993927126 ## ## Parameters of node D (multinomial distribution) ## ## Conditional probability table: ## ## , , E = no ## ## B ## D no yes ## no 0.90012963 0.21376147 ## yes 0.09987037 0.78623853 ## ## , , E = yes ## ## B ## D no yes ## no 0.27777778 0.14630225 ## yes 0.72222222 0.85369775 "],
["validacion-del-modelo.html", "5.4 Validación del modelo", " 5.4 Validación del modelo Ahora que tenemos una estructura de red y tablas de probabilidad condicional en los nodos, el siguiente paso es validar el modelo o, más bien, evaluar el modelo ajustado a los datos. “La validación cruzada es una forma estándar de obtener estimaciones imparciales de la bondad de ajuste de un modelo. Comparando tales medidas para diferentes estrategias de aprendizaje (diferentes combinaciones de algoritmos de aprendizaje, técnicas de adaptación y los parámetros respectivos) podemos elegir la óptima para los datos que tenemos en mano de una manera basada en principios de objetividad”. bnlearn tiene 3 métodos para validación cruzada: k-fold(default), custom, and hold out. Para el ejercicio coparemos las primeras dos: k-fold and custom. Este es el ejemplo del método k-fold Los datos se “particionan” (separan), en k subconjuntos del mmismo tamaño cada uno. Cada subconjunto es usado por turnos para validar el modelo que ha sido entrenado con los restante k-1 subconjuntos. A lower expected loss value is better. Here we will cross-validate two learning algorithms - Max-Min Hill-Climb (mmhc) and Hill-Climb (hc). And the BDE scoring method will be used, which requires an iss (‘imaginery sample size’ used for bde scores) term. bn.cv(asia, bn = &quot;mmhc&quot;, algorithm.args = list()) ## ## k-fold cross-validation for Bayesian networks ## ## target learning algorithm: Max-Min Hill-Climbing ## number of folds: 10 ## loss function: Log-Likelihood Loss (disc.) ## expected loss: 2.42354 bn.cv(asia, bn = &quot;hc&quot;, algorithm.args = list(score = &quot;bde&quot;, iss = 1)) ## ## k-fold cross-validation for Bayesian networks ## ## target learning algorithm: Hill-Climbing ## number of folds: 10 ## loss function: Log-Likelihood Loss (disc.) ## expected loss: 2.209674 Podemos especifica el número de repeticiones, lo usual es hacer 10. cv_mmhc = bn.cv(asia, bn = &quot;hc&quot;, runs = 10, algorithm.args = list(score = &quot;bde&quot;, iss = 1)) ## Warning in entropy.loss(fitted = fitted, data = data, debug = debug): 2 ## observations were dropped because the corresponding probabilities for node ## X were 0 or NaN. cv_hc = bn.cv(asia, bn = &quot;mmhc&quot;, runs = 10, algorithm.args = list()) cv_mmhc ## ## k-fold cross-validation for Bayesian networks ## ## target learning algorithm: Hill-Climbing ## number of folds: 10 ## loss function: Log-Likelihood Loss (disc.) ## number of runs: 10 ## average loss over the runs: 2.209862 ## standard deviation of the loss: 0.0007095383 cv_hc ## ## k-fold cross-validation for Bayesian networks ## ## target learning algorithm: Max-Min Hill-Climbing ## number of folds: 10 ## loss function: Log-Likelihood Loss (disc.) ## number of runs: 10 ## average loss over the runs: 2.423637 ## standard deviation of the loss: 0.0002911196 De esta manera, los resultados de la validación cruzada, sugieren que el algoritmo basado en “escalada simple” (Hill-Climb) produce una estructura del modelo/red que ajusta bastante bien a los datos, a juzgar por el valor de error total al predecir (loss): Algoritmo error (loss) mmhc 2.209862 hc 2.423637 "],
["inferencia.html", "5.5 Inferencia", " 5.5 Inferencia Ahora que tenemos la estructura y las estimmaciones de los parámetros de la red podemos hacer inferencias con ella. Una ventaja de las redes bayesianas es que la inferencia puede hacerse en cualquier dirección (omnidireccional), de principio hacia el final o del final hacia el principio o de en medio hacia alguno de los extremos. Cada uan de esas modalidades se puede reconocer como una forma distinta de “razonamiento”. Veamos un par de ejeplos: Inicio a final: de Asia rayos-X: consulta_red = cpquery(fit1, event = (X==&quot;yes&quot;), evidence = ( A==&quot;yes&quot;)) la probabilidad de que tu catastro toraxico sea positivo cuando has estado en Asia es alrededor de 7.32%. Ahora el caso contrario: rayos-X Xray implicación respecto de Asia: consulta_red = cpquery(fit1, event = (A==&quot;yes&quot;), evidence = ( X==&quot;yes&quot;)) En este caso la probabilidad de haber estado en Asia dado que se te encontró una placa de rayos-X positiva es alrededor de 2.55%. "],
["lagartijas.html", "Sección 6 Lagartijas", " Sección 6 Lagartijas # load the data. data(lizards) # create and plot the network structure. dag = model2network(&quot;[Species][Diameter|Species][Height|Species]&quot;) graphviz.plot(dag, shape = &quot;ellipse&quot;) ## Loading required namespace: Rgraphviz # This data set is useful as it offers nominal values for # the conditional mutual information and X^2 tests. ci.test(&quot;Height&quot;, &quot;Diameter&quot;, &quot;Species&quot;, test = &quot;mi&quot;, data = lizards) ## ## Mutual Information (disc.) ## ## data: Height ~ Diameter | Species ## mi = 2.0256, df = 2, p-value = 0.3632 ## alternative hypothesis: true value is greater than 0 ci.test(&quot;Height&quot;, &quot;Diameter&quot;, &quot;Species&quot;, test = &quot;x2&quot;, data = lizards) ## ## Pearson&#39;s X^2 ## ## data: Height ~ Diameter | Species ## x2 = 2.0174, df = 2, p-value = 0.3647 ## alternative hypothesis: true value is greater than 0 "]
]
