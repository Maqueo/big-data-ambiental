[
["index.html", "Big Data Ambiental Información del curso", " Big Data Ambiental Julián Equihua, Miguel Equihua, Miguel Hidalgo, Octavio Pérez, Oliver López, Teresa Ortiz 2019-03-05 Información del curso En el estado actual de la comprensión de los desafíos que implica el desarrollo humano en co‐evolución con los ecosistemas ha venido emergiendo la llamada ciencia de la sustentabilidad (Clark et al., 2003; Koss, 2011; Spangenberg, 2011). Surge en un contexto de crisis multidimensional que desafía los enfoques adoptados por las disciplinas tradicionales y en consecuencia a nuestra propia visión del mundo. Se reconoce que en la forma como el modelo económico dominante actual ha concebido los “recursos naturales”, conlleva dos importantes errores (Folke et al., 2002). El primer error es el supuesto de que los ecosistemas responden en forma lineal, predecible y controlable, al uso humano; el segundo es el suponer que los dos sub‐sistemas (humano y natural) deben ser abordados por separado. La emergente ciencia de la sustentabilidad surge ante la necesidad de comprender la complejidad en la que la humanidad está inmersa y la encrucijada en la que estamos para definir el desarrollo humano y nuestro futuro. La complejidad, tanto desde la perspectiva del pensamiento complejo como de la teoría de la complejidad (Walby, 2007; Zoya, 2015), nos confrontan a la dificultad de confiar en la ciencia para pronosticar la evolución previsible de la realidad. También nos hacen conscientes de la responsabilidad ética inherente al uso del conocimiento que impacta sobre el futuro de la humanidad (Rozzi et al., 2015; Garnett, 2018). Al mismo tiempo, nos impulsa a buscar, desarrollar y utilizar nuevas herramientas predictivas, así como a reconstruir nuestros enfoques. En consecuencia, proponemos este curso como un espacio de reflexión sobre el pensamiento complejo, así como una introducción a las nuevas herramientas que están surgiendo para comprender y analizar la complejidad a partir de los datos que emite, los que cada vez más podemos obtener en forma masiva. Este trabajo está bajo una Licencia Creative Commons Atribución 4.0 Internacional. "],
["temario.html", "Temario", " Temario Minería de datos: Lenguaje de programación y cómputo en la nube Aprendizaje automatizado: Redes Bayesianas "],
["introduccion-a-probabilidad.html", "Sección 1 Introducción a probabilidad", " Sección 1 Introducción a probabilidad “Probabilidad es el lenguaje matemático para cuantificar incertidumbre.” -Wasserman En estas notas hacemos un repaso de conceptos de probabilidad con un enfoque computacional: Terminología de probabilidad: espacio de resultados, eventos, funciones de probabilidad. Interpretación frecuentista de probabilidad. Variables aleatorias: a qué se refieren. Las referencias para esta sección son Pitman (1992), Ross (1998) y Wasserman (2010). Referencias "],
["probabilidad-como-extension-a-proporcion.html", "1.1 Probabilidad como extensión a proporción", " 1.1 Probabilidad como extensión a proporción Espacio de resultados y eventos El espacio de resultados \\(\\Omega\\) es el conjunto de posibles resultados de un experimento aleatorio. A los puntos \\(\\omega \\in \\Omega\\) se les conoce como resultados muestrales, realizaciones o elementos. Ejemplo: Si lanzamos una moneda dos veces entonces el espacio de resultados es: \\[\\Omega = \\{AA, AS, SA, SS \\}\\] Un evento es un subconjunto del espacio muestral, los eventos usualmente se denotan por letras mayúsculas. El evento: que el primer lanzamiento resulte águila es \\[A=\\{AA, AS\\}\\] Eventos equiprobables Históricamente la primera aproximación a la probabilidad ocurrió con apuestas y juegos de azar, y se veía como una extensión de la idea de proporción, o cociente de una parte con respecto a un todo. Por ejemplo, si en la carrera de matemáticas del ITAM hay 300 estudiantes hombres y 700 mujeres, la proporción de hombres es: \\[\\frac{300}{700+300}=0.3\\] Ahora, supongamos que elegimos un estudiante al azar, la probabilidad de elegir una mujer es \\(0.7\\). En el ejemplo hay un supuesto implícito en elegir al azar (o aleatoriamente), en este caso estamos suponiendo que todos los estudiantes tienen la misma probabilidad de ser elegidos, que nos lleva al siguiente concepto: Eventos equiprobables. Si todos los elementos en el espacio de resultados tienen la misma oportunidad de ser elegidos entonces la probabilidad del evento A es el número de resultados en A dividido entre el número total de posibles resultados: \\[P(A)=\\frac{\\#(A)}{\\#(\\Omega)}\\] Por lo que solo hace falta contar. Por ejemplo, la probabilidad de obtener \\(AA\\) si lanzamos una moneda dos veces es \\(1/4 = 0.25\\), y la probabilidad del evento que al primer lanzamiento resulte águila es \\(2/4 = 0.5\\). Lanzamos un dado y anotamos el número de la cara superior, después lanzamos otro dado y anotamos el número de la cara superior. ¿Cuál es el espacio de resultados? ¿Cuál es la probabilidad de que la suma de los números sea 5? ¿Cuál es la probabilidad de que el segundo número sea mayor que el primero? Repite las preguntas anteriores cuando lanzas 2 dados con \\(n\\) caras (\\(n \\ge 4\\)). Ejemplo: combinaciones Un comité de 5 personas será seleccionado de un grupo de 6 hombres y 9 mujeres. Si la selección es aleatoria, ¿cuál es la probabilidad de que el comité este conformado por 3 hombres y 2 mujeres? Hay \\(\\dbinom{15}{5}\\) posibles comités, cada uno tiene la misma posibilidad de ser seleccionado. Por otra parte, hay \\(\\dbinom{6}{3} \\dbinom{9}{2}\\) posibles comités que incluyen 3 hombres y 2 mujeres, por lo tanto, la probabilidad que buscamos es: \\[\\frac{\\dbinom{6}{3} \\dbinom{9}{2}}{\\dbinom{15}{5}} \\] y la función para calcular combinaciones en R es choose(n, r) choose(6, 3) * choose(9, 2) / choose(15, 5) #&gt; [1] 0.24 Los solución a problemas derivados de juegos de azar se complica rápidamente y suele ser necesario conocer técnicas de conteo para resolverlos. Ahora, a pesar de que históricamente el desarrollo de estás técnicas surge de los juegos de azar, la realidad es que los jugadores en realidad estaban pensando en frecuencias relativas: ¿Si apuesto en un juego de dados de manera repetida, terminaré con ganancias o pérdidas? ¿Qué estrategia debo seguir para mejorar mis posibilidades de ganar? Es así que la interpretación frecuentista de la probabilidad estaba considerada desde un inicio. "],
["interpretacion-frecuentista-de-probabilidad.html", "1.2 Interpretación frecuentista de probabilidad", " 1.2 Interpretación frecuentista de probabilidad Ya tenemos una interpretación intuitiva de probabilidad pero nos deja abierta la pregunta de como interpretar probabilidades en aplicaciones. Abordamos ahora la interpretación frecuentista de la probabilidad en la cuál las probabilidades se entienden como una aproximación matemática de frecuencias relativas cuando la frecuencia total tiende a infinito. Una frecuencia relativa es una proporción que mide que tan seguido, o frecuente, ocurre una u otra cosa en una sucesión de observaciones. Pensemos en un experimento que se pueda repetir, por ejemplo, lanzar una moneda, lanzar un dado, el nacimiento de un bebé. Llamaremos ensayo a una repetición del experimento. Ahora, sea A un posible resultado del evento (obtener sol, obtener un 6, el bebé es niña), si A ocurre \\(m\\) veces en \\(n\\) ensayos, entonces la frecuencia relativa de A en \\(n\\) ensayos es \\(m/n\\). Supongamos que lanzamos una moneda 10 veces y obtenemos los siguientes resultados: lanzamientos_10 &lt;- sample(c(&quot;A&quot;, &quot;S&quot;), 10, replace = TRUE) lanzamientos_10 #&gt; [1] &quot;S&quot; &quot;S&quot; &quot;S&quot; &quot;S&quot; &quot;A&quot; &quot;A&quot; &quot;S&quot; &quot;A&quot; &quot;S&quot; &quot;S&quot; Podemos calcular las secuencia de frecuencias relativas de águila: cumsum(lanzamientos_10 == &quot;A&quot;) # suma acumulada de águilas #&gt; [1] 0 0 0 0 1 2 2 3 3 3 cumsum(lanzamientos_10 == &quot;A&quot;) / 1:10 #&gt; [1] 0.000 0.000 0.000 0.000 0.200 0.333 0.286 0.375 0.333 0.300 Una regla general, es que las frecuencias relativas basadas en un número mayor de observaciones son menos fluctuantes comparado con las frecuencias relativas basadas en pocas observaciones. Este fenómeno se conoce como la ley empírica de los promedios (y se formalizó después en las leyes de los grandes números): n &lt;- 1000 tibble(num_lanzamiento = 1:n, lanzamiento = sample(c(&quot;A&quot;, &quot;S&quot;), n, replace = TRUE)) %&gt;% mutate(frec_rel = cummean(lanzamiento == &quot;A&quot;)) %&gt;% ggplot(aes(x = num_lanzamiento, y = frec_rel)) + geom_hline(yintercept = 0.5, color = &quot;red&quot;, alpha = 0.5) + geom_line(color = &quot;darkgray&quot;) + geom_point(size = 1.0) + labs(y = &quot;frecuencia relativa&quot;, title = &quot;1000 volados&quot;, x = &quot;lanzamiento&quot;) Veamos las frecuencias relativas para 3 series de 1000 lanzamientos. lanzar &lt;- function(n = 1000){ tibble(num_lanzamiento = 1:n, lanzamiento = sample(c(&quot;A&quot;, &quot;S&quot;), n, replace = TRUE)) %&gt;% mutate(frec_rel = cummean(lanzamiento == &quot;A&quot;)) } head(lanzar()) #&gt; # A tibble: 6 x 3 #&gt; num_lanzamiento lanzamiento frec_rel #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1 S 0 #&gt; 2 2 S 0 #&gt; 3 3 A 0.333 #&gt; 4 4 S 0.25 #&gt; 5 5 A 0.4 #&gt; 6 6 A 0.5 set.seed(31287931) # usamos la función map_df del paquete purrr map_df(1:3, ~lanzar(), .id = &quot;serie&quot;) %&gt;% ggplot(aes(x = log(num_lanzamiento), y = frec_rel, color = as.character(serie))) + geom_hline(yintercept = 0.5, color = &quot;darkgray&quot;) + geom_line() + scale_x_continuous(&quot;lanzamiento&quot;, labels = exp, breaks = log(sapply(0:10, function(i) 2 ^ i))) + labs(color = &quot;serie&quot;, y = &quot;frecuencia relativa&quot;, title = &quot;1000 volados&quot;) En la interpretación frecuentista, la probabilidad de un evento \\(A\\) es la estimación de la frecuencia relativa de \\(A\\) cuando el número de ensayos tiende a infinito. Si denotemos la proporción de veces que ocurre \\(A\\) en \\(n\\) ensayos por \\(P_n(A)\\), se espera que \\(P_n(A)\\) sea cercana a la probabilidad \\(P(A)\\) si \\(n\\) es grande: \\[P_n(A) \\approx P(A)\\] Veamos un ejemplo de calculo de una probabilidad como frecuencia relativa; el objetivo es entender cómo la interpretación frecuentista nos da el nivel de detalle correcto cuando suponemos resultados equiprobables. Ejemplo: Lanzamiento de dos monedas Supongamos que lanzamos dos monedas de manera simultánea. ¿Cuál es la probabilidad de que las dos monedas sean águila? Las dos son águila o no, así que la posibilidad es 1/2. Si definimos el resultado como el número de caras que se leen en las monedas, puede haber 0, 1 o 2. Si suponemos que estos tres resultados son igualmente probables, entonces la posibilidad es 1/3. A pesar de que las monedas son similares supongamos que se pueden distinguir, llamémoslas moneda 1 y moneda 2. Ahora tenemos cuatro posibles resultados: AA, AS, SA, SS, (la primer letra corresponde a la cara observada en la moneda 1 y la segunda en la moneda 2). Si estos 4 resultados son igualmente probables entonces el evento AA tiene posibilidad de 1/4. ¿Cuál es la respuesta correcta? En cuanto a teoría formal todas son correctas, cada escenario tiene supuestos de resultados equiprobables claramente enunciados y con base en éstos determina una probabilidad de manera correcta; sin embargo, los supuestos son diferentes y por tanto también las conclusiones. Únicamente una de las soluciones puede ser consistente con la interpretación frecuentista, ¿cuál es? La primer respuesta es incorrecta pues supone probabilidad cero para el evento águila y sol. La solución dos, por otra parte, no es fácil de desacreditar, así que realicemos el experimento para encontrar la respuesta: n &lt;- 10000 moneda_1 &lt;- sample(c(&quot;A&quot;, &quot;S&quot;), n, replace = TRUE) moneda_2 &lt;- sample(c(&quot;A&quot;, &quot;S&quot;), n, replace = TRUE) sum(moneda_1 == moneda_2 &amp; moneda_1 ==&quot;A&quot;) / n #&gt; [1] 0.257 La respuesta 3 es la correcta, y lo que vemos es que incluso cuando el supuesto de igualmente probables es apropiado a un cierto nivel de descripción determinado, este nivel no es algo que se pueda juzgar usando únicamente matemáticas, sino que se debe juzgar usando una interpretación de la probabilidad, como frecuencias relativas en ensayos. Más aún, hay ejemplos donde las monedas no son justas, o como la predeción del sexo de un bebé recién nacido, donde el supuesto de equiprobabilidad no es adecuado. "],
["simulacion-para-el-calculo-de-probabilidades.html", "1.3 Simulación para el cálculo de probabilidades", " 1.3 Simulación para el cálculo de probabilidades En el ejemplo anterior vimos que puede ser sencillo usar simulación para calcular probabilidades, pues usando la interpretación de frecuencia relativa simplemente hace falta simular el experimento y contar los casos favorables entre el total de casos. Simulación para el cálculo de probabilidades: Definir el espacio de resultados. Describir el mecanismo que genera los resultados, esto incluye entender los pasos que involucran azar y los que no. Replicar el experimento con código, siguiendo el conocimiento elicitado en 1 y 2. Repetir el paso 3 \\(n\\) veces y calcular la frecuencia relativa de éxitos, estimando así la probabilidad. Para el paso 2, en R suelen ser de utilidad las funciones runif y sample(), revisa la ayuda de estas funciones. Ejemplo: comité Un comité de 5 personas será seleccionado de un grupo de 6 hombres y 9 mujeres. Si la selección es aleatoria, ¿cuál es la probabilidad de que el comité este conformado por 3 hombres y 2 mujeres? El espacio de resultados es \\(\\Omega = \\{M_1M_2M_3M_4M_5, M_2M_3M_4M_5M_6,... H_1,H_2H_3H_4H_5,H_2H_3H_4H_5H_6\\}\\). Se seleccionan 5 integrantes al azar del conjunto de hombres y mujeres, es claro que cada persona solo puede estar una vez. candidatos &lt;- c(paste(&quot;M&quot;, 1:9, sep = &quot;_&quot;), paste(&quot;H&quot;, 1:6, sep = &quot;_&quot;)) sample(candidatos, 5, replace = FALSE) #&gt; [1] &quot;H_1&quot; &quot;M_7&quot; &quot;H_5&quot; &quot;M_4&quot; &quot;M_3&quot; comite &lt;- function(){ candidatos &lt;- c(paste(&quot;M&quot;, 1:9, sep = &quot;_&quot;), paste(&quot;H&quot;, 1:6, sep = &quot;_&quot;)) comite &lt;- sample(candidatos, 5, replace = FALSE) n_mujeres &lt;- sum(substr(comite, 1, 1) == &quot;M&quot;) n_mujeres == 2 } rerun(1000, comite()) %&gt;% flatten_dbl() %&gt;% mean() #&gt; [1] 0.219 Ejemplo: La ruina del jugador Un jugador tiene $100, y va a apostar en un juego donde la probabilidad de ganar es p = 0.47 (e.g. una ruleta 18/38), si gana recibe el doble de lo que arriesgó, si no gana pierde todo lo que apostó. Cada vez que juega puede apostar cualquier cantidad siempre y cuando aún cuente con dinero. El jugador dejará de jugar cuando su capital sea $0 o cuando gane $200. El jugador busca una estrategia que le ayude a aumentar su probabilidad de ganar y te pregunta: ¿Cuál es la probabilidad de ganar si apuesto en incrementos de $5 cada vez que apuesto? Siguiendo los pasos enunciados: El espacio de resultados es \\(\\Omega = \\{GGGGGGGGGGGGGGGGGGGG, \\\\ \\mspace{40mu}PGGGGGGGGGGGGGGGGGGGGGG,\\\\ \\mspace{40mu}GPGGGGGGGGGGGGGGGGGGGGG, ...\\}\\) El jugador juega mientras tenga capital y este sea menor a $200, el monto de la apuesta está fijo en $5, no importa el capital en cada momento. La componente aleatoria involucra si gana cada uno de los juegos y esto ocurre con probabilidad 0.47. apostar &lt;- function(dinero = 100, apuesta = 5, tope = 200){ while(0 &lt; dinero &amp; dinero &lt; tope){ if(sample(1:38, 1) &lt;= 18){ dinero &lt;- dinero + apuesta } else{ dinero &lt;- dinero - apuesta } } dinero &gt; 0 } n_juegos &lt;- 5000 juegos &lt;- rerun(n_juegos, apostar()) %&gt;% flatten_dbl() mean(juegos) #&gt; [1] 0.114 # incrementos de 50? juegos &lt;- rerun(n_juegos, apostar(apuesta = 50)) %&gt;% flatten_dbl() mean(juegos) #&gt; [1] 0.443 La solución analítica la pueden leer en este documento de caminatas aleatorias: p = 0.47 1 - (1 - (p / (1 - p)) ^ (100 / 5)) / (1 - (p / (1 - p)) ^ (200 / 5)) # apostando de 5 en 5 #&gt; [1] 0.083 1 - (1 - (p / (1 - p)) ^ (100 / 50)) / (1 - (p / (1 - p)) ^ (200 / 50)) # apostando de 50 en 50 #&gt; [1] 0.44 Cumpleaños. ¿Cuántas personas debe haber en un salón para que la probabilidad de encontrar 2 con el mismo cumpleaños sea 0.5? Supuestos: Mismo cumpleaños implica mismo día y mes. No hay años bisiestos. La probabilidad de que alguien nazca un día dado es la misma para todos los días del año. Chabelo (Monty Hall) Supongamos que estamos jugando las catafixias de Chabelo, en este juego hay 3 catafixias: 2 de ellas están vacías y una tiene un premio: El juego comienza cuando escoges una catafixia. A continuación Chabelo abre una catafixia vacía de las dos catafixias restantes. Tu eliges si te mantienes con tu catafixia o cambias a la otra que continúa cerrada. Chabelo abre tu segunda elección de catafixia y se revela si ganaste. ¿Cuál es la probabilidad de que ganes si cambias de catafixia? Urna: 10 personas (con nombres distintos) escriben sus nombres y los ponen en una urna, después seleccionan un nombre (al azar). Sea A el evento en el que ninguna persona selecciona su nombre, ¿Cuál es la probabilidad del evento A? Supongamos que hay 3 personas con el mismo nombre, ¿Cómo calcularías la probabilidad del evento A en este nuevo experimento? El señor J. tiene 2 cachorros, el mayor es hembra. ¿Cuál es la probabilidad de que los dos sean hembra? La señora K. tiene 2 cachorros, al menos uno es macho. ¿Cuál es la probabilidad de que los dos sean macho? Podemos generalizar las definiciones de equiprobable al caso continuo, como ejemplo supongamos que se lanza un dado a un tablero cuadrandgular de lado con longitud 2, ¿cuál es la probabilidad de que el dado caiga en el círculo de radio 1 inscrito (contenido) en un cuadrado de lado con longitud 2? tablero &lt;- ggplot() + geom_circle(aes(x0 = 0, y0 = 0, r = 1)) + geom_rect(aes(xmin = -1, xmax = 1, ymin = -1, ymax = 1), fill = &quot;white&quot;, color = &quot;black&quot;, alpha = 0.5) + coord_equal() ggsave(&quot;imagenes/tablero.png&quot;, tablero, width = 3, height = 3) En este caso usamos áreas relativas (círculo \\(\\phi\\) y cuadrado \\(\\Omega\\)) para calcular la probabilidad: denotemos C al evento tal que el dardo cae en el círculo, entonces: \\[P(C) = \\frac{Área(\\phi)}{Área(\\Omega)}\\] ¿Y simulando? circunferencia &lt;- function(){ x &lt;- runif(1) * sample(c(-1, 1), 1) y &lt;- runif(1) * sample(c(-1, 1), 1) sqrt(x ^ 2 + y ^ 2) &lt; 1 } rerun(10000, circunferencia()) %&gt;% flatten_dbl() %&gt;% mean() #&gt; [1] 0.784 dardos &lt;- tibble(x = runif(1000, -1, 1), y = runif(1000, -1, 1), en_circulo = sqrt(x ^ 2 + y ^ 2) &lt; 1) tablero_dardos &lt;- tablero + geom_point(data = dardos, aes(x, y, color = en_circulo), alpha = 0.5, show.legend = FALSE) ggsave(&quot;imagenes/tablero_dardos.png&quot;, tablero_dardos, width = 3, height = 3) knitr::include_graphics(&quot;imagenes/tablero_dardos.png&quot;) Ahora, en el ejemplo de los dardos es más realista pensar que la probabilidad de que el dardo caiga en un segmento de la zona central no es la misma a que caiga en un segmento de igual área en las orillas. tablero_zonas &lt;- tablero + geom_rect(aes(xmin = -1, xmax = -0.8, ymin = -1, ymax = -0.8), fill = &quot;red&quot;, alpha = 0.5) + geom_rect(aes(xmin = -.1, xmax = 0.1, ymin = -0.1, ymax = 0.1), fill = &quot;red&quot;, alpha = 0.5) ggsave(&quot;imagenes/tablero_zonas.png&quot;, tablero_zonas, width = 3, height = 3) knitr::include_graphics(&quot;imagenes/tablero_zonas.png&quot;) La definición de probabilidad como área relativa no se puede usar en estos casos, sin embargo, el enfoque de simulación se continúa manteniendo. Comencemos con el caso del dardo univariado. unif &lt;- ggplot() + geom_rect(aes(xmin = 0.3, xmax = 0.6, ymin = 0, ymax = 1), fill = &quot;red&quot;, alpha = 0.5) + xlim(0, 1) unif En este caso de área relativa, calculamos la probabilidad cómo el área sombreada \\[P([a, b]) = \\frac{b-a}{1} = \\int_a^b 1dx\\] Ahora, si el dardo cae en ciertas zonas con mayor probabilidad: ggplot(tibble(x = c(0 , 1)), aes(x)) + stat_function(fun = dbeta, args = list(shape1 = 5, shape2 = 2)) + geom_rect(data = NULL, aes(xmin = 0, xmax = 1, ymin = 0, ymax = 1), fill = &quot;red&quot;, alpha = 0.2) \\[P([a,b])=\\int_a^bf(x)dx\\] Y lo podemos calcular con simulación, por ejemplo la probabilidad de x en [0.2, 0.5]: curva &lt;- function(){ x &lt;- runif(1) y &lt;- runif(1) * 2.5 while(dbeta(x, 5, 2) &lt; y){ x &lt;- runif(1) y &lt;- runif(1) * 2.5 } x } sims_x &lt;- rerun(5000, curva()) %&gt;% flatten_dbl() mean(sims_x &gt; 0.2 &amp; sims_x &lt; 0.5) #&gt; [1] 0.104 tibble(x = runif(1000), y = runif(1000) * 2.5, dentro = dbeta(x, 5, 2) &gt; y, en_int = dentro * (x &gt; 0.2 &amp; x &lt; 0.5), cat = case_when(!dentro ~ &quot;a&quot;, dentro &amp; en_int ~ &quot;b&quot;, TRUE ~ &quot;c&quot;)) %&gt;% ggplot()+ stat_function(fun = dbeta, args = list(shape1 = 5, shape2 = 2)) + geom_point(aes(x, y, color = cat), alpha = 0.5, show.legend = FALSE) En el caso discreto: Supongamos que el proceso de selección del comité tiene sesgo, las mujeres se seleccionan con mayor probabilidad que los hombres: comite &lt;- function(){ candidatos &lt;- c(paste(&quot;M&quot;, 1:9, sep = &quot;_&quot;), paste(&quot;H&quot;, 1:6, sep = &quot;_&quot;)) comite &lt;- sample(candidatos, 5, replace = FALSE, prob = c(rep(2, 9), rep(1, 6))) n_mujeres &lt;- sum(substr(comite, 1, 1) == &quot;M&quot;) n_mujeres == 2 } rerun(1000, comite()) %&gt;% flatten_dbl() %&gt;% mean() #&gt; [1] 0.094 "],
["probabilidad-definicion-matematica.html", "1.4 Probabilidad: definición matemática", " 1.4 Probabilidad: definición matemática Desde un punto de vista puramente matemático, la probabilidad se define como una función de eventos. Los eventos se representan como conjuntos, y suponemos que la función de probabilidad satisface las reglas básicas de proporción. Antes de definir estas reglas consideremos la representación de los eventos como subconjuntos de un espacio de resultados. Supongamos que tenemos un espacio de resultados \\(\\Omega\\), y que todos los eventos de interés están representados como subconjuntos de \\(\\Omega\\). Podemos pensar en \\(\\Omega\\) como una representación de todas las situaciones que pueden ocurrir, no suponemos que es finito, ni que los eventos son igualmente probables. Las reglas de la probabilidad involucran relaciones lógicas entre eventos; estas se traducen a relaciones de conjuntos. Por ejemplo, si C es el evento que ocurre si sucede A o si sucede B, entonces el conjunto de maneras en las que ocurre C es la unión del conjunto de maneras en que ocurre A y el conjunto de maneras en que ocurre B. Veamos como se traduce de eventos a conjuntos Lenguaje de eventos Lenguaje de conjuntos Notación de conjuntos Espacio de resultados conjunto universal \\(\\Omega\\) evento subconjunto de \\(\\Omega\\) \\(A,B,C,...\\) evento imposible conjunto vacío \\(\\emptyset\\) no A, opuesto de A complemento de A \\(A^c\\) A o B unión de A y B \\(A\\cup B\\) tanto A como B intersección de A y B \\(AB,A\\cap B\\) A y B mutuamente excluyentes A y B disjuntos \\(AB=\\emptyset\\) si A entonces B A es subconjunto de B \\(A\\subset B\\) Particiones y axiomas de probabilidad Decimos que un conjunto de \\(n\\) eventos \\(B_1,...,B_n\\) es una partición del evento \\(B\\) si \\(B=B_1 \\cup B_2 \\cup \\cdot\\cdot\\cdot \\cup B_n\\) y los eventos \\(B_1,...,B_n\\) son mutuamente excluyentes. Ahora podemos definir probabilidad: Una función \\(P\\) es una función de probabilidad si satisface las siguientes condiciones: Un valor de probabilidad debe ser no-negativo: \\[P(B) \\geq 0\\] para cualquier evento \\(B\\) La suma de las probabilidades a través de todos los posibles eventos en el espacio de resultados debe ser 1 (i.e. uno de los eventos en el espacio de resultados debe ocurrir). \\[P(\\Omega) = 1\\] Si \\(B_1,...,B_n\\) es una partición del evento \\(B\\) entonces, la probabilidad de que ocurra B es la suma de las probabilidades individuales: \\[P(B)=P(B_1)+P(B_2) + \\cdot\\cdot\\cdot +P(B_n)\\] 1.4.1 Propiedades de la función de probabilidad: \\(P(A^c) = 1 - P(A)\\) \\(P(\\emptyset)=0\\) Si \\(A \\subset B\\) entonces \\(P(A) \\le P(B)\\) \\(0\\le P(A) \\le 1\\) La regla general de la suma: \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) "],
["variables-aleatorias.html", "1.5 Variables aleatorias", " 1.5 Variables aleatorias A partir de un experimento aleatorio se pueden definir muchas preguntas de probabilidad, por ejemplo, en el caso de la ruina del jugador podríamos preguntarnos: las ganancias después del tercer juego, probabilidad de ganar, duración del experimeto (cuántos juegos se jugaron antes de alcanzar las reglas de término). Sin embargo, muchas veces nos centramos en estudiar un solo aspecto del experimento. La variable aleatoria \\(X\\) es un mapeo entre el espacio de resultados y los números reales. Distribución de probabilidad La distribución de probabilidad de una variable aleatoria \\(X\\) es simplemente una lista de todos los posibles valores y sus probabilidades correspondientes (en el caso discreto). Podemos pensar en el término distribución como una masa distribuida sobre un área o volumen \\(\\Omega\\), y \\(P(A)\\) representa la proporción de esa masa en el subconjunto \\(A\\). Definimos \\(X\\) como la variable aleatoria del número de juegos antes de que termine el experimento de la ruina del jugador, grafica la distribución de probabilidad de \\(X\\) (calcula \\(P(X=1), P(X=2),...,P(X=50)\\)). La función de distribución acumulada contiene la misma información que la función de distribución y se define como \\[P(X \\le x)\\] con la ventaja de que la definición aplica tanto al caso discreto como en el caso continuo. Esperanza La esperanza (valor esperado o media) de una variable aleatoria \\(X\\), es la media de la distribución \\(X\\), esto es, \\[E(X)=\\sum_{x\\in \\Omega_x} x P(X=x)\\] el promedio de todos los posibles valores de \\(X\\) ponderados por sus probabilidades. Por ejemplo, si \\(X\\) toma únicamente dos posibles valores, \\(a,b\\) con probabilidad \\(P(a)\\) y \\(P(b)\\) entonces \\[E(X)=aP(a)+bP(b).\\] Ejemplo: Supongamos que \\(X\\) es el valor que se produce cuando tiro un dado justo. Entonces, \\[E(X)=1\\cdot P(X=1) +2\\cdot P(X=2) +3\\cdot P(X=3) +\\\\ \\mspace{92mu}4\\cdot P(X=4) +5\\cdot P(X=5) +6\\cdot P(X=6) = 3.5\\] Lo que nos dice que si tiramos el dado muchas veces deberíamos esperar que el promedio de las tiradas sea cercano a 3.5. Esperanza como un promedio cuando n es grande. Si vemos las probabilidades de los valores de \\(X\\) como una aproximación de frecuencias relativas cuando n es grande, entonces \\(E(X)\\) es aproximadamente el valor promedio del valor de \\(X\\) cuando n es grande. x &lt;- rnorm(10000, mean = 10) mean(x) #&gt; [1] 9.99 La esperanza cumple las siguientes reglas: Constantes. La esperanza de una variable aleatoria constante es su valor constante, \\[E(c) = c\\] Indicadoras. Si \\(I_A\\) es la función indicadora del evento \\(A\\), \\[E(I_A) = P(A)\\] Funciones. Típicamente, \\(E[g(X)]\\ne g[E(X)]\\), pero \\[E[g(X)] = \\sum_{x \\in \\Omega_X} g(x) P(X=x)\\] Factores constantes. Para una constante c, \\[E(cX)=cE(X)\\] Adición. Para cualquier par de variables aleatorias \\(X\\), \\(Y\\), \\[E(X+Y) = E(X)+E(Y)\\] Multiplicación. Típicamente \\(E(XY) \\ne E(X)E(Y)\\), pero si \\(X\\) y \\(Y\\) son independientes, entonces \\[E(XY)=E(X)E(Y)\\] Varianza y desviación estándar Si intentamos predecir el valor de una variable aleatoria usando su media \\(E(X)=\\mu\\), vamos a fallar por una cantidad aleatoria \\(X-\\mu\\). Suele ser importante tener una idea de que tan grande será esta desviación. Debido a que \\[E(X-\\mu) = E(X)-\\mu=0\\] es necesario considerar la diferencia absoluta o la diferencia al cuadrado de \\(X-\\mu\\) con el fin de tener una idea del tamaño de la desviación sin importar el signo de esta. Varianza y desviación estándar. La varianza de \\(X\\), denotada \\(var(X)=\\sigma^2\\) es la media de la desviación cuadrada de \\(X\\) respecto a su valor esperado \\(\\mu=E(X)\\): \\[\\sigma^2(X)=var(X)=E(X-\\mu)^2\\] La desviación estándar de \\(X\\), es la raíz cuadrada de la varianza de X: \\[\\sigma(X)=sd(X)=\\sqrt{var(X)}\\] Intuitivamente, \\(sd(X)\\) es una medida de la dispersión de la distribución de \\(X\\) alrededor de su media. Debido a que la varianza es el valor central de la distribución de \\((X-\\mu)^2\\), su raíz cuadrada da una idea del tamaño típico de la desviación absoluta \\(|X-\\mu|\\). Notemos que \\(E(X)\\), \\(var(X)\\) y \\(sd(X)\\) están determinados por \\(X\\), de tal manera que si dos variables aleatorias tienen la misma distribución, también tienen la misma media, varianza y desviación estándar. "],
["distribuciones-multivariadas.html", "1.6 Distribuciones multivariadas", " 1.6 Distribuciones multivariadas Hasta ahora hemos estudiado distribuciones univariadas y como simular de ellas, sin embargo, es común que un modelo probabilístico involucre más de una variable aleatoria por lo que estudiaremos el concepto de distribuciones de probabilidad multivariadas. La distribución conjunta sobre un conjunto de variables aleatorias \\(\\{X_1,...,X_n\\}\\), que denotamos \\(p(x_1,...,x_n)\\), asigna probabilidades a todos los eventos determinados por el conjunto de variables aleatorias. En el caso discreto bivariado, dado las variables aleatorias discretas \\(X\\) y \\(Y\\), definimos la función de densidad conjunta como \\(f(x,y)=P(X=x, Y=y)\\). Ejemplo. Consideremos una distribución de probabilidad sobre la población de habitats para un jaguar en Veracruz. El espacio de resultados es el conjunto de todos los hábitats en la población. En muchas ocasiones buscamos resolver preguntas que involucran más de una variable aleatoria, en este ejemplo nos interesan: Abundancia de presas: toma los valores baja (≤1k), media ((1k,5k]), media alta ((5k,12k]) y alta (&gt;12k). Tipo de habitat: toma 3 valores, agropecuario, protegido u otros. La distribución conjunta de variables aleatorias discretas se puede representar por medio de tablas. Presas/Tipo agropecuario protegido otros baja 0.17 0.01 0.02 media 0.44 0.03 0.01 media alta 0.09 0.07 0.01 alta 0 0.14 0.10 En el caso continuo bivariado, decimos que la función \\(p(x,y)\\) es una función de densidad de probabilidad para las variables aleatorias \\((X,Y)\\) si: 1. \\(p(x,y) \\geq 0\\) para toda \\((x,y)\\). \\(\\int_{-\\infty}^{\\infty}p(x,y)dxdy=1\\). Para cualquier conjunto \\(A \\subset \\mathbb{R} \\times \\mathbb{R}\\), \\(P((X,Y) \\in A) = \\int\\int_A p(x,y)dxdy\\). Ejemplo. Sean \\((X,Y)\\) uniformes en el cuadrado unitario, entonces \\[ p(x,y) = \\left\\{ \\begin{array}{lr} 1, &amp; 0\\leq x \\leq 1,0\\leq y \\leq 1\\\\ 0, &amp; e.o.c. \\end{array} \\right. \\] Para encontrar \\(P(X &lt; \\frac{1}{2}, Y&lt;\\frac{1}{2})\\), esto es la probailidad del evento \\(A=\\{X&lt;1/2, Y&lt;1/2\\}\\). La integral de \\(p\\) sobre este subconjunto corresponde, en este caso, a calcular el área del conjunto \\(A\\) que es igual a \\(\\frac{1}{4}\\). De la distribución conjunta \\(p(x_1,...,x_n)\\) podemos obtener la distribución de únciamente una variable aleatoria \\(X_j\\), donde \\(X_j \\in \\{X_1,...,X_n\\}\\), la llamamos la distribución marginal de \\(X_j\\). Sea \\(\\{X_1,...,X_n\\}\\) un conjunto de variables aleatorias con distribución conjunta \\(p(x_1,...,x_n)\\), la distribución marginal de \\(X_j\\) (\\(j \\in \\{1,...,n\\}\\)) se define como, \\[p_{X_j}(x_j) = \\sum_{x_1,...,x_{j-1},x_{j+1},...,x_n}p(x_1,...,x_n)\\mbox{ en el caso discreto,}\\] \\[p_{X_j}(x_j) = \\int_{x_1,...,x_{j-1},x_{j+1},...,x_n}p(x_1,...,x_n)dx_1,...,dx_n\\mbox{ en el caso continuo}\\] Ejemplo. Retomando el problema de los hábitats del jaguar, ¿Cuál es la probabilidad de que uno de ellos elegido al azar tenga abundancia de presas baja? Probabilidad condicional Sean \\(A\\), \\(B\\) dos eventos, con \\(P(B)&gt;0\\), la probabilidad condicional de \\(A\\) dado \\(B\\) es \\[P(A|B)=\\frac{P(AB)}{P(B)}\\] Ejemplo. ¿Cuál es la probabilidad de que los hábitats protegidos tengan abundancia baja de presas? ¿Cómo se compara con la probabilidad de que la abundancia de presas sea baja (desconozco el tipo de hábitat)? La noción de probabilidad condicional se extiende a distribuciones condicionales: Sean \\(X\\), \\(Y\\) dos variables aleatorias con función de densidad conjunta \\(p(x,y)\\), entonces la función de densidad condicional de \\(X\\) dado \\(Y=y\\), para toda \\(y\\) tal que \\(p_Y(y) &gt; 0\\), se define como \\[p_{X\\vert Y}(x\\vert y) = \\frac{p(x, y)}{p_Y(y).}\\] Ejemplo. ¿Cuál es la distribución condicional de presas dado tipo protegido? Para obtener toda la distribución condicional calculamos los dos casos restantes (abudnancia de presas media, media alta y alta). Hay que destacar que una distribución condicional se asocia también a una distribución de probabilidad. En el ejemplo anterior, verifiquemos que cada renglón de la tabla de probabilidades suma uno, tiene sólo valores positivos y menores o igual que uno. Probabilidad Total Sean \\(E\\), \\(F\\) dos eventos entonces, \\[P(E) = P(E\\vert F)P(F) + P(E\\vert F^c)P(F^c).\\] De manera más general, sean \\(F_i\\) \\(i = 1,...,n\\) eventos mutuamente excluyentes cuya unión es el espacio muestral, entonces \\[P(E) = \\sum_{i=1}^n P(E\\vert F_i)P(F_i).\\] Ejemplo. Supongamos que el conejo de las montañas o zacatuche (Romerolagus diazi) esta amenazado de desaparecer en varias localidades y que el riesgo de que eso ocurra puede ser de nivel: bajo, medio y alto. De acuerdo con los registros, las probabilidades de que esto ocurra en el lapso de 1 año se estima son \\(0.05\\), \\(0.15\\) y \\(0.30\\) respectivamente. Si el \\(20\\%\\) de las localidades se clasifican en riesgo bajo, \\(50\\%\\) en medio y \\(30\\%\\) en alto, ¿qué proporción de las localidades perderan al zacatuche en un año dado? Para variables aleatorias tenemos: Sean \\(X\\), \\(Y\\) dos variables aleatorias, podemos expresar la distribución marginal de \\(X\\) como: \\[p_X(x) = \\sum_{y} p_{X \\vert Y}(x\\vert y)p_Y(y).\\] Supongamos que ruedo un dado, si observo un número par, lanzo en seguida una moneda justa (la probabilidad de observar águila con ella es la misma que la de observar sol), si el dado muestra un número impar lanzo una moneda sesgada en la que la probabilidad de observar águila es \\(0.9\\). Si observo sol, ¿Cuál es la probabilidad de que haya lanzado la moneda sesgada? El ejercicio anterior introduce la noción de probabilidad inversa: inicialmente conozco la probabilidad de observar sol condicional a que la moneda es sesgada pero ahora me interesa conocer la probabilidad de que haya lanzado una moneda sesgada una vez que observé un sol en el volado. Regla de Bayes La regla de Bayes es una consecuencia de la definición de probabilidad condicional. Sean \\(F_i\\) y \\(i = 1,...,n\\) eventos mutuamente excluyentes cuya unión es el espacio muestral, entonces \\[P(F_j\\vert E) = \\frac{P(E\\vert F_j)P(F_j)}{\\sum_{i=1}^n P(E\\vert F_i)P(F_i)}\\] esta identidad se conoce como la regla de Bayes. Ejemplo. En el contexto del ejemplo de los seguros ahora nos hacemos la siguiente pregunta: si un asegurado tuvo accidentes en 2013, ¿cuál es la probabilidad de que clasifique en riesgo bajo? La intuición es engañosa: En estudios en Alemania y EUA, investigadores le pidieron a médicos que estimaran la probabilidad de que una mujer asintomática entre los \\(40\\) y \\(50\\) años tuviera cáncer de mama si su mamograma era positivo. Se les explicó que el \\(7\\%\\) de los mamogramas indican cáncer cuando no lo hay (falsos positivos). Adicional mente, se le explicó a los médicos que la incidencia de cáncer de mama en ese grupo de edad es \\(0.8\\%\\) y la tasa de falsos negativos de \\(10\\%\\). En Alemania, un tercio de los médicos determinaron que la probabilidad era cercana al \\(90\\%\\) y la mediana de las estimaciones fue \\(70\\%\\). En EUA \\(95\\) de \\(100\\) médicos estimaron que la probabilidad rondaba el \\(75\\%\\). ¿Cómo determinas la probabilidad de que una mujer con mamograma positivo tenga cáncer? Al igual que con probabilidad condicional, la Regla de Bayes tiene una definición análoga para variables aleatorias. Sean \\(X\\), \\(Y\\) dos variables aleatorias, \\[p_{X\\vert Y}(x\\vert y) = \\frac{p_{Y\\vert X}(y\\vert x)p_X(x)}{p_Y(y)}.\\] Supongamos ahora que una compañía de seguros divide a la gente en dos clases: propensos a accidente (30% de las personas) y no propensos a accidente. En un año dado aquellos propensos a accidentes sufren un accidente con probabilidad 0.4, mientras que los del otro grupo sufren un accidente con probabilidad 0.2. ¿Cuál es la probabilidad de que un asegurado tenga un accidente en su segundo año condicional a que sufrió un accidente en el primer año? Una consecuencia de la regla de Bayes es que cualquier distribución multivariada sobre \\(n\\) variables \\(X_1,X_2,...X_n\\) se puede expresar como: \\[p(x_1,x_2,...x_n) = p_{X_1}(x_1)p_{X_2\\vert X_1}(x_2\\vert x_1)p_{X_3\\vert X_1X_2}(x_3\\vert x_1x_2)···p_{X_n\\vert X_1...X_{n-1}}(x_n\\vert x_1...x_{n-1})\\] esta igualdad se conoce como regla de la cadena. Nótese que esta regla funciona para cualquier ordenamiento de las variables aleatorias. Independencia Los eventos \\(E\\), \\(F\\) son independientes sí y solo sí \\[P(EF) = P(E)P(F)\\] De la definición de independencia se sigue que \\(P(E\\vert F) = P(E)\\). Esto es, los eventos \\(E\\) y \\(F\\) son independientes si saber que uno de ellos ocurrió no afecta la probabilidad del otro. Utilizaremos la notación \\(E\\perp F\\) que se lee “\\(E\\) es independiente de \\(F\\)”. Dos variables aleatorias \\(X\\), \\(Y\\), son independientes sí y sólo sí \\[p(x,y) = p_X(x)p_Y(y)\\] Más aún, \\(X\\) y \\(Y\\) son independientes sí y sólo sí \\(p(x,y) \\propto g(x)h(y)\\), por lo que para demostrar independecia podemos omitir las constantes en la factorización de las densidades Similar a la independencia en eventos, la independencia de variables aleatorias implica que \\(p_{X\\vert Y}(x\\vert y) = p_X(x)\\), esto es, \\(Y = y\\) no provee información sobre \\(X\\). Ejemplo. Consideremos la función de densidad conjunta \\(p(x,y) = \\frac{1}{384} x^2y^4e^{-y-(x/2)}\\), \\(x&gt;0\\), \\(y&gt;0\\), ¿\\(X\\) y \\(Y\\) son independientes? Podemos definir \\[ g(x) = \\left\\{ \\begin{array}{lr} x^2e^{-x/2} &amp; : x &gt; 0\\\\ 0 &amp; : x \\le 0 \\end{array} \\right. \\] y \\[ h(y) = \\left\\{ \\begin{array}{lr} y^4e^{-y} &amp; : y &gt; 0\\\\ 0 &amp; : y \\le 0 \\end{array} \\right. \\] entonces \\(p(x,y) \\propto g(x)h(y)\\), para toda \\(x\\), \\(y\\) \\(\\in \\mathbb{R}\\) y concluímos que \\(X\\) y \\(Y\\) son independientes. **Ejemplo.*. Si la densidad conjunta de \\(X\\) y \\(Y\\) está dada por: \\[ p(x, y) = \\left\\{ \\begin{array}{lr} 2 &amp; : 0 &lt; x &lt; y, 0 &lt; y &lt; 1\\\\ 0 &amp; : e.o.c. \\end{array} \\right. \\] ¿\\(X\\) y \\(Y\\) son independientes? Ejercicio. Recordando el ejemplo de departamentos en Hong Kong, veamos si Renta y Tipo son independientes, para esto comparemos \\(p(renta|tipo)\\) y \\(p(renta)\\). 1.6.0.1 Independencia condicional La independencia de eventos o variables aleatorias es poco común en la práctica, más frecuente es el caso en que dos eventos son independientes dado un tercer evento. Ejemplo. En una competencia de velocidad, cada atleta se somete a dos pruebas de dopaje que buscan detectar si el deportista ingirió una substania prohibida. La prueba A consiste en un examen de sangre y la prueba B en un exámen de orina, cada prueba se realiza en un laboratorio distinto y no hay intercambio de información entre los laboratorios. Es razonable pensar que los resultados de los dos exámenes no son independientes. Ahora, supongamos que sabemos que el atleta consumió la substancia prohibida, en este caso podemos argumentar que conocer el resultado de la prueba A no cambia la probabilidad de que el atleta salga positivo en la prueba B. Decimos que el resultado de la prueba B es condicionalmente independiente del resultado de la prueba A dado que el atleta consumió la substancia. Sean \\(A\\), \\(B\\) y \\(C\\), tres eventos decimos que \\(A\\) es independiente de \\(B\\) condicional a \\(C\\) (\\(A \\perp B \\vert C\\)) si, \\[ P(A,B\\vert C) = P(A\\vert C)P(B\\vert C)\\] Similar al caso de independencia, \\(A\\) y \\(B\\) son condicionalmente independientes dado \\(C\\) sí y solo sí \\(P(A \\vert B,C) = P(A \\vert C)\\), esto es, una vez que conocemos el valor de \\(C\\), \\(B\\) no proporciona información adicional sobre \\(A\\). Ejemplo. Retomemos el ejercicio de asegurados. En la solución de este ejercicio utilizamos que \\(P(A_2|AA_1) = 0.4\\) y que \\(P(A_2|A^cA_1) = 0.2\\), al establecer esa igualdad estamos asumiendo que \\(A_2\\) (el asegurado tiene un accidente en el año 2) y \\(A_1\\) (el asegurado tiene un accidente en el año 1) son eventos condicionalmente independientes dado \\(A\\) (el asegurado es propenso a accidentes): \\(P(A_2|AA_1) = P(A_2|A) = 0.4\\) y \\(P(A_2|A^cA_1) = P(A_2|A^c) = 0.2\\). Ejemplo. Retomemos el ejercicio de asegurados. En la solución de este ejercicio utilizamos que \\(P(A_2|AA_1) = 0.4\\) y que \\(P(A_2|A^cA_1) = 0.2\\), al establecer esa igualdad estamos asumiendo que \\(A_2\\) (el asegurado tiene un accidente en el año 2) y \\(A_1\\) (el asegurado tiene un accidente en el año 1) son eventos condicionalmente independientes dado \\(A\\) (el asegurado es propenso a accidentes): \\(P(A_2|AA_1) = P(A_2|A) = 0.4\\) y \\(P(A_2|A^cA_1) = P(A_2|A^c) = 0.2\\). En el caso de variables aleatorias definimos independencia condicional como sigue. Sean \\(X\\), \\(Y\\) y \\(Z\\), tres variables aleatorias decimos que \\(X\\) es independiente de \\(Y\\) condicional a \\(Z\\) (\\(X \\perp Y \\vert Z\\)) si y sólo sí, \\[p(x,y\\vert z) = p_{X\\vert Z}(x\\vert z)p_{Y\\vert Z}(y\\vert z).\\] Y tenemos que \\(X\\) es independiente de \\(Y\\) condicional a \\(Z\\) sí y sólo sí, \\(p(x,y,z) \\propto g(x,z)h(y,z)\\). Ejemplo. Supongamos que ruedo un dado, si observo un número par realizo dos lanzamientos de una moneda justa (la probabilidad de observar águila es la misma que la de observar sol), si el dado muestra un número impar realizo dos lanzamientos de una moneda sesgada en la que la probabilidad de observar águila es 0.9. Denotemos por \\(Z\\) la variable aleatoria asociada a la selección de la moneda, \\(X_1\\) la correspondiente al primer lanzamiento y \\(X_2\\) la correspondiente al segundo. Entonces, \\(X_1\\) y \\(X_2\\) no son independientes, sin embargo, son condicionalmente independientes (\\(X_1 \\perp X_2 \\vert Z\\)), puesto que una vez que se que moneda voy a lanzar el resultado del primer lanzamiento no aporta información adicional para el segundo lanzamiento. Calcularemos la distribución conjunta y la distribución condicional de \\(X_2\\) dado \\(X_1\\). La distribución conjunta esta determinada por la siguiente tabla: Z X1 X2 P(Z,X1,X2) justa a a 0.125 justa a s 0.125 justa s a 0.125 justa s s 0.125 ses a a 0.405 ses a s 0.045 ses s a 0.045 ses s s 0.005 La distribución condicional \\(p(X_2|X_1)\\) es, X1/X2 a s . a 0.757 0.243 1 s 0.567 0.433 1 y la distribución condicional \\(p(X_2|X_1,Z)=p(X_2|Z)\\) es, X1/X2 Z a s . a par 0.5 0.5 1 s par 0.5 0.5 1 a impar 0.9 0.1 1 s impar 0.9 0.1 1 En este punto es claro que \\(X \\perp Y \\vert Z\\) no implica \\(X \\perp Y\\), pues como vimos en el ejemplo de las monedas \\(X_1 \\perp X_2 \\vert Z\\) pero \\(X_1 \\not \\perp X_2\\). Más aún, \\(X \\perp Y\\) tampoco implica \\(X \\perp Y \\vert Z\\). La independencia condicional tiene importantes consecuencias, por ejemplo, si \\(X\\) es independiente de \\(Y\\) dado \\(Z\\) entonces, \\[p(x,y,z) = p_Z(z)p_{X\\vert Z}(x\\vert z)p_{Y\\vert Z}(y\\vert z).\\] Esta expresión de la densidad conjunta es similar a la que obtendríamos usando la regla de la cadena; sin embargo, el número de parámetros necesarios bajo esta representación es menor lo que facilita la estimación. 1.6.0.2 Independencia condicional La independencia de eventos o variables aleatorias es poco común en la práctica, más frecuente es el caso en que dos eventos son independientes dado un tercer evento. Ejemplo. En una competencia de velocidad, cada atleta se somete a dos pruebas de dopaje que buscan detectar si el deportista ingirió una substania prohibida. La prueba A consiste en un examen de sangre y la prueba B en un exámen de orina, cada prueba se realiza en un laboratorio distinto y no hay intercambio de información entre los laboratorios. Es razonable pensar que los resultados de los dos exámenes no son independientes. Ahora, supongamos que sabemos que el atleta consumió la substancia prohibida, en este caso podemos argumentar que conocer el resultado de la prueba A no cambia la probabilidad de que el atleta salga positivo en la prueba B. Decimos que el resultado de la prueba B es condicionalmente independiente del resultado de la prueba A dado que el atleta consumió la substancia. Sean \\(A\\), \\(B\\) y \\(C\\), tres eventos decimos que \\(A\\) es independiente de \\(B\\) condicional a \\(C\\) (\\(A \\perp B \\vert C\\)) si, \\[ P(A,B\\vert C) = P(A\\vert C)P(B\\vert C)\\] Similar al caso de independencia, \\(A\\) y \\(B\\) son condicionalmente independientes dado \\(C\\) sí y solo sí \\(P(A \\vert B,C) = P(A \\vert C)\\), esto es, una vez que conocemos el valor de \\(C\\), \\(B\\) no proporciona información adicional sobre \\(A\\). Ejemplo. Retomemos el ejercicio de asegurados. En la solución de este ejercicio utilizamos que \\(P(A_2|AA_1) = 0.4\\) y que \\(P(A_2|A^cA_1) = 0.2\\), al establecer esa igualdad estamos asumiendo que \\(A_2\\) (el asegurado tiene un accidente en el año 2) y \\(A_1\\) (el asegurado tiene un accidente en el año 1) son eventos condicionalmente independientes dado \\(A\\) (el asegurado es propenso a accidentes): \\(P(A_2|AA_1) = P(A_2|A) = 0.4\\) y \\(P(A_2|A^cA_1) = P(A_2|A^c) = 0.2\\). En el caso de variables aleatorias definimos independencia condicional como sigue. Sean \\(X\\), \\(Y\\) y \\(Z\\), tres variables aleatorias decimos que \\(X\\) es independiente de \\(Y\\) condicional a \\(Z\\) (\\(X \\perp Y \\vert Z\\)) si y sólo sí, \\[p(x,y\\vert z) = p_{X\\vert Z}(x\\vert z)p_{Y\\vert Z}(y\\vert z).\\] Y tenemos que \\(X\\) es independiente de \\(Y\\) condicional a \\(Z\\) sí y sólo sí, \\(p(x,y,z) \\propto g(x,z)h(y,z)\\). Ejemplo. Supongamos que ruedo un dado, si observo un número par realizo dos lanzamientos de una moneda justa (la probabilidad de observar águila es la misma que la de observar sol), si el dado muestra un número impar realizo dos lanzamientos de una moneda sesgada en la que la probabilidad de observar águila es 0.9. Denotemos por \\(Z\\) la variable aleatoria asociada a la selección de la moneda, \\(X_1\\) la correspondiente al primer lanzamiento y \\(X_2\\) la correspondiente al segundo. Entonces, \\(X_1\\) y \\(X_2\\) no son independientes, sin embargo, son condicionalmente independientes (\\(X_1 \\perp X_2 \\vert Z\\)), puesto que una vez que se que moneda voy a lanzar el resultado del primer lanzamiento no aporta información adicional para el segundo lanzamiento. Calcularemos la distribución conjunta y la distribución condicional de \\(X_2\\) dado \\(X_1\\). La distribución conjunta esta determinada por la siguiente tabla: Z X1 X2 P(Z,X1,X2) justa a a 0.125 justa a s 0.125 justa s a 0.125 justa s s 0.125 ses a a 0.405 ses a s 0.045 ses s a 0.005 ses s s 0.045 La distribución condicional \\(p(X_2|X_1)\\) es, X1/X2 a s . a 0.757 0.243 1 s 0.567 0.433 1 y la distribución condicional \\(p(X_2|X_1,Z)=p(X_2|Z)\\) es, X1/X2 a s . a 0.5 0.5 1 s 0.9 0.1 1 En este punto es claro que \\(X \\perp Y \\vert Z\\) no implica \\(X \\perp Y\\), pues como vimos en el ejemplo de las monedas \\(X_1 \\perp X_2 \\vert Z\\) pero \\(X_1 \\not \\perp X_2\\). Más aún, \\(X \\perp Y\\) tampoco implica \\(X \\perp Y \\vert Z\\). La independencia condicional tiene importantes consecuencias, por ejemplo, si \\(X\\) es independiente de \\(Y\\) dado \\(Z\\) entonces, \\[p(x,y,z) = p_Z(z)p_{X\\vert Z}(x\\vert z)p_{Y\\vert Z}(y\\vert z).\\] Esta expresión de la densidad conjunta es similar a la que obtendríamos usando la regla de la cadena; sin embargo, el número de parámetros necesarios bajo esta representación es menor lo que facilita la estimación. Ejemplo (discusión). Consideremos que nos interesa entender la relación entre 3 variables categóricas cada una con 4 niveles. Para describir la conjunta \\(p(x,y,z)\\) necesitamos \\(63=4 \\cdot 4 \\cdot 4 -1\\) parámetros (menos 1 pues las probabilidades deben sumar uno), pues tenemos que dar una probabiilidad para cada combinación de valores de \\(X,Y,Z\\). También podemos usar la regla del producto para contar: \\[p(x,y,z) = p_Z(z)p_{X\\vert Z}(x\\vert z)p_{Y\\vert X,Z}(y\\vert x,z)\\] Para la marginal de \\(Z\\) requerimos 4-1=3 parámetros, la condiconal de X dado Z requiere 4(4-1)=12 parámetros, finalmente la condicional de \\(Y\\) dada \\(X\\) y \\(Z\\) requiere 4(4)(4-1)=48 parámetros, resultando un total de 3+12+48=63 parámetros. ¿Qué pasa si todas las variables son independientes? Quedamos con un problema mucho más fácil, pues entonces \\[p(x,y,z) = p_Z(z)p_{X}(x)p_{Y}(y)\\] requiere 3 parámetros para \\(p_Z\\), 3 para \\(p_X\\) y 3 para \\(p_Y\\), que dan un total de 9 parámetros (en lugar de 63). Aunque la independencia de todas las variables generalmente no se da, ¿qué pasa por ejemplo si \\(Y\\) y \\(Z\\) son condicionalmente independientes dada \\(X\\)? \\[p(x,y,z) = p_Z(z)p_{X\\vert Z}(x\\vert z)p_{Y\\vert X}(y\\vert x).\\] requiere 3 parámetros para \\(p_Z\\), 4(4-1)=12 para \\(p_{X|Z}\\) y 12 para \\(p_{Y|Z}\\), que dan un total de 27 parámetros (en lugar de 63). En general, podemos construir modelos más parsimoniosos cuando identificamos y explotamos independencias condicionales. Esto incluso puede determinar si un problema es tratable o no. Por ejemplo, si tenemos \\(n\\) variables con \\(r\\) niveles cada una, la conjunta tiene tamaño \\(r^n-1\\). Si \\(n=20\\) y \\(r=4\\) (no tan raro), entonces necesitamos al menos un millón de millones de celdas para definir una conjunta general. Estimar esos parámetros requeriría muestras astronómicas. Por otra parte, si el problema es relativamente ralo en sus dependencias (lo cual sucede en muchos problemas reales), entonces es factible entender, modelar y calcular con la conjunta implícita en un conjunto de distribuciones condicionales que determina la conjunta. "],
["redes-bayesianas.html", "Sección 2 Redes bayesianas", " Sección 2 Redes bayesianas Intoducción: Modelos gráficos Un modelo gráfico es una red de variables aleatorias donde: Nodos representan variables aleatorias. Arcos (dirigidos o no) representan dependencia Los dos esquemas generales para representar dependencias/independiencias (condicionales) de forma gráfica son los modelos dirigidos (redes bayesianas) y no dirigidos (redes markovianas). En este módulo nos enfocaremos en modelos dirigidos veamos un ejemplo de una red de seguros de auto. En este ejemplo nos interesa entender los patrones de dependencia entre variables como edad, calidad de conductor y tipo de accidente: library(bnlearn) #&gt; Error in library(bnlearn): there is no package called &#39;bnlearn&#39; head(insurance) #&gt; Error in head(insurance): objeto &#39;insurance&#39; no encontrado insurance_dat &lt;- insurance[, c(&#39;Age&#39;, &#39;GoodStudent&#39;, &#39;SocioEcon&#39;, &#39;RiskAversion&#39;, &#39;Accident&#39;,&#39;DrivQuality&#39;)] #&gt; Error in eval(expr, envir, enclos): objeto &#39;insurance&#39; no encontrado blacklist &lt;- data.frame(from=c(&#39;DrivQuality&#39;,&#39;Accident&#39;), to=c(&#39;Age&#39;,&#39;DrivQuality&#39;)) Utilizamos una red bayesiana: insurance_gm &lt;- hc(insurance_dat, blacklist = blacklist) #&gt; Error in hc(insurance_dat, blacklist = blacklist): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(insurance_gm) #&gt; Error in graphviz.plot(insurance_gm): no se pudo encontrar la función &quot;graphviz.plot&quot; insurance.fit &lt;- bn.fit(insurance_gm, data = insurance_dat, method = &#39;bayes&#39;, iss = 1) #&gt; Error in bn.fit(insurance_gm, data = insurance_dat, method = &quot;bayes&quot;, : no se pudo encontrar la función &quot;bn.fit&quot; #write.net(file = &#39;./salidas/insurance.net&#39;, insurance.fit) ¿Cómo interpretar esta gráfica? Vemos por ejemplo como mucho de la asociación entre edad y tipo de accidente desaparece cuando condicionamos a calidad de conductor. prop.table(table(insurance$Age, insurance$Accident), margin = 1) #&gt; Error in table(insurance$Age, insurance$Accident): objeto &#39;insurance&#39; no encontrado prop.table(table(insurance$Age, insurance$Accident, insurance$DrivQuality), margin = c(1, 3)) #&gt; Error in table(insurance$Age, insurance$Accident, insurance$DrivQuality): objeto &#39;insurance&#39; no encontrado También podemos entender cómo depende calidad de conductor de edad y aversión al riesgo (modelo local para DrvQuality): prop_tab_q &lt;- prop.table(table(insurance$DrivQuality, insurance$RiskAversion, insurance$Age), c(2, 3)) #&gt; Error in table(insurance$DrivQuality, insurance$RiskAversion, insurance$Age): objeto &#39;insurance&#39; no encontrado prop_tab_q #&gt; Error in eval(expr, envir, enclos): objeto &#39;prop_tab_q&#39; no encontrado df_q &lt;- data.frame(prop_tab_q) #&gt; Error in data.frame(prop_tab_q): objeto &#39;prop_tab_q&#39; no encontrado names(df_q) &lt;- c(&#39;DrvQuality&#39;, &#39;RiskAversion&#39;, &#39;Age&#39;, &#39;Prop&#39;) #&gt; Error in names(df_q) &lt;- c(&quot;DrvQuality&quot;, &quot;RiskAversion&quot;, &quot;Age&quot;, &quot;Prop&quot;): objeto &#39;df_q&#39; no encontrado ggplot(df_q, aes(x = Age, y = Prop, colour = RiskAversion, group = RiskAversion)) + geom_line() + facet_wrap(~DrvQuality) + geom_point() #&gt; Error in ggplot(df_q, aes(x = Age, y = Prop, colour = RiskAversion, group = RiskAversion)): objeto &#39;df_q&#39; no encontrado Otras asociaciones con DrvQuality podemos entenderlas a través de estas dos variables: edad y aversión al riesgo. Veremos cómo modelar estas estructuras (además de usar las tablas, que corresponden a estimación de máxima verosimilitud sin restricciones, podemos usar por ejemplo GLMs). ¿Por qué modelos gráficos? Usando modelos gráficos podemos representar de manera compacta y atractiva distribuciones de probabilidad entre variables aleatorias. Auxiliar en el diseño de modelos. Fácil combinar información proveniente de los datos con conocimiento de expertos. Proveen un marco general para el estudio de modelos más específicos. Muchos de los modelos probabilísticos multivariados clásicos son casos particulares del formalismo general de modelos gráficos (mezclas gaussianas, modelos de espacio de estados ocultos, análisis de factores, filtro de Kalman,…). Juegan un papel importante en el diseño y análisis de algoritmos de aprendizaje máquina. "],
["graficas-dirigidas.html", "2.1 Gráficas dirigidas", " 2.1 Gráficas dirigidas Una gráfica dirigida \\({\\mathcal G}\\) es un conjunto de vértices junto con un subconjunto de aristas dirigidas (pares ordenados de vértices). En nuestro caso, cada vértice corresponde a una variable aleatoria, y cada arista dirigida representa una asociación probabilística entre las variables (vértices) que conecta. Nos interesan en particular las gráficas dirigidas acíclicas (GADs), estas son aquellas que no tienen caminos dirigidos partiendo de un vértice y regresando al mismo (ciclos). Ejemplo. library(igraph) #&gt; Error in library(igraph): there is no package called &#39;igraph&#39; gr &lt;- graph(c(1, 2, 3, 2, 3, 4)) #&gt; Error in graph(c(1, 2, 3, 2, 3, 4)): no se pudo encontrar la función &quot;graph&quot; plot(gr, vertex.label = c(&#39;Dieta&#39;, &#39;Enf. corazón&#39;, &#39;Fuma&#39;, &#39;Tos&#39;), layout = matrix(c(0, 0.5, 2, 0, 4, 0.5, 6, 0), byrow = TRUE, ncol = 2), vertex.size = 23, vertex.color = &#39;salmon&#39;, vertex.label.cex = 1.2, vertex.label.color = &#39;gray40&#39;, vertex.frame.color = NA, asp = 0.5, edge.arrow.size = 1) #&gt; Error in plot(gr, vertex.label = c(&quot;Dieta&quot;, &quot;Enf. corazón&quot;, &quot;Fuma&quot;, &quot;Tos&quot;), : objeto &#39;gr&#39; no encontrado Nos interesan estas gráficas por lo que pueden representar acerca de la estructura de la distribución conjunta de las variables. Recordemos que la distribución conjunta es el modelo completo del fenómeno, a partir de la cual podemos contestar cualquier pregunta de inferencia, asociación, independencia, etc. En las siguientes secciones explicaremos dos enfoques para interpretar una gráfica dirigida probabilísticamente (en términos de la distribición conjunta). Por una parte la gráfica define un esqueleto que sirve para representar de manera compacta una distribución de dimensión alta, esto es: En lugar de codificar la probabilidad de todos los posibles valores de las variables en nuestro dominio, podemos separar la distribución en factores más chicos, cada uno sobre un conjunto de posibilidades mucho más chico. Una vez que definimos los factores podemos definir la distribución conjunta como el producto de los factores. La segunda perspectiva es que la gráfica es una representación compacta de un conjunto de independencias que se sostienen en la distribución (la distribución que codifica nuestras creencias de una situación particular). Probabilidad conjunta y factorizaciones Siempre es posible representar a una distribución conjunta como un producto de condicionales de una sola variable. Dado un ordenamiento \\(X_1,X_2,\\ldots, X_k\\), podemos escribir (por la regla del producto) \\[p(x_1,\\ldots, x_k)=p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)\\cdots p(x_k|x_1,\\ldots, x_{k-1}).\\] Por ejemplo, si tenemos tres variables \\(X_1,X_2,X_3\\) podemos usar la regla del producto para obtener \\[p(x_1,x_2,x_3)= p(x_1)p(x_2|x_1)p(x_3|x_1,x_2),\\] también podemos ordenar las variables de manera distinta y escribir: \\[p(x_1,x_2,x_3)= p(x_3)p(x_1|x_3)p(x_2|x_1,x_3).\\] Estas son representaciones válidas para la conjunta de \\(X_1,X_2,X_3\\). Para modelar \\(X_1,X_2,X_3\\) podríamos entonces estimar primero la marginal de \\(X_3\\), después entender la condicional de \\(X_1\\) dada \\(X_3\\) y finalmente la condicional de \\(X_2\\) dado \\(X_1\\) y \\(X_3\\). Algunas representaciones son más fáciles para trabajar, calcular y entender que otras. Ejemplo. Si sacamos sucesivamente tres cartas de una baraja y registramos si son rojas o negras, lo más fácil es definir \\(X_i\\) = color de la \\(i\\)-ésima carta, y entonces si buscamos calcular \\[p(X_1=roja, X_2=roja, X_3=negra),\\] simplemente calculamos: \\[P(X_1=roja)=26/52, P(X_2=roja|X_1=roja)=25/51\\] y finalmente \\[P(X_3=negra|X_1=roja,X_2=roja)=25/50,\\] de modo que la probabilidad que nos interesa es \\[\\frac{26\\cdot 25\\cdot 26}{52\\cdot 51\\cdot 50}.\\] Otro caso en que la factorización que escogemos es importante, es cuando existen independencias condicionales, la factorización puede resultar en un modelo más compacto o más conveniente. Ejemplo. Si \\(X_2\\) y \\(X_3\\) son independentes y \\(X_2\\) es condicionalmente independiente de \\(X_1\\) dado \\(X_3\\), podemos comenzar con la segunda factorización \\[p(x_1,x_2,x_3)= p(x_3)p(x_1)p(x_2|x_1,x_3),\\] y finalmente \\[p(x_1,x_2,x_3)=p(x_3)p(x_1)p(x_2|x_3)\\] el cual es un modelo considerablemente más simple que el original pues incluye dos marginales y sólo es necesario modelar cómo depende \\(x_2\\) de \\(x_3\\). Esto lo expresamos en el siguiente resultado: Una factorización de la conjunta puede ser entendida como una parametrización particular de la conjunta a través de sus distribuciones condicionales. Ejemplo. Supongamos la factorización \\(p(x,y)=p(x)p(y|x)\\), y que \\(x\\) y \\(y\\) son variables binarias que toman los valores \\(0\\) y \\(1\\). La parametrización usual para \\(p(x,y)\\) está dada por \\(p_{00},p_{01},p_{10},p_{11}\\) donde \\(p(x,y)=p_{xy}\\) y \\(p_{00} +p_{01}+p_{10}+p_{11}=1\\) (3 parámetros en total). De esta forma tenemos que especificar, por ejemplo, los parámetros \\(p_{00},p_{01},p_{10}\\). Por otra parte, la factorización sugiere los parámetros \\(p_0,p_{0|1},p_{0|0},\\) donde \\(p_0=p(x=0)\\), \\(p_{0|1}=p(y=0|x=1)\\) y \\(p_{0|0}=p(y=0|x=1)\\). Los otros parámetros están dados por \\(p_1=1-p_0\\), \\(p_{1|0}=1-p_{0|0}\\) y \\(p_{1|1}=1-p_{0|1}\\). Nótese que la idea general es Usar la regla de la cadena, lo que siempre nos da una expresión válida para la conjunta, y en la cual aparece la condicional de cada variable una sola vez para una ordenamiento adecuado de las variables. Simplificar la expresión obtenida usando las independencias condicionales que suponemos. Hacer los cálculos/inferencia, etc. usando la parametrización de condicionales. 2.1.1 Factorizaciones de la conjunta y gráficas dirigidas. #&gt; Error in graph(c(1, 3, 2, 3, 2, 4, 3, 5)): no se pudo encontrar la función &quot;graph&quot; #&gt; Error in plot(gr, vertex.label = c(&quot;Dificultad&quot;, &quot;Inteligencia&quot;, &quot;Calificación&quot;, : objeto &#39;gr&#39; no encontrado ¿Qué factorización crees que es apropiada para la distribución conjunta \\(p(d, i, c, g, r)\\)? \\(p(d)p(i)p(c|i)p(c|d)\\) \\(p(d)p(i)p(c|i,d)p(g|i)p(r|c)\\) \\(p(d)p(i)p(c)p(g)p(r)\\) \\(p(d|c)p(i|c,g)p(c|r)p(g)p(r)\\) Ninguna de las anteriores. En primer lugar, las _gráficas dirigidas acíclicas asociadas a una distribución conjunta dan una factorización particular \\(p\\) para la conjunta. Sea \\({\\mathcal G}\\) una gráfica dirigida con vértices \\(X_1,X_2,...,X_k\\), denotamos por \\(Pa(x_i)\\) a todos los padres de \\(X_i\\) en \\({\\mathcal G}\\). Sea \\(p\\) una distribución conjunta para \\(X_1,X_2,\\ldots, X_k\\). Decimos que \\({\\mathcal G}\\) representa a \\(p\\) cuando la conjunta se factoriza como \\[p(x_1,x_2,\\ldots, x_n)=\\prod_{i=1}^k p(x_i|Pa(x_i)).\\] El conjunto de distribuciones que son representadas por \\({\\mathcal G}\\) lo denotamos por \\(M({\\mathcal G})\\) (llamadas distribuciones markovianas con respecto a \\(\\mathcal G\\)). Nótese que una gráfica acíclica no dirigida (GAD) no establece una distribución particular, sino un conjunto de posibles distribuciones: todas las distribuciones que se factorizan bajo \\({\\mathcal G}\\). Nota. La factorización del lado derecho del resultado \\[p(x_1,x_2,\\ldots, x_n)=\\prod_{i=1}^k p(x_i|Pa(x_i))\\] siempre es una distribución de probabilidad. Por ejemplo, si consideramos la siguiente factorización de \\(p(x,u,d,f,e,y,t)\\): \\[p(x)p(u)p(d)p(f|d)p(e|f)p(y|f)p(t|d,u).\\] Veremos que es una distribución de probabilidad como sigue: en primer lugar, este producto es no negativo, pues todas son distribuciones condicionales. Basta demostrar que si sumamos sobre todos los posibles valores de \\(x,u,d,f,e,y,t\\), entonces esta expresión suma 1: \\[\\sum_{x,u,d,f,e,y,t}p(x)p(u)p(d)p(f|d)p(e|f)p(y|f)p(t|d,u) \\] \\[\\left (\\sum_{u,d,f,e,y,t}p(u)p(d)p(f|d)p(y|f)p(t|d,u)\\right)\\left(\\sum_{x}p(x)\\right) \\] \\[\\sum_{u,d,f,t}\\left \\{ p(u)p(d)p(f|d)p(t|d,u)\\sum_y p(y|f)\\sum_e p(e|f) \\right\\}\\] \\[\\sum_{u,d,f,t}p(u)p(d)p(f|d)p(t|d,u)\\] \\[\\sum_{u,d,t}\\left \\{ p(u)p(d)p(t|d,u)\\sum_f p(f|d)\\right \\}\\] \\[\\sum_{u,d,t}p(u)p(d)p(t|d,u)\\] \\[\\sum_{u,d}p(u)p(d)\\] \\[\\sum_{d}p(d)\\sum_u p(u)=1\\] Discusión. Ordenamiento topológico de vértices en un gráfica dirigida acíclica. En este último ejemplo vimos que el cálculo de la suma total se hace empujando primero dentro de la suma los índices de las variables que no tienen descendientes (o que no aparecen como condicionadoras), y trabajando hacia arriba. En términos de la gráfica, trabajamos de los últimos vértices hasta los primeros. De hecho, una GAD siempre da un ordenamiento (topológico) de los vértices, módulo variables que están al mismo nivel. Por ejemplo, en la gráfica de la figura anterior, los ordenamientos son \\(D,I,C,G,R\\) o \\(I,D,C,G,R\\). ¿Qué ordenamiento da la siguiente gráfica? gr &lt;- graph(c(1, 2, 1, 3, 3, 2, 2, 4)) #&gt; Error in graph(c(1, 2, 1, 3, 3, 2, 2, 4)): no se pudo encontrar la función &quot;graph&quot; plot(gr, vertex.label=c(&#39;X&#39;,&#39;Y&#39;,&#39;Z&#39;,&#39;W&#39;), layout = matrix(c(0, 0.5, 0.5, 0, 0, -0.5, 1, 0), byrow = TRUE, ncol = 2), vertex.size = 20, vertex.color = &#39;salmon&#39;, vertex.label.cex = 1.2, vertex.label.color = &#39;gray40&#39;, vertex.frame.color = NA, asp = 0.5, edge.arrow.size = 1) #&gt; Error in plot(gr, vertex.label = c(&quot;X&quot;, &quot;Y&quot;, &quot;Z&quot;, &quot;W&quot;), layout = matrix(c(0, : objeto &#39;gr&#39; no encontrado Ejemplo: Gráficas cíclicas. Cuando hay ciclos en una gráfica, no hay una manera clara de entender qué factorización produce. Por ejemplo, si tenemos tres variables \\(X\\), \\(Y\\),\\(Z\\) asociados con un ciclo \\(X\\rightarrow Y\\rightarrow Z\\rightarrow X\\), esto quizá sugiere una factorización \\(p(y|x)p(z|y)p(x|z)\\). Pero se puede ver que esta expresión en general no es una distribución de probabilidad. library(dplyr) # x: inteligencia, y: examen, z: trabajo # y|x mar_1 &lt;- expand.grid(x = c(&quot;i_0&quot;, &quot;i_1&quot;), y = c(&quot;e_0&quot;, &quot;e_1&quot;)) mar_1$p1 &lt;- c(0.95, 0.2, 0.05, 0.8) # z|y mar_2 &lt;- expand.grid(y = c(&quot;e_0&quot;, &quot;e_1&quot;), z = c(&quot;t_0&quot;, &quot;t_1&quot;)) mar_2$p2 &lt;- c(0.8, 0.4, 0.2, 0.6) # x|z mar_3 &lt;- expand.grid(z = c(&quot;t_0&quot;, &quot;t_1&quot;), x = c(&quot;i_0&quot;, &quot;i_1&quot;)) mar_3$p3 &lt;- c(0.8, 0.4, 0.2, 0.6) tab_1 &lt;- inner_join(mar_1, mar_2) #&gt; Joining, by = &quot;y&quot; tab_2 &lt;- inner_join(tab_1, mar_3) #&gt; Joining, by = c(&quot;x&quot;, &quot;z&quot;) tab_2$p &lt;- tab_2$p1 * tab_2$p2 * tab_2$p3 sum(tab_2$p) #&gt; [1] 1.12 En el ejemplo anterior vemos que \\(p(y|x)p(z|y)p(x|z)\\) no suma uno. Por otra parte \\(p(x)p(y|x)p(z|y,x)\\) si suma uno: # x: inteligencia, y: examen, z: trabajo # x mar_1 &lt;- data.frame(x = c(&quot;i_0&quot;, &quot;i_1&quot;), p1 = c(0.6, 0.4)) # y|x mar_2 &lt;- expand.grid(x = c(&quot;i_0&quot;, &quot;i_1&quot;), y = c(&quot;e_0&quot;, &quot;e_1&quot;)) mar_2$p2 &lt;- c(0.95, 0.2, 0.05, 0.8) # z|x,y mar_3 &lt;- expand.grid(y = c(&quot;e_0&quot;, &quot;e_1&quot;), x = c(&quot;i_0&quot;, &quot;i_1&quot;), z = c(&quot;t_0&quot;, &quot;t_1&quot;)) mar_3$p3 &lt;- c(0.8, 0.6, 0.5, 0.1, 0.2, 0.4, 0.5, 0.9) tab_1 &lt;- inner_join(mar_1, mar_2) #&gt; Joining, by = &quot;x&quot; tab_2 &lt;- inner_join(tab_1, mar_3) #&gt; Joining, by = c(&quot;x&quot;, &quot;y&quot;) tab_2$p &lt;- tab_2$p1 * tab_2$p2 * tab_2$p3 sum(tab_2$p) #&gt; [1] 1 2.1.2 Redes bayesianas Ahora podemos definir red bayesiana: Una red bayesiana es una gráfica GAD \\({\\mathcal G}\\) junto con una distribución de probabilidad particular que se factoriza sobre \\(G\\). Dado que \\(p\\) se factoriza sobre \\(\\mathcal G\\), podemos usar la factorización para evitar dar explícitamente la conjunta sobre todas las posibles combinaciones de las variables. Es decir, podemos usar la parametrización dada por la factorización en condicionales. Ejemplo. Sea \\({\\mathcal G}\\) la siguiente gráfica library(igraph) #&gt; Error in library(igraph): there is no package called &#39;igraph&#39; gr &lt;- graph( c(1,2,3,2,2,4) ) #&gt; Error in graph(c(1, 2, 3, 2, 2, 4)): no se pudo encontrar la función &quot;graph&quot; plot(gr, vertex.label=c(&#39;llueve&#39;, &#39;mojado&#39;, &#39;regar&#39;, &#39;piso&#39;), layout = matrix(c(0, 1, 1, 0, 0, -1, 2, 0), byrow = TRUE, ncol = 2), vertex.size = 20, vertex.color = &#39;salmon&#39;, vertex.label.cex = 1.2, vertex.label.color = &#39;gray40&#39;, vertex.frame.color = NA, asp = 0.5, edge.arrow.size = 1) #&gt; Error in plot(gr, vertex.label = c(&quot;llueve&quot;, &quot;mojado&quot;, &quot;regar&quot;, &quot;piso&quot;), : objeto &#39;gr&#39; no encontrado La conjunta \\(p(m,l,r,z)\\) (\\(z\\) es piso resbaloso) se factoriza como \\[p(l)p(r)p(m|l,r)p(z|m)\\] En este ejemplo construiremos la red como si fuéramos los expertos. Esta es una manera de construir redes que ha resultado útil y exitosa en varias áreas (por ejemplo diagnóstico). De forma que podemos construir una red bayesiana simplemente dando los valores de cada factor. En nuestro ejemplo, empezamos por las marginales de \\(l\\) y \\(r\\): llueve &lt;- c(&#39;No&#39;, &#39;Sí&#39;) p_llueve &lt;- data.frame(llueve = factor(llueve, levels= c(&quot;No&quot;, &quot;Sí&quot;)), prob_l = c(0.9, 0.1)) p_llueve #&gt; llueve prob_l #&gt; 1 No 0.9 #&gt; 2 Sí 0.1 regar &lt;- c(&#39;Apagado&#39;, &#39;Prendido&#39;) p_regar &lt;- data.frame(regar = factor(regar, levels = c(&#39;Apagado&#39;, &#39;Prendido&#39;)), prob_r = c(0.7, 0.3)) p_regar #&gt; regar prob_r #&gt; 1 Apagado 0.7 #&gt; 2 Prendido 0.3 Ahora establecemos la condicional de mojado dado lluvia y regar: mojado &lt;- c(&#39;Mojado&#39;,&#39;Seco&#39;) # los niveles son todas las combinaciones de los valores de las variables niveles &lt;- expand.grid(llueve = llueve, regar = regar, mojado = mojado) # mojado|lluve,regar p_mojado_lr &lt;- data.frame(niveles, prob_m = NA) p_mojado_lr$prob_m[1:4] &lt;- c(0.02, 0.6, 0.7, 0.9) p_mojado_lr$prob_m[5:8]&lt;- 1 - p_mojado_lr$prob_m[1:4] p_mojado_lr #&gt; llueve regar mojado prob_m #&gt; 1 No Apagado Mojado 0.02 #&gt; 2 Sí Apagado Mojado 0.60 #&gt; 3 No Prendido Mojado 0.70 #&gt; 4 Sí Prendido Mojado 0.90 #&gt; 5 No Apagado Seco 0.98 #&gt; 6 Sí Apagado Seco 0.40 #&gt; 7 No Prendido Seco 0.30 #&gt; 8 Sí Prendido Seco 0.10 Y finalmente la condicional de piso resbaloso dado piso mojado: p_piso_mojado &lt;- data.frame(expand.grid( piso = c(&#39;Muy.resbaladizo&#39;, &#39;Resbaladizo&#39;, &#39;Normal&#39;), mojado=c(&#39;Mojado&#39;,&#39;Seco&#39;))) p_piso_mojado #&gt; piso mojado #&gt; 1 Muy.resbaladizo Mojado #&gt; 2 Resbaladizo Mojado #&gt; 3 Normal Mojado #&gt; 4 Muy.resbaladizo Seco #&gt; 5 Resbaladizo Seco #&gt; 6 Normal Seco p_piso_mojado$prob_p &lt;- c(0.3, 0.6, 0.1, 0.02, 0.3, 0.68) p_piso_mojado #&gt; piso mojado prob_p #&gt; 1 Muy.resbaladizo Mojado 0.30 #&gt; 2 Resbaladizo Mojado 0.60 #&gt; 3 Normal Mojado 0.10 #&gt; 4 Muy.resbaladizo Seco 0.02 #&gt; 5 Resbaladizo Seco 0.30 #&gt; 6 Normal Seco 0.68 Con esta información podemos calcular la conjunta. En este caso, como el problema es relativamente chico, podemos hacerlo explícitamente para todos los niveles: library(dplyr) p_1 &lt;- inner_join(p_piso_mojado, p_mojado_lr) #&gt; Joining, by = &quot;mojado&quot; p_2 &lt;- inner_join(p_1, p_llueve) #&gt; Joining, by = &quot;llueve&quot; p_conj &lt;- inner_join(p_2, p_regar) #&gt; Joining, by = &quot;regar&quot; p_conj$prob &lt;- p_conj$prob_p * p_conj$prob_m * p_conj$prob_l * p_conj$prob_r p_conj #&gt; piso mojado prob_p llueve regar prob_m prob_l prob_r #&gt; 1 Muy.resbaladizo Mojado 0.30 No Apagado 0.02 0.9 0.7 #&gt; 2 Muy.resbaladizo Mojado 0.30 Sí Apagado 0.60 0.1 0.7 #&gt; 3 Muy.resbaladizo Mojado 0.30 No Prendido 0.70 0.9 0.3 #&gt; 4 Muy.resbaladizo Mojado 0.30 Sí Prendido 0.90 0.1 0.3 #&gt; 5 Resbaladizo Mojado 0.60 No Apagado 0.02 0.9 0.7 #&gt; 6 Resbaladizo Mojado 0.60 Sí Apagado 0.60 0.1 0.7 #&gt; 7 Resbaladizo Mojado 0.60 No Prendido 0.70 0.9 0.3 #&gt; 8 Resbaladizo Mojado 0.60 Sí Prendido 0.90 0.1 0.3 #&gt; 9 Normal Mojado 0.10 No Apagado 0.02 0.9 0.7 #&gt; 10 Normal Mojado 0.10 Sí Apagado 0.60 0.1 0.7 #&gt; 11 Normal Mojado 0.10 No Prendido 0.70 0.9 0.3 #&gt; 12 Normal Mojado 0.10 Sí Prendido 0.90 0.1 0.3 #&gt; 13 Muy.resbaladizo Seco 0.02 No Apagado 0.98 0.9 0.7 #&gt; 14 Muy.resbaladizo Seco 0.02 Sí Apagado 0.40 0.1 0.7 #&gt; 15 Muy.resbaladizo Seco 0.02 No Prendido 0.30 0.9 0.3 #&gt; 16 Muy.resbaladizo Seco 0.02 Sí Prendido 0.10 0.1 0.3 #&gt; 17 Resbaladizo Seco 0.30 No Apagado 0.98 0.9 0.7 #&gt; 18 Resbaladizo Seco 0.30 Sí Apagado 0.40 0.1 0.7 #&gt; 19 Resbaladizo Seco 0.30 No Prendido 0.30 0.9 0.3 #&gt; 20 Resbaladizo Seco 0.30 Sí Prendido 0.10 0.1 0.3 #&gt; 21 Normal Seco 0.68 No Apagado 0.98 0.9 0.7 #&gt; 22 Normal Seco 0.68 Sí Apagado 0.40 0.1 0.7 #&gt; 23 Normal Seco 0.68 No Prendido 0.30 0.9 0.3 #&gt; 24 Normal Seco 0.68 Sí Prendido 0.10 0.1 0.3 #&gt; prob #&gt; 1 0.00378 #&gt; 2 0.01260 #&gt; 3 0.05670 #&gt; 4 0.00810 #&gt; 5 0.00756 #&gt; 6 0.02520 #&gt; 7 0.11340 #&gt; 8 0.01620 #&gt; 9 0.00126 #&gt; 10 0.00420 #&gt; 11 0.01890 #&gt; 12 0.00270 #&gt; 13 0.01235 #&gt; 14 0.00056 #&gt; 15 0.00162 #&gt; 16 0.00006 #&gt; 17 0.18522 #&gt; 18 0.00840 #&gt; 19 0.02430 #&gt; 20 0.00090 #&gt; 21 0.41983 #&gt; 22 0.01904 #&gt; 23 0.05508 #&gt; 24 0.00204 sum(p_conj$prob) #&gt; [1] 1 Usamos el paquete bnlearn para construir el objeto que corresponde a esta red bayesiana: library(bnlearn) #&gt; Error in library(bnlearn): there is no package called &#39;bnlearn&#39; # nodos graf_jardin &lt;- empty.graph(c(&#39;llueve&#39;, &#39;regar&#39;, &#39;mojado&#39;, &#39;piso&#39;)) #&gt; Error in empty.graph(c(&quot;llueve&quot;, &quot;regar&quot;, &quot;mojado&quot;, &quot;piso&quot;)): no se pudo encontrar la función &quot;empty.graph&quot; # arcos arcs(graf_jardin) &lt;- matrix(c(&#39;llueve&#39;, &#39;mojado&#39;, &#39;regar&#39;, &#39;mojado&#39;, &#39;mojado&#39;, &#39;piso&#39;), ncol = 2, byrow = T) #&gt; Error in arcs(graf_jardin) &lt;- matrix(c(&quot;llueve&quot;, &quot;mojado&quot;, &quot;regar&quot;, &quot;mojado&quot;, : objeto &#39;graf_jardin&#39; no encontrado node.ordering(graf_jardin) #&gt; Error in node.ordering(graf_jardin): no se pudo encontrar la función &quot;node.ordering&quot; plot(graf_jardin) #&gt; Error in plot(graf_jardin): objeto &#39;graf_jardin&#39; no encontrado modelo_jardin &lt;- bn.fit(graf_jardin, data = data.frame(p_conj[, c(&#39;llueve&#39;, &#39;regar&#39;, &#39;mojado&#39;, &#39;piso&#39;)])) #&gt; Error in bn.fit(graf_jardin, data = data.frame(p_conj[, c(&quot;llueve&quot;, &quot;regar&quot;, : no se pudo encontrar la función &quot;bn.fit&quot; Y este es el objeto que representa nuestra red (aunque falta corregir las probabilidades): str(modelo_jardin) #&gt; Error in str(modelo_jardin): objeto &#39;modelo_jardin&#39; no encontrado Ahora pondremos las probabilidades condicionales correctas (también llamados modelos locales): tab_1 &lt;- table(p_conj$llueve) tab_1[c(1, 2)] &lt;- p_llueve[, 2] tab_1 #&gt; #&gt; No Sí #&gt; 0.9 0.1 modelo_jardin$llueve &lt;- tab_1 #&gt; Error in modelo_jardin$llueve &lt;- tab_1: objeto &#39;modelo_jardin&#39; no encontrado tab_2 &lt;- table(p_conj$regar) tab_2[c(1,2)] &lt;- p_regar[,2] tab_2 #&gt; #&gt; Apagado Prendido #&gt; 0.7 0.3 modelo_jardin$regar &lt;- tab_2 #&gt; Error in modelo_jardin$regar &lt;- tab_2: objeto &#39;modelo_jardin&#39; no encontrado tab_3 &lt;- xtabs(prob_m ~ mojado + llueve + regar, data = p_mojado_lr) tab_3 #&gt; , , regar = Apagado #&gt; #&gt; llueve #&gt; mojado No Sí #&gt; Mojado 0.02 0.60 #&gt; Seco 0.98 0.40 #&gt; #&gt; , , regar = Prendido #&gt; #&gt; llueve #&gt; mojado No Sí #&gt; Mojado 0.70 0.90 #&gt; Seco 0.30 0.10 modelo_jardin$mojado &lt;- tab_3 #&gt; Error in modelo_jardin$mojado &lt;- tab_3: objeto &#39;modelo_jardin&#39; no encontrado tab_4 &lt;- xtabs(prob_p ~ piso + mojado, data = p_piso_mojado) tab_4 #&gt; mojado #&gt; piso Mojado Seco #&gt; Muy.resbaladizo 0.30 0.02 #&gt; Resbaladizo 0.60 0.30 #&gt; Normal 0.10 0.68 modelo_jardin$piso &lt;- tab_4 #&gt; Error in modelo_jardin$piso &lt;- tab_4: objeto &#39;modelo_jardin&#39; no encontrado modelo_jardin #&gt; Error in eval(expr, envir, enclos): objeto &#39;modelo_jardin&#39; no encontrado Finalmente, para hacer inferencia en la red (es decir, calcular probabilidades dado cierto conocimiento), necesitamos usar un algoritmo eficiente (por ejemplo en SAMIAM. Aquí usamos el paquete gRain. Los query que hacemos son la inferencia, pero también se llaman así en la literatura de modelos gráficos. En este caso, podemos examinar las marginales condicionales a toda la evidencia (información) que tenemos. Por ejemplo, ¿cómo se ven las marginales cuando sabemos que el piso está muy resbaladizo? library(gRain) #&gt; Error in library(gRain): there is no package called &#39;gRain&#39; comp_jardin &lt;- compile(as.grain(modelo_jardin)) #&gt; Error in compile(as.grain(modelo_jardin)): no se pudo encontrar la función &quot;compile&quot; querygrain(comp_jardin) #&gt; Error in querygrain(comp_jardin): no se pudo encontrar la función &quot;querygrain&quot; query_1 &lt;- setEvidence(comp_jardin, nodes = c(&#39;piso&#39;), states = c(&#39;Muy.resbaladizo&#39;)) #&gt; Error in setEvidence(comp_jardin, nodes = c(&quot;piso&quot;), states = c(&quot;Muy.resbaladizo&quot;)): no se pudo encontrar la función &quot;setEvidence&quot; querygrain(query_1) #&gt; Error in querygrain(query_1): no se pudo encontrar la función &quot;querygrain&quot; Podemos ver que llueve y mojado son independientes (sin condicionar). query_2 &lt;- setEvidence(comp_jardin, nodes = c(&#39;llueve&#39;), states = c(&#39;Sí&#39;)) #&gt; Error in setEvidence(comp_jardin, nodes = c(&quot;llueve&quot;), states = c(&quot;Sí&quot;)): no se pudo encontrar la función &quot;setEvidence&quot; querygrain(query_2)$regar #&gt; Error in querygrain(query_2): no se pudo encontrar la función &quot;querygrain&quot; query_3 &lt;- setEvidence(comp_jardin, nodes = c(&#39;llueve&#39;), states = c(&#39;No&#39;)) #&gt; Error in setEvidence(comp_jardin, nodes = c(&quot;llueve&quot;), states = c(&quot;No&quot;)): no se pudo encontrar la función &quot;setEvidence&quot; querygrain(query_2)$regar #&gt; Error in querygrain(query_2): no se pudo encontrar la función &quot;querygrain&quot; Y ahora vemos la dependencia entre llueve y regar si condicionamos a piso resbaladizo: query_4 &lt;- setEvidence(comp_jardin, nodes = c(&#39;piso&#39;, &#39;regar&#39;), states = c(&#39;Muy.resbaladizo&#39;, &#39;Apagado&#39;)) #&gt; Error in setEvidence(comp_jardin, nodes = c(&quot;piso&quot;, &quot;regar&quot;), states = c(&quot;Muy.resbaladizo&quot;, : no se pudo encontrar la función &quot;setEvidence&quot; querygrain(query_4)$llueve #&gt; Error in querygrain(query_4): no se pudo encontrar la función &quot;querygrain&quot; query_5 &lt;- setEvidence(comp_jardin, nodes=c(&#39;piso&#39;, &#39;regar&#39;), states = c(&#39;Muy.resbaladizo&#39;,&#39;Prendido&#39;)) #&gt; Error in setEvidence(comp_jardin, nodes = c(&quot;piso&quot;, &quot;regar&quot;), states = c(&quot;Muy.resbaladizo&quot;, : no se pudo encontrar la función &quot;setEvidence&quot; querygrain(query_5)$llueve #&gt; Error in querygrain(query_5): no se pudo encontrar la función &quot;querygrain&quot; Construir esta red en samaiam, y repetir los queries. 2.1.3 Independencia condicional y redes bayesianas Ahora abordamos el segundo enfoque de las redes bayesianas. En este, leemos directamente independencias condicionales a partir de la estructura de la gráfica (es esencialmente equivalente al criterio de factorización). Independencias condicionales locales Una distribución de probabilidad \\(p\\in M({\\mathcal G})\\) (es decir, se factoriza en \\(\\mathcal G\\)) si y sólo si para toda variable \\(W\\), \\(W\\) es condicionalmente independiente de cualquier variable que no sea su padre o descendiente dados los padres \\(Pa(W)\\). Es decir \\[W \\bot Z|Pa(W)\\] para cualquier \\(Z\\) que no sea descendiente o padre de \\(W\\). Otra manera de decir esto es que dados los padres, un nodo sólo puede transmitir información probabilística a sus descendientes y a ningún otro nodo. Por ejemplo, en la siguiente gráfica, el nodo rojo, dado los nodos azules, es condicionalmente independiente de los nodos grises: gr &lt;- graph(c(1, 4, 2, 5, 3, 5, 4, 6, 5, 6, 7, 8, 6, 8, 8, 9, 8, 10)) #&gt; Error in graph(c(1, 4, 2, 5, 3, 5, 4, 6, 5, 6, 7, 8, 6, 8, 8, 9, 8, 10)): no se pudo encontrar la función &quot;graph&quot; plot(gr, vertex.size = 20, vertex.color=c(rep(&#39;gray80&#39;, 3), rep(&#39;blue&#39;, 2), &#39;red&#39;, &#39;gray80&#39;, &#39;salmon&#39;, &#39;salmon&#39;, &#39;salmon&#39;), vertex.label.cex = 1.2, vertex.label.color = &#39;gray50&#39;, vertex.frame.color = NA, asp = 0.7, edge.arrow.size = 1) #&gt; Error in plot(gr, vertex.size = 20, vertex.color = c(rep(&quot;gray80&quot;, 3), : objeto &#39;gr&#39; no encontrado 2.1.3.1 Discusión de demostración. Supongamos que las independencias locales se satisfacen según el enunciado anterior. Si tomamos las variables según el orden topológico de \\(\\mathcal G\\), dado por \\(X_1,\\ldots, X_k\\), entonces por la regla del producto: \\[p(x)=\\prod_{i=1}^k p(x_i|x_1,\\ldots, x_{i-1}).\\] Ahora, nótese que 1) para cada \\(X_i\\), ninguna de las variables \\(X_1,\\ldots, X_{i-1}\\) es descendiente de \\(X_i\\) y 2) que \\(Pa(X_i)\\) está contenido en \\(X_1,\\ldots, X_{i-1}\\). Por lo tanto, por el supuesto de las independencias locales, vemos que \\[p(x_i|x_1,\\ldots, x_{i-1})=p(x_i|Pa(x_i)),\\] y así hemos demostrado que \\(p\\) se factoriza en \\(\\mathcal G\\). El otro sentido de la demostración es más difícil, veamos un ejemplo. En la siguiente gráfica, describimos una factorización para la conjunta de varias variables: inteligencia de un alumno, dificultad del curso, calificación obtenida en el curso, calificación obtenida en el examen GRE y si el alumno recibe o no una carta de recomendación de su profesor: library(igraph) #&gt; Error in library(igraph): there is no package called &#39;igraph&#39; gr &lt;- graph( c(1,3,2,3,2,4,3,5) ) #&gt; Error in graph(c(1, 3, 2, 3, 2, 4, 3, 5)): no se pudo encontrar la función &quot;graph&quot; plot(gr, vertex.label=c(&#39;Dificultad&#39;,&#39;Inteligencia&#39;,&#39;Calificación&#39;,&#39;GRE&#39;, &#39;Recomendación&#39;), layout = matrix(c(-1,2,1,2,0,1,2,1,0,0), byrow = TRUE, ncol = 2), vertex.size = 20, vertex.color = &#39;salmon&#39;, vertex.label.cex = 1.2, vertex.label.color = &#39;gray40&#39;, vertex.frame.color = NA, asp = 0.5, edge.arrow.size = 1) #&gt; Error in plot(gr, vertex.label = c(&quot;Dificultad&quot;, &quot;Inteligencia&quot;, &quot;Calificación&quot;, : objeto &#39;gr&#39; no encontrado La conjunta se factoriza como \\[p(i,d,c,g,r)=p(i)p(d)p(c|d,i)p(g|i)p(r|c).\\] Queremos demostrar que dada la inteligencia, la calificación del GRE es condicionalmente independiente del resto de las variables (pues el resto no son ni padres ni descendientes de GRE), es decir, busamos demostrar que \\[p(g|i,d,c,r)=p(g|i).\\] Comenzamos por la factorización de arriba: \\[p(i,d,c,g,r)=p(i)p(d)p(c|d,i)p(g|i)p(r|c).\\] Necesitamos calcular \\[p(g|i,d,c,r)=\\frac{p(g,i,d,c,r)}{p(i,d,c,r)}.\\] Así que comenzamos con la factorización y sumamos sobre \\(s\\) para obtener \\[p(i,d,c,r)=\\sum_g p(i)p(d)p(c|d,i)p(g|i)p(r|c),\\] \\[p(i,d,c,r)=p(i)p(d)p(c|d,i)p(r|c),\\] y dividiendo obtenemos que \\[p(g|i,d,c,r)=p(g|i),\\] que era lo que queríamos demostrar. De acuerdo a la gráfica, la calificación en el GRE es independiente de la dificultad una vez que conocemos la inteligencia, es decir \\(p(g | i, d) = p(g | i)\\), veamos la factorización. Usando el teorema de Bayes podemos calcular la densidad condicional como, \\[p(g|i,d) = \\frac{p(g,i,d)}{p(i,d)}\\] Ahora, comencemos calculando la densidad marginal \\(p(g,i,d)\\): \\[\\begin{align} \\nonumber p(g,i,d) &amp;= \\sum_c \\sum_r p(i,d,c,r) \\nonumber &amp;= \\sum_c \\sum_r p(i)p(d)p(c|d,i)p(g|i)p(r|c) \\nonumber &amp;= \\sum_c p(i)p(d)p(c|d,i)p(g|i)\\sum_r p(r|c) \\nonumber &amp;= p(i)p(d)p(g|i) \\sum_c p(c|d,i) \\nonumber &amp;= p(i)p(d)p(g|i) \\end{align}\\] Calculemos ahora el denominador en la regla de Bayes, \\[\\begin{align} \\nonumber p(i,d) &amp;= \\sum_g p(g,i,d) \\nonumber &amp;= \\sum_g p(i)p(d)p(g|i) \\nonumber &amp;= p(i)p(d)\\sum_g p(g|i) \\nonumber &amp;= p(i)p(d) \\mbox{ (inteligencia y dificultad son indep.)} \\end{align}\\] Por lo tanto, la densidad condicional es \\[p(g|i,d) = \\frac{p(g,i,d)}{p(i,d)} = \\frac{p(i)p(d)p(g|i)}{p(i)p(d)} = p(g|i),\\] esto es, la calificación es independiente de la dificultad condicional a la inteligencia del alumno. Repetir para \\(p(c|d,i)\\). Este último resultado explica cuáles son las independencias condicionales necesarias y suficientes para que una distribución se factorice según la gráfica \\({\\mathcal G}\\). Ahora la pregunta que queremos resolver es: ¿hay otras independencias condicionales representadas en la gráfica? Buscamos independencias condicionales no locales. La respuesta es sí, pero necesitamos conceptos adicionales a los que hemos visto hasta ahora (d-separación). Ejemplo. Antes de continuar, podemos ver un ejemplo de independencias no locales implicadas por la estructura gráfica. Si tenemos: \\[X \\rightarrow Y \\rightarrow Z \\rightarrow W\\] es fácil ver que \\(X\\) es independiente de \\(W\\), dada \\(Y\\), aunque esta independencia no es de la forma del resultado anterior, pues no estamos condicionando a los padres de ningún vértice. 2.1.4 Flujo de información probabilística En esta parte entenderemos primero como se comunica localmente la información probabilística a lo largo de los nodos cuando tenemos información acerca de alguno de ellos. Utilizaremos las factorizaciones implicadas por las gráficas asociadas. ¿En cuáles de los siguientes casos información sobre \\(X\\) puede potencialmente cambiar la distribución sobre \\(Y\\)? Razonamiento causal: \\(X\\rightarrow Z \\rightarrow Y\\) Si no tenemos información acerca de \\(Z\\), \\(X\\) y \\(Y\\) pueden estar asociadas. En este caso tenemos \\(p(x,y,z)=p(x)p(z|x)p(y|z)\\), de forma que, haciendo un cálculo simple: \\[p(x,y)= p(x) \\sum_z p(y|z)p(z|x).\\] Como siempre es cierto que \\(p(x,y)=p(x)p(y|x)\\), tenemos \\[p(y|x)=\\sum_z p(y|z)p(z|x),\\] donde vemos que cuando cambia \\(x\\), puede cambiar también \\(p(y|x)\\). En el ejemplo \\(Edad \\to Riesgo \\to Accidente\\), si alguien es más joven, entonces es más probable que sea arriesgado, y esto hace más probable que tenga un accidente. Si sabemos el valor de \\(Z\\), sin embargo, \\(X\\) no nos da información de \\(Y\\). En este caso tenemos \\(p(x,y)=p(x)p(z|x)p(y|z)\\), como \\(z\\) está fija tenemos que \\(p(x,y)=p(x)h(x)g(y)\\), donde \\(h\\) y \\(g\\) son funciones fijas. Como la conjunta se factoriza, \\(X\\) y \\(Y\\) son independientes dada \\(Z\\). En nuestro ejemplo, si conociemos la aversión al riesgo, la edad del asegurado no da información adicional acerca de la probabilidad de tener un accidente. Razonamiento evidencial: \\(Y\\rightarrow Z \\rightarrow X.\\) Si no sabemos acerca de \\(Z\\), sí, por un argumento similar al del inciso anterior. Es un argumento de probabilidad inversa en \\(Edad \\to Riesgo \\to Accidente\\). Si alguien tuvo un accidente, entonces es más probable que sea arriesgado, y por tanto es más probable que sea joven. Si sabemos el valor que toma \\(Z\\), entonces \\(X\\) no puede influenciar a \\(Y\\), por un argumento similar. Razonamiento de causa común: \\(X\\leftarrow Z \\rightarrow Y\\). Sí, pues en este caso: \\[p(x,y,z)=p(z)p(y|z)p(x|z),\\] Sumando sobre \\(z\\) tenemos \\[p(x,y)=\\sum_z p(y|z)p(x,z),\\] así que \\(p(y|x)=\\sum_z p(y|z)p(z|x).\\) En el ejemplo podríamos tener \\(Tiempo manejando \\leftarrow Edad \\rightarrow Riesgo\\). Una persona que lleva mucha tiempo manejando es más probablemente mayor, lo cual hace más probable que sea aversa al riesgo. No. Si conocemos el valor de \\(Z\\), entonces \\(X\\) y \\(Y\\) son condicionalmente independientes, pues \\(p(x,y,z)=p(z)p(y|z)p(x|z)\\), donde vemos que una vez que está dada la \\(z\\) \\(x\\) y \\(y\\) no interactuán (están en factores distintos). Razonamiento intercausal: Colisionador o estructura-v: \\(X\\rightarrow Z \\leftarrow Y\\). Si no tenemos información acerca de \\(Z\\), no. Esto es porque tenemos \\[p(x,y,z)=p(x)p(y)p(z|x,y),\\] de donde vemos que la conjunta de \\(X\\) y \\(Y\\) satisface \\(p(x,y)=p(x)p(y)\\) (sumando sobre \\(z\\)). Podríamos tener que \\(Calidad de conductor \\rightarrow Accidente \\leftarrow Condicion de calle\\). Que alguien vaya por una calle en mal estado no cambia las probabilidades de ser un mal conductor (en nuestro modelo). Si sabemos el valor de \\(Z\\), sí conocimiento de \\(X\\) puede cambiar probabilidades de \\(Y\\). Como tenemos \\[p(x,y,z)=p(x)p(y)p(z|x,y),\\] el término (z está fijo) \\(p(z|x,y)=h(x,y)\\) puede incluir interacciones entre \\(x\\) y \\(y\\). En nuestro ejemplo, si sabemos que hubo un accidente, las condiciones de la calle si nos da información acerca de la calidad del conductor: por ejemplo, si la calle está en buen estado, se hace más probable que se trate de un conductor malo. #&gt; Error in library(igraph): there is no package called &#39;igraph&#39; #&gt; Error in graph(c(1, 3, 2, 3, 2, 4, 3, 5)): no se pudo encontrar la función &quot;graph&quot; #&gt; Error in plot(gr, vertex.label = c(&quot;Dificultad&quot;, &quot;Inteligencia&quot;, &quot;Calificación&quot;, : objeto &#39;gr&#39; no encontrado Si sabemos que la clase es difícil y que el estudiante obtuvo 6, ¿como cambia la probabilidad posterior de inteligencia alta? a) sube b) baja c) no cambia d) No se puede saber? 2.1.5 Caminos: pelota de Bayes Un camino (no dirigido) esta activo si una pelota de Bayes que viaja a través del camino NO se topa con un símbolo de bloqueo (-&gt;|). En los esquemas los nodos sombreados indican que se tiene información de esas variables (ya no son aleatorios). En la figura de la izquierda (abajo) notamos que (siguiendo las reglas de la pelota de Bayes) la pelota no puede llegar del nodo \\(X\\) al nodo \\(Y\\), esto es no existe un camino activo que conecte \\(X\\) y \\(Y\\). Por otra parte, la figura del lado derecho muestra que al condicionar en el conjunto \\(\\{X, W\\}\\) se activa un camino que permite que la pelota de Bayes viaje de \\(X\\) a \\(Y\\). Ahora veamos alegbráicamente que si condicionamos únicamente a \\(Z\\), entonces \\(X \\perp Y | Z\\), esto es lo que vemos en la figura de la izquierda. Para esto escribamos la densidad conjunta: \\[p(z,a,y,x,b,c) = p(z)p(a|z)p(y|z)p(x|a)p(b|a,y)p(c|b)\\] Y la utilizamos para obtener la densidad marginal \\(p(x,y,z)\\): \\[\\begin{align} \\nonumber p(x,y,z) &amp;= \\sum_a \\sum_b \\sum_c p(z,a,y,x,b,c) \\nonumber &amp;= \\sum_a \\sum_b \\sum_c p(z)p(a|z)p(y|z)p(x|a)p(b|a,y)p(c|b) \\nonumber &amp;= \\sum_a \\sum_b p(z)p(a|z)p(y|z)p(x|a)p(b|a,y)\\sum_c p(c|b) \\nonumber &amp;= \\sum_a p(z)p(a|z)p(y|z)p(x|a) \\sum_b p(b|a,y) \\nonumber &amp;= p(z)p(y|z) \\sum_a p(a|z) p(x|a) \\nonumber &amp;= g(y,z)h(x,z) \\end{align}\\] donde \\(g(y,z) = p(z)p(y|z)\\) y \\(h(y,z) = \\sum_a p(a|z) p(x|a)\\). Por lo tanto \\(X \\perp Y | Z\\). Utilizando la gráfica del lado derecho demuestra algebráicamente que dados \\(Z,W\\), \\(X\\) no es necesariamente independiente de \\(Y\\). "],
["flujo-de-probabilidad-y-d-separacion.html", "2.2 Flujo de probabilidad y d-Separación", " 2.2 Flujo de probabilidad y d-Separación De la discusión anterior, definimos caminos activos en una gráfica los que, dada cierta evidencia \\(Z\\), pueden potencialmente transmitir información probabilística. Sea \\(U\\) un camino no dirigido en una gráfica \\({\\mathcal G}\\). Decimos que el camino es activo dada evidencia \\(W\\) si: Todos los colisionadores en el camino \\(U\\) están o tienen un descendiente en \\(W\\). Ningún otro vértice de el camino está en \\(W\\). Un caso adicional interesante es cuando los descendiente de un colisionador activan un camino. #&gt; Error in library(igraph): there is no package called &#39;igraph&#39; #&gt; Error in graph(c(1, 2, 2, 4, 3, 4, 3, 5, 4, 6, 6, 7, 5, 7, 7, 8, 4, 8)): no se pudo encontrar la función &quot;graph&quot; #&gt; Error in plot(gr, vertex.label = c(&quot;Coherencia&quot;, &quot;Dificultad&quot;, &quot;Inteligencia&quot;, : objeto &#39;gr&#39; no encontrado ¿Cuáles de los siguientes son caminos activos si observamos Calificación? \\(Coh \\rightarrow Dif \\rightarrow Calif \\leftarrow Int \\rightarrow GRE\\) \\(Int \\rightarrow Cal \\rightarrow Rec \\leftarrow Tra \\rightarrow Fel\\) \\(Int \\rightarrow GRE \\rightarrow Tra \\rightarrow Fel\\) \\(Coh \\rightarrow Dif \\rightarrow Cal \\leftarrow Int \\rightarrow GRE \\rightarrow Tra \\leftarrow Rec\\) Volviendo al ejemplo anterior Algebráicamente: La distribución conjunta se factoriza como: \\[p(z,a,y,x,b,w)=p(z)p(a|z)p(y|z)p(x|a)p(b|a,y)p(w|b)\\] Por lo que la marginal \\(p(x,y,w,z)\\) se obtiene de la siguiente manera: \\[p(x,y,w,z) = \\sum_a \\sum_b p(z,a,y,x,b,w)\\] \\[= \\sum_a \\sum_b p(z)p(a|z)p(y|z)p(x|a)p(b|a,y)p(w|b)\\] \\[= p(z)p(y|z) \\sum_a p(a|z)p(x|a) \\sum_b p(b|a,y)p(w|b)\\] Notamos que \\(X\\) y \\(Y\\) interactúan a través de \\(A\\) y \\(B\\), por lo que no es posible encontrar dos funciones \\(g\\), \\(h\\), tales que \\(p(x,y,w,z) \\propto g(x,w,z) h(y,w,z)\\) y concluímos que \\(X \\not \\perp Y | W\\). Sean \\(X\\) y \\(Y\\) vértices distintos y \\(W\\) un conjunto de vértices que no contiene a \\(X\\) o \\(Y\\). Decimos que \\(X\\) y \\(Y\\) están d-separados dada \\(W\\) si no existen caminos activos dada \\(W\\) entre \\(X\\) y \\(Y\\). Es decir, la \\(d\\)-separación desaparece cuando hay información condicionada en colisionadores o descendientes de colisionadores. Este concepto de \\(d\\)-separación es precisamente el que funciona para encontrar todas las independencias condicionales: Supongamos que \\(p\\) se factoriza sobre \\(\\mathcal G\\). Sean \\(A\\), \\(B\\) y \\(C\\) conjuntos disjuntos de vértices de \\({\\mathcal G}\\). Si \\(A\\) y \\(B\\) están \\(d\\)-separados por \\(C\\) entonces \\(A\\bot B | C\\) bajo \\(p\\) . 2.2.0.1 Discusión El resultado anterior no caracteriza la independencia condicional de una distribución \\(p\\) por una razón simple, que podemos entender como sigue: si agregamos aristas a una gráfica \\({\\mathcal G}\\) sobre la que se factoriza \\(p\\), entonces \\(p\\) se factoriza también sobre la nueva gráfica \\({\\mathcal G}&#39;\\). Esto reduce el número de independencias de \\(p\\) que representa \\({\\mathcal G}\\). Un ejemplo trivial son dos variables aleatorias independientes \\(X\\) y \\(Y\\) bajo \\(p\\). \\(p\\) claramente se factoriza en \\(X\\to Y\\), pero de esta gráfica no se puede leer la independencia de \\(X\\) y \\(Y\\). ¿Qué es lo malo de esto? En primer lugar, si usamos \\({\\mathcal G}&#39;\\) en lugar de \\({\\mathcal G}\\), no reducimos la complejidad del modelo al usar las independencias condicionales gráficas que desaparecen al agregar aristas. En segundo lugar, la independencia condicional no mostrada en la gráfica es más difícil de descubrir: tendríamos que ver directamente la conjunta particular de nuestro problema, en lugar de leerla directamente de la gráfica. Finalmente, estos argumentos también sugieren que quisiéramos encontrar mapeos que no sólo sean mínimos (no se pueden eliminar aristas), sino también perfectos en el sentido de que representan exactamente las independencias condicionales. Veremos estos temas más adelante. Algo que sí podemos establecer es cómo se comporta la familia de distribuciones que se factorizan sobre una gráfica \\(\\mathcal G\\): Sea \\(\\mathcal G\\) una DAG. Si \\(X\\) y \\(Y\\) no están \\(d\\)-separadas en \\(\\mathcal G\\), entonces existe alguna distribución \\(q\\) (que se factoriza sobre \\({\\mathcal G}\\)) tal que \\(X\\) y \\(Y\\) no son independientes bajo \\(q\\). Para que existan independencias que no están asociadas a \\(d\\)-separación los parámetros deben tomar valores paticulares. Este conjunto de valores es relativamente chico en el espacio de parámetros (son superficies), por lo tanto podemos hacer más fuerte este resultado: Sea \\(\\mathcal G\\) una DAG. Excepto en un conjunto de “medida cero” en el espacio de distribuciones \\(M({\\mathcal G})\\) que se factorizan sobre \\(\\mathcal G\\), tenemos que \\(d\\)-separación es equivalente a independencia condicional. Es decir, \\(d\\)-separación caracteriza precisamente las independencias condicionales de cada \\(p\\in M(\\mathcal G)\\), excepto para un conjunto relativamente chico de \\(p \\in M({\\mathcal G})\\) . 2.2.1 Equivalencia Markoviana En esta parte trataremos el problema de la unicidad de la representación gráfica dada un conjunto de independencias condicionales. La respuesta corta es que las representaciones no son únicas, pues algunas flechas pueden reorientarse sin que haya cambios en términos de la conjunta representada. Decimos que dos gráficas \\({\\mathcal G}_1\\) y \\({\\mathcal G}_2\\) son Markov equivalentes cuando el conjunto de independencias implicadas de ambas es el mismo. Otra manera de decir esto, es que ambas gráficas tienen exactamente la misma estructura de \\(d-\\)separación. La equivalencia Markoviana limita nuestra capacidad de inferir la dirección de las flechas únicamente de las probabilidades, esto implica que dos gráficas Markov equivalentes no se pueden distinguir usando solamente una base de datos. Por ejemplo, en la siguiente gráfica, cambiar la dirección del arco que une \\(X_1\\) y \\(X_2\\) genera una gráfica Markov equivalente, esto es, la dirección del arco que une a \\(X_1\\) y \\(X_2\\) no se puede inferir de información probabilística. library(igraph) #&gt; Error in library(igraph): there is no package called &#39;igraph&#39; gr &lt;- graph( c(1,2,1,3,2,4,3,4,4,5) ) #&gt; Error in graph(c(1, 2, 1, 3, 2, 4, 3, 4, 4, 5)): no se pudo encontrar la función &quot;graph&quot; plot(gr, vertex.label=c(&#39;X1&#39;,&#39;X2&#39;,&#39;X3&#39;,&#39;X4&#39;,&#39;X5&#39;), layout = matrix(c(-0.3,0,0,-0.3,0, 0.3,0.3,0,0.6,0), byrow = TRUE, ncol = 2), vertex.size = 20, vertex.color = &#39;salmon&#39;, vertex.label.cex = 1.2, vertex.label.color = &#39;gray40&#39;, vertex.frame.color = NA, asp = 0.5, edge.arrow.size = 1) #&gt; Error in plot(gr, vertex.label = c(&quot;X1&quot;, &quot;X2&quot;, &quot;X3&quot;, &quot;X4&quot;, &quot;X5&quot;), layout = matrix(c(-0.3, : objeto &#39;gr&#39; no encontrado Decimos que un colisionador no está protegido cuando las variables que apuntan a la colisión no tienen vértice entre ellas. Definimos adicionalmente el esqueleto de una GAD como la versión no dirigida de \\(\\mathcal G\\). El siguiente resultado establece que la distribución sólo puede determinar determinar la dirección de las flechas en presencia de un colisionador no protegido: Dos gráficas \\({\\mathcal G}_1\\) y \\({\\mathcal G}_2\\) son Markov equivalentes si y sólo si Sus esqueletos son iguales y \\({\\mathcal G}_1\\) y \\({\\mathcal G}_2\\) tienen los mismos colisionadores no protegidos. Las equivalencias que señala este teorema son importantes. Por ejemplo, las gráficas \\(X\\rightarrow Y \\rightarrow Z\\) y \\(X\\leftarrow Y \\leftarrow Z\\) son equivalentes, lo que implica que representan a las mismas distribuciones condicionales. Solamente usando datos (o el modelo), no podemos distinguir estas dos estructuras, sin embargo, puede ser que tengamos información adicional para preferir una sobre otra (por ejemplo, si es una serie de tiempo). Una estructura que sí podemos identificar de manera dirigida es el colisionador. El resto de las direcciones pueden establecerse por facilidad de interpretación o razones causales. Regresando a la gráfica anterior, notamos que al revertir el sentido del arco que une a \\(X_1\\) con \\(X_2\\) no se crea ni se destruye ningun colisionador y por tanto la gráfica resultante del cambio de sentido es efectivamente Markov equivalente. Consideremos ahora los arcos dirigidos que unen a \\(X_2\\) con \\(X_4\\) y a \\(X_4\\) con \\(X_5\\), notamos que no hay manera de revertir la dirección de estos arcos si crear un nuevo colisionador, esto implica que algunas funciones de probabilidad \\(p\\) restringen la dirección de éstas flechas en la gráfica. En el siguiente ejemplo, mostramos la clase de equivalencia de una red de ejemplo. Ahí vemos cuáles son las aristas que se pueden orientar de distinta manera, y cuáles pertenecen a colisionadores en los cuales las direcciones están identificadas: library(bnlearn) #&gt; Error in library(bnlearn): there is no package called &#39;bnlearn&#39; grafica.1 &lt;- gs(insurance[c(&#39;Age&#39;, &#39;RiskAversion&#39;, &#39;Accident&#39;, &#39;DrivQuality&#39;, &#39;Antilock&#39;, &#39;VehicleYear&#39;)], alpha = 0.01) #&gt; Error in gs(insurance[c(&quot;Age&quot;, &quot;RiskAversion&quot;, &quot;Accident&quot;, &quot;DrivQuality&quot;, : no se pudo encontrar la función &quot;gs&quot; graphviz.plot(grafica.1) #&gt; Error in graphviz.plot(grafica.1): no se pudo encontrar la función &quot;graphviz.plot&quot; ¿Cuáles de las gráficas anteriores son Markov equivalentes? 1 y 2 1 y 3 2 y 4 2 y 4 Ninguna 2.2.2 Resumen Dada una gráfica \\(G\\) podemos encontrar las as independencias condicionales que establece, \\(I(G)\\). Dada una distribución \\(p\\) podemos encontrar las independencias que implica, \\(I(p)\\) (en teoría). Las independencias condicionales definidas por la red bayesiana son un subconjunto de las independencias en \\(p\\), esto es \\(I(G) \\subset I(p)\\). Equivalencia Markoviana se expresa como: \\(I(G) = I(G&#39;)\\). 2.2.3 Ejemlos Repositorio de redes Universidad de Utrecht Genie y Smile Librería de Norsys (Netica) Casos de Hugin "],
["modelos-locales.html", "2.3 Modelos locales", " 2.3 Modelos locales En esta parte veremos cómo construir los modelos locales que corresponden a factores en la regla del producto para factorizaciones sobre DAGs, y veremos cómo usar datos para ajustar sus parámetros. 2.3.1 Tablas de probabilidad condicional En primer lugar, recordemos que siempre podemos hacer representaciones tabulares para la condicional de cada variable dado sus padres: \\[P(X|Pa(X)),\\] donde establecemos, para cada combinación de valores de las variables en \\(Pa(X)\\), una distribución sobre \\(X\\) tal que \\[\\sum_x P(X=x|Pa(X))=1.\\] Ejemplo. En el ejemplo de la clase anterior construimos directamente las condicionales de llueve (no condicional), regar (no condicional) y mojado dado llueve y regar: llueve &lt;- c(&#39;Sí&#39;,&#39;No&#39;) regar &lt;- c(&#39;Prendido&#39;, &#39;Apagado&#39;) p_llueve &lt;- data.frame(llueve = llueve, prob.l = c(0.1, 0.9)) p_llueve #&gt; llueve prob.l #&gt; 1 Sí 0.1 #&gt; 2 No 0.9 p_regar &lt;- data.frame(regar = regar, prob.r = c(0.2, 0.8)) p_regar #&gt; regar prob.r #&gt; 1 Prendido 0.2 #&gt; 2 Apagado 0.8 mojado &lt;- c(&#39;Mojado&#39;,&#39;Seco&#39;) niveles &lt;- expand.grid(llueve = llueve, regar = regar, mojado = mojado) p_mojado_lr &lt;- data.frame(niveles, prob_m = NA) p_mojado_lr$prob_m[1:4] &lt;- c(0.97, 0.9, 0.8, 0.01) p_mojado_lr$prob_m[5:8]&lt;- 1 - p_mojado_lr$prob_m[1:4] p_mojado_lr #&gt; llueve regar mojado prob_m #&gt; 1 Sí Prendido Mojado 0.97 #&gt; 2 No Prendido Mojado 0.90 #&gt; 3 Sí Apagado Mojado 0.80 #&gt; 4 No Apagado Mojado 0.01 #&gt; 5 Sí Prendido Seco 0.03 #&gt; 6 No Prendido Seco 0.10 #&gt; 7 Sí Apagado Seco 0.20 #&gt; 8 No Apagado Seco 0.99 Representar los modelos locales de esta forma tiene una desventaja potencial: Esta representación no explota ninguna regularidad que pueda existir en la condicional, así que cuando la variable respuesta depende de muchas variables hay muchos parámetros por estimar individualmente (cada probabilidad condicional, menos uno). Esto puede ser difícil de ajustar con datos o demasiado engorroso de elicitar para un experto. Ejemplos de regularidades: Si riegan, entonces el piso va a estar mojado sin importar si llueve o no. (no es necesario un parámetro separado para llueve/no llueve) La probabilidad de conseguir ser aceptado en una universidad depende de la calidad de las cartas de recomendación del profesor A, el profesor B, y de la carta que decida enviar el solicitante. Si un estudiante escoge la carta de recomendación del profesor A para pedir trabajo, la probabilidad de conseguir el trabajo no depende de la carta del profesor B. (dado que escogió la carta A, basta dar la tabla de probabilidades aceptación-calidad de carta A, sin importar la calidad de la carta B). La probabilidad de una categoría sigue un modelo logístico sin interacciones entre las variables de entrada (padres) (no es necesario tener parámetros para interacciones entre las variables de entrada). En todos estos casos, podemos reducir el número de parámetros a estimar y obtener una representación más simple, siempre y cuando nuestros modelos más simples ajusten a los datos. La idea importante es que para especificar las probabilidades condicionales no es necesario dar una tabla completa explícitamente. Podemos tener reglas o modelos simples de las cuales podamos calcular cualquier probabilidad condicional que nos interese. 2.3.2 Estimación directa por máxima verosimilitud Cuando usamos datos para estimar los modelos locales, si no hacemos supuestos sobre la estructura de los modelos locales, podemos usar máxima verosimilitud para hacer la estimación. Para estimar \\[P(X_i=x|X_1=x_1,\\ldots, X_k=x_k)\\] utilizamos simplemente \\[\\frac{N(X_i=x,X_1=x_1,\\ldots, X_k=x_k)}{N(X_1=x_1,\\ldots, X_k=x_k)}.\\] Nótese que cuando hay muchas variables de entrada/relativamente pocos datos, esta estimación puede ser muy ruidosa (pocos casos en el denominador), o simplemente infactible. Para modelos simples funciona razonablemente bien. Una solución (relacionada con un modelo bayesiano) es suavizar los conteos con \\[\\frac{N(X_i=x,X_1=x_1,\\ldots, X_k=x_k)+\\alpha_x}{N(X_1=x_1,\\ldots, X_k=x_k)+\\alpha},\\] donde \\(\\sum_x \\alpha_x=\\alpha\\). Ejemplo. Consideramos el siguiente ejemplo de datos de la ENIGH 2010 (una observación por hogar, características de hogares y sus habitantes): library(bnlearn) #&gt; Error in library(bnlearn): there is no package called &#39;bnlearn&#39; library(plyr) #&gt; ------------------------------------------------------------------------- #&gt; You have loaded plyr after dplyr - this is likely to cause problems. #&gt; If you need functions from both plyr and dplyr, please load plyr first, then dplyr: #&gt; library(plyr); library(dplyr) #&gt; ------------------------------------------------------------------------- #&gt; #&gt; Attaching package: &#39;plyr&#39; #&gt; The following objects are masked from &#39;package:dplyr&#39;: #&gt; #&gt; arrange, count, desc, failwith, id, mutate, rename, summarise, #&gt; summarize #&gt; The following object is masked from &#39;package:purrr&#39;: #&gt; #&gt; compact library(dplyr) load(file = &#39;data/dat_ing.Rdata&#39;) #&gt; Error in readChar(con, 5L, useBytes = TRUE): no se puede abrir la conexión dat_ing$marg &lt;- factor(as.character(dat_ing$marg)) #&gt; Error in factor(as.character(dat_ing$marg)): objeto &#39;dat_ing&#39; no encontrado # creamos una base únicamente con variables de interés dat_ing_f &lt;- select(dat_ing, tam_loc, marg, decil, nivelaprob, vehiculo, drenaje, pisos, sexojefe) #&gt; Error in select(dat_ing, tam_loc, marg, decil, nivelaprob, vehiculo, drenaje, : objeto &#39;dat_ing&#39; no encontrado black &lt;- data.frame( form = c(&#39;drenaje&#39;, &#39;nivelaprob&#39;, &#39;decil&#39;, &#39;decil&#39;, &#39;nivelaprob&#39;), to = c(&#39;decil&#39;, &#39;sexojefe&#39;, &#39;nivelaprob&#39;, &#39;tam_loc&#39;, &#39;marg&#39;)) net_enigh &lt;- hc(dat_ing_f, score = &#39;aic&#39;, blacklist = black) #&gt; Error in hc(dat_ing_f, score = &quot;aic&quot;, blacklist = black): no se pudo encontrar la función &quot;hc&quot; net_enigh #&gt; Error in eval(expr, envir, enclos): objeto &#39;net_enigh&#39; no encontrado fit_enigh_mle &lt;- bn.fit(net_enigh, data = dat_ing_f, method = &#39;mle&#39;) #&gt; Error in bn.fit(net_enigh, data = dat_ing_f, method = &quot;mle&quot;): no se pudo encontrar la función &quot;bn.fit&quot; #write.net(&quot;./salidas/enigh_mle_1.net&quot;, fit_enigh_mle) graphviz.plot(net_enigh) #&gt; Error in graphviz.plot(net_enigh): no se pudo encontrar la función &quot;graphviz.plot&quot; La estimación por máxima verosimilitud para la condicional de marginación dado tamaño de localidad es fit_enigh_mle[[&#39;marg&#39;]] #&gt; Error in eval(expr, envir, enclos): objeto &#39;fit_enigh_mle&#39; no encontrado Que es simplemente (máxima verosimilitud): tab_1 &lt;- table(dat_ing$marg, dat_ing$tam_loc) #&gt; Error in table(dat_ing$marg, dat_ing$tam_loc): objeto &#39;dat_ing&#39; no encontrado tab_1 #&gt; #&gt; No Sí #&gt; 0.9 0.1 tab_2 &lt;- prop.table(tab_1, margin = 2) #&gt; Error in if (d2 == 0L) {: valor ausente donde TRUE/FALSE es necesario tab_2 #&gt; #&gt; Apagado Prendido #&gt; 0.7 0.3 En este ejemplo, donde los denominadores son relativamente grandes, no es necesario hacer ningún suavizamiento. Sin embargo, podemos utilizar suavizamiento de conteos de la siguiente forma (iss es imaginary sample size). fit_enigh_b &lt;- bn.fit(net_enigh, data = dat_ing_f, method = &#39;bayes&#39;, iss = 100) #&gt; Error in bn.fit(net_enigh, data = dat_ing_f, method = &quot;bayes&quot;, iss = 100): no se pudo encontrar la función &quot;bn.fit&quot; fit_enigh_b[[&#39;marg&#39;]] #&gt; Error in eval(expr, envir, enclos): objeto &#39;fit_enigh_b&#39; no encontrado prop.table(tab_1 + 100 / (4 * 5), margin = 2) #&gt; Error in if (d2 == 0L) {: valor ausente donde TRUE/FALSE es necesario Mayor suavizamiento regulariza más los conteos. Para muestras más chicas, es posible que sea necesario escoger suavizamientos más chicos. Ejemplo. Repetiremos el ejercicio con una muestra chica para ver cómo puede mejorar nuestra estimación el suavizamiento. library(ggplot2) library(tidyr) set.seed(282095) # tomamos una muestra de tamaño 50 dat_ing_muestra &lt;- sample_n(dat_ing_f, 50) #&gt; Error in sample_n(dat_ing_f, 50): objeto &#39;dat_ing_f&#39; no encontrado # veamos la tabla cruda table(dat_ing_muestra$marg, dat_ing_muestra$tam_loc) #&gt; Error in table(dat_ing_muestra$marg, dat_ing_muestra$tam_loc): objeto &#39;dat_ing_muestra&#39; no encontrado # usamos máxima verosimilitud fit_enigh_1 &lt;- bn.fit(net_enigh, data = dat_ing_muestra, method=&#39;mle&#39;) #&gt; Error in bn.fit(net_enigh, data = dat_ing_muestra, method = &quot;mle&quot;): no se pudo encontrar la función &quot;bn.fit&quot; probs_est_mle &lt;- data.frame(fit_enigh_1[[&#39;marg&#39;]]$prob) #&gt; Error in data.frame(fit_enigh_1[[&quot;marg&quot;]]$prob): objeto &#39;fit_enigh_1&#39; no encontrado names(probs_est_mle)[3] &lt;- &#39;mle&#39; #&gt; Error in names(probs_est_mle)[3] &lt;- &quot;mle&quot;: objeto &#39;probs_est_mle&#39; no encontrado probs_est_mle #&gt; Error in eval(expr, envir, enclos): objeto &#39;probs_est_mle&#39; no encontrado # repetimos con suavizamiento fit_enigh_2 &lt;- bn.fit(net_enigh, data = dat_ing_muestra, method = &#39;bayes&#39;, iss = 30) #&gt; Error in bn.fit(net_enigh, data = dat_ing_muestra, method = &quot;bayes&quot;, iss = 30): no se pudo encontrar la función &quot;bn.fit&quot; probs_est_bayes &lt;- data.frame(fit_enigh_2[[&#39;marg&#39;]]$prob) #&gt; Error in data.frame(fit_enigh_2[[&quot;marg&quot;]]$prob): objeto &#39;fit_enigh_2&#39; no encontrado names(probs_est_bayes)[3] &lt;- &#39;bayes&#39; #&gt; Error in names(probs_est_bayes)[3] &lt;- &quot;bayes&quot;: objeto &#39;probs_est_bayes&#39; no encontrado probs_1 &lt;- join(probs_est_mle, probs_est_bayes) #&gt; Error in as.vector(y): objeto &#39;probs_est_bayes&#39; no encontrado # comparamos con las estimaciones que toman toda la base tab_df &lt;- data.frame(tab_2) names(tab_df) &lt;- c(&#39;marg&#39;, &#39;tam_loc&#39;, &#39;mle_c&#39;) #&gt; Error in names(tab_df) &lt;- c(&quot;marg&quot;, &quot;tam_loc&quot;, &quot;mle_c&quot;): el atributo &#39;names&#39; [3] debe tener la misma longitud que el vector [2] # las unimos a la base de datos probs_1 probs_2 &lt;- join(probs_1, tab_df) #&gt; Error in as.vector(x): objeto &#39;probs_1&#39; no encontrado # creamos dos nuevas variables: método y estimación para poder graficar probs_2_l &lt;- gather(probs_2, metodo, est, mle, bayes, mle_c) #&gt; Error in gather(probs_2, metodo, est, mle, bayes, mle_c): objeto &#39;probs_2&#39; no encontrado ggplot(probs_2_l, aes(x = marg, y = est, colour = metodo)) + geom_jitter(size=3,position=position_jitter(width=0.1, height=0))+ facet_wrap(~ tam_loc) #&gt; Error in ggplot(probs_2_l, aes(x = marg, y = est, colour = metodo)): objeto &#39;probs_2_l&#39; no encontrado Muy poca regularización (iss chica) típicamente no tiene efectos negativos (y conviene hacerla para evitar estimación de ceros), pero puede ser que demasiada regularización sí. Este parámetro puede ser escogido mediante validación cruzada, o desde un punto de vista bayesiano con información previa. Ejemplo. Cuando los modelos son más complejos, la estimación de máxima verosimilitud puede ser muy mala, por ejemplo: mle_vehiculo &lt;- data.frame(fit_enigh_mle[[&#39;vehiculo&#39;]]$prob) #&gt; Error in data.frame(fit_enigh_mle[[&quot;vehiculo&quot;]]$prob): objeto &#39;fit_enigh_mle&#39; no encontrado mle_vehiculo_true &lt;- filter(mle_vehiculo, vehiculo == &#39;TRUE&#39;, nivelaprob!=&#39;No esp&#39;) #&gt; Error in filter(mle_vehiculo, vehiculo == &quot;TRUE&quot;, nivelaprob != &quot;No esp&quot;): objeto &#39;mle_vehiculo&#39; no encontrado ggplot(mle_vehiculo_true, aes(x = nivelaprob, y = Freq, colour = decil, group = decil)) + facet_wrap(~ sexojefe) + geom_point() + geom_line() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) #&gt; Error in ggplot(mle_vehiculo_true, aes(x = nivelaprob, y = Freq, colour = decil, : objeto &#39;mle_vehiculo_true&#39; no encontrado fit_enigh_b &lt;- bn.fit(net_enigh, data = dat_ing_f, method = &#39;bayes&#39;, iss = 1000) #&gt; Error in bn.fit(net_enigh, data = dat_ing_f, method = &quot;bayes&quot;, iss = 1000): no se pudo encontrar la función &quot;bn.fit&quot; b_vehiculo &lt;- data.frame(fit_enigh_b[[&#39;vehiculo&#39;]]$prob) #&gt; Error in data.frame(fit_enigh_b[[&quot;vehiculo&quot;]]$prob): objeto &#39;fit_enigh_b&#39; no encontrado b_vehiculo_true &lt;- filter(b_vehiculo, vehiculo == &#39;TRUE&#39;, nivelaprob!=&#39;No esp&#39;) #&gt; Error in filter(b_vehiculo, vehiculo == &quot;TRUE&quot;, nivelaprob != &quot;No esp&quot;): objeto &#39;b_vehiculo&#39; no encontrado ggplot(b_vehiculo_true, aes(x = nivelaprob, y = Freq, colour = decil, group = decil)) + facet_wrap(~ sexojefe) + geom_point() + geom_line() + theme(axis.text.x = element_text(angle = 45, hjust = 1)) #&gt; Error in ggplot(b_vehiculo_true, aes(x = nivelaprob, y = Freq, colour = decil, : objeto &#39;b_vehiculo_true&#39; no encontrado 2.3.3 Probabilidades condicionales basadas en árboles Podemos usar árboles de decisión para construir versiones compactas de probabilidades condicionales. Ejemplo. Una carta de recomendación buena del profesor A da una probabilidad de 0.6 de conseguir el trabajo, mientras que una carta mala de 0.4. Para el profesor B, las probabilidades son 0.8 y 0.4. Consideramos la siguiente gráfica: library(igraph) #&gt; Error in library(igraph): there is no package called &#39;igraph&#39; gr &lt;- graph(c(1, 2, 3, 2, 4, 2)) #&gt; Error in graph(c(1, 2, 3, 2, 4, 2)): no se pudo encontrar la función &quot;graph&quot; plot(gr, vertex.label = c(&#39;ProfA&#39;, &#39;Trabajo&#39;, &#39;ProfB&#39;, &#39;Carta&#39;), layout = matrix(c(0, 1, 0.6, 0, 0,-1, 0, 0), byrow = TRUE, ncol = 2), vertex.size = 20, vertex.color = &#39;salmon&#39;, vertex.label.cex = 1.2, vertex.label.color = &#39;gray40&#39;, vertex.frame.color = NA, asp = 0.8, edge.arrow.size = 1) #&gt; Error in plot(gr, vertex.label = c(&quot;ProfA&quot;, &quot;Trabajo&quot;, &quot;ProfB&quot;, &quot;Carta&quot;), : objeto &#39;gr&#39; no encontrado La tabla de probabilidad condicional correspondiente a Trabajo tiene un total de 8 parámetros. Sin embargo, por la observación anterior, en relidad está dada por 2 parámetros, pues Trabajo sólo depende de ProfA cuando Carta=A, y sólo depende de ProfB cuando Carta=B (con las mismas probabilidades 0.6 y 0.4). Representamos este escenario mediante un árbol: La estructura adicional que observamos es que cuando Carta=A, Trabajo es condicionalmente independiente de Prof B, y cuando Carta=B, Trabajo es condiconalmente independiente de ProfA. Esta es una independencia condicional distinta a las que vimos antes: dice que para ciertos niveles de alguna variable, existen independencias condicionales entre otras variables. Esto no quiere decir que dado Carta, Trabajo sea condicionalmente independiente de ProfA o ProfB. Otra manera de decir esto es que estos modelos locales pueden tener información de independencias condicionales en ciertos contextos (para valores particulares de las variables). Ejemplo library(rpart) library(rpart.plot) #&gt; Error in library(rpart.plot): there is no package called &#39;rpart.plot&#39; library(rattle) #&gt; Error in library(rattle): there is no package called &#39;rattle&#39; set.seed(22857) # simulamos datos prof_a &lt;- sample(c(&#39;Buena&#39;, &#39;Mala&#39;, &#39;Mala&#39;), 400, replace = T) prof_b &lt;- sample(c(&#39;Buena&#39;, &#39;Buena&#39;, &#39;Mala&#39;), 400, replace = T) carta &lt;- sample(c(&#39;A&#39;, &#39;B&#39;), 400, replace = T) datos_sim &lt;- data.frame(prof_a, prof_b, carta) # describimos las probabilidades probas &lt;- datos_sim %&gt;% distinct() %&gt;% mutate(proba = (prof_a == &#39;Mala&#39; &amp; carta == &#39;A&#39;) * 0.4 + (prof_b == &#39;Mala&#39; &amp; carta == &#39;B&#39;) * 0.4 + (prof_a == &#39;Buena&#39; &amp; carta == &#39;A&#39;) * 0.6 + (prof_b == &#39;Buena&#39; &amp; carta == &#39;B&#39;) * 0.8) probas #&gt; prof_a prof_b carta proba #&gt; 1 Mala Mala B 0.4 #&gt; 2 Buena Buena B 0.8 #&gt; 3 Mala Buena B 0.8 #&gt; 4 Buena Buena A 0.6 #&gt; 5 Mala Buena A 0.4 #&gt; 6 Buena Mala B 0.4 #&gt; 7 Mala Mala A 0.4 #&gt; 8 Buena Mala A 0.6 # finalmente simulamos si consigue el trabajo datos_1 &lt;- inner_join(datos_sim, probas) #&gt; Joining, by = c(&quot;prof_a&quot;, &quot;prof_b&quot;, &quot;carta&quot;) datos_1$consigue &lt;- rbinom(nrow(datos_1), size = 1, prob = datos_1$prob) # usamos un árbol de decisión arbol_1 &lt;- rpart(consigue ~ prof_a + prof_b + carta, datos_1, method = &#39;class&#39;, cp = 0) printcp(arbol_1) #&gt; #&gt; Classification tree: #&gt; rpart(formula = consigue ~ prof_a + prof_b + carta, data = datos_1, #&gt; method = &quot;class&quot;, cp = 0) #&gt; #&gt; Variables actually used in tree construction: #&gt; [1] carta prof_a prof_b #&gt; #&gt; Root node error: 183/400 = 0.5 #&gt; #&gt; n= 400 #&gt; #&gt; CP nsplit rel error xerror xstd #&gt; 1 0.17 0 1.0 1.0 0.05 #&gt; 2 0.11 1 0.8 0.9 0.05 #&gt; 3 0.04 2 0.7 0.7 0.05 #&gt; 4 0.00 3 0.7 0.7 0.05 fancyRpartPlot(arbol_1) #&gt; Error in fancyRpartPlot(arbol_1): no se pudo encontrar la función &quot;fancyRpartPlot&quot; Aunque, sin más información, no hay garantía de recuperar la forma original. set.seed(46654) prof_a &lt;- sample(c(&#39;Buena&#39;, &#39;Mala&#39;, &#39;Mala&#39;), 300, replace = T) prof_b &lt;- sample(c(&#39;Buena&#39;, &#39;Buena&#39;, &#39;Mala&#39;), 300, replace = T) carta &lt;- sample(c(&#39;A&#39;, &#39;B&#39;), 300, replace = T) datos_sim &lt;- data.frame(prof_a, prof_b, carta) # describimos las probabilidades probas &lt;- datos_sim %&gt;% distinct() %&gt;% mutate(proba = (prof_a == &#39;Mala&#39; &amp; carta == &#39;A&#39;) * 0.4 + (prof_b == &#39;Mala&#39; &amp; carta == &#39;B&#39;) * 0.4 + (prof_a == &#39;Buena&#39; &amp; carta == &#39;A&#39;) * 0.6 + (prof_b == &#39;Buena&#39; &amp; carta == &#39;B&#39;) * 0.8) # finalmente simulamos si consigue el trabajo datos_1 &lt;- inner_join(datos_sim, probas) #&gt; Joining, by = c(&quot;prof_a&quot;, &quot;prof_b&quot;, &quot;carta&quot;) datos_1$consigue &lt;- rbinom(nrow(datos_1), size = 1, prob = datos_1$prob) # usamos un árbol de decisión arbol_2 &lt;- rpart(consigue ~ prof_a + prof_b + carta, datos_1, method = &#39;class&#39;, cp = 0) printcp(arbol_2) #&gt; #&gt; Classification tree: #&gt; rpart(formula = consigue ~ prof_a + prof_b + carta, data = datos_1, #&gt; method = &quot;class&quot;, cp = 0) #&gt; #&gt; Variables actually used in tree construction: #&gt; [1] carta prof_a prof_b #&gt; #&gt; Root node error: 127/300 = 0.4 #&gt; #&gt; n= 300 #&gt; #&gt; CP nsplit rel error xerror xstd #&gt; 1 0.09 0 1.0 1.0 0.07 #&gt; 2 0.04 1 0.9 1.0 0.07 #&gt; 3 0.02 3 0.8 0.9 0.07 #&gt; 4 0.00 5 0.8 0.8 0.07 fancyRpartPlot(arbol_2) #&gt; Error in fancyRpartPlot(arbol_2): no se pudo encontrar la función &quot;fancyRpartPlot&quot; # usamos un árbol de decisión arbol_3 &lt;- rpart(consigue ~ prof_a + prof_b + carta, datos_1, method = &#39;class&#39;, cp = 0, cost = c(100, 100, 1)) printcp(arbol_3) #&gt; #&gt; Classification tree: #&gt; rpart(formula = consigue ~ prof_a + prof_b + carta, data = datos_1, #&gt; method = &quot;class&quot;, cost = c(100, 100, 1), cp = 0) #&gt; #&gt; Variables actually used in tree construction: #&gt; [1] carta prof_a prof_b #&gt; #&gt; Root node error: 127/300 = 0.4 #&gt; #&gt; n= 300 #&gt; #&gt; CP nsplit rel error xerror xstd #&gt; 1 0.07 0 1.0 1.0 0.07 #&gt; 2 0.00 3 0.8 0.8 0.06 fancyRpartPlot(arbol_3) #&gt; Error in fancyRpartPlot(arbol_3): no se pudo encontrar la función &quot;fancyRpartPlot&quot; 2.3.4 Modelos lineales generalizados Otra técnica es utilizar modelos logísticos multinomiales (o simplemente logístico cuando la respuesta tiene 2 niveles). La ventaja de este enfoque es que podemos controlar la complejidad del modelo a través de inclusión/exclusión de interacciones y regularización. net_enigh &lt;- hc(dat_ing_f, score=&#39;aic&#39;, blacklist = black) #&gt; Error in hc(dat_ing_f, score = &quot;aic&quot;, blacklist = black): no se pudo encontrar la función &quot;hc&quot; net_enigh #&gt; Error in eval(expr, envir, enclos): objeto &#39;net_enigh&#39; no encontrado fit_enigh &lt;- bn.fit(net_enigh, data = dat_ing_f, method=&#39;mle&#39;) #&gt; Error in bn.fit(net_enigh, data = dat_ing_f, method = &quot;mle&quot;): no se pudo encontrar la función &quot;bn.fit&quot; graphviz.plot(net_enigh) #&gt; Error in graphviz.plot(net_enigh): no se pudo encontrar la función &quot;graphviz.plot&quot; Nos interesa el nodo de posesión de vehículo dado decil, nivel aprobado del jefe de familia y sexo del jefe de familia. En este caso, utilizaremos un modelo logístico regularizado. Los datos se ven como sigue: library(tidyr) dat_res &lt;- dat_ing_f %&gt;% group_by(sexojefe, nivelaprob, decil, vehiculo) %&gt;% dplyr::summarise(num = n()) %&gt;% group_by(sexojefe, nivelaprob, decil) %&gt;% mutate(total = sum(num)) %&gt;% ungroup() %&gt;% mutate(prop = num/total) #&gt; Error in eval(lhs, parent, parent): objeto &#39;dat_ing_f&#39; no encontrado dat_res #&gt; Error in eval(expr, envir, enclos): objeto &#39;dat_res&#39; no encontrado dat_res_sub &lt;- filter(dat_res, vehiculo==TRUE, num &gt; 5) #&gt; Error in filter(dat_res, vehiculo == TRUE, num &gt; 5): objeto &#39;dat_res&#39; no encontrado cuadrado &lt;- function(x){x ^ 2} ggplot(dat_res_sub, aes(x = nivelaprob, y = prop, colour = decil, group = decil)) + geom_point(aes(size = sqrt(num))) + geom_line() + facet_wrap(~sexojefe) + scale_size_continuous(&quot;# obs.&quot;, labels = cuadrado) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) #&gt; Error in ggplot(dat_res_sub, aes(x = nivelaprob, y = prop, colour = decil, : objeto &#39;dat_res_sub&#39; no encontrado Comenzamos con un modelo simple, con poca regularización: library(arm) #&gt; Error in library(arm): there is no package called &#39;arm&#39; # vemos como se ve la variable vehículo table(dat_ing$vehiculo) #&gt; Error in table(dat_ing$vehiculo): objeto &#39;dat_ing&#39; no encontrado dat_ing$vehiculo_l &lt;- as.logical(dat_ing$vehiculo == &quot;TRUE&quot;) #&gt; Error in eval(expr, envir, enclos): objeto &#39;dat_ing&#39; no encontrado table(dat_ing$vehiculo_l) #&gt; Error in table(dat_ing$vehiculo_l): objeto &#39;dat_ing&#39; no encontrado # modelo con poca regularización mod_1 &lt;- bayesglm(vehiculo_l ~ sexojefe + nivelaprob + decil, data = dat_ing, prior.scale = 2.5, family = &#39;binomial&#39;) #&gt; Error in bayesglm(vehiculo_l ~ sexojefe + nivelaprob + decil, data = dat_ing, : no se pudo encontrar la función &quot;bayesglm&quot; display(mod_1) #&gt; Error in display(mod_1): no se pudo encontrar la función &quot;display&quot; mod_1$aic #&gt; Error in eval(expr, envir, enclos): objeto &#39;mod_1&#39; no encontrado Agregamos las interacciones de sexojefe con decil. mod_2 &lt;- bayesglm(vehiculo ~ sexojefe + nivelaprob + decil + sexojefe:decil, data = dat_ing, prior.scale = 2.5, family = &#39;binomial&#39;) #&gt; Error in bayesglm(vehiculo ~ sexojefe + nivelaprob + decil + sexojefe:decil, : no se pudo encontrar la función &quot;bayesglm&quot; display(mod_2) #&gt; Error in display(mod_2): no se pudo encontrar la función &quot;display&quot; mod_2$aic #&gt; Error in eval(expr, envir, enclos): objeto &#39;mod_2&#39; no encontrado Agregamos ahora la interacción sexojefe con nivelaprob, notemos que incluir esta interacción incrementa considerablemente el aic, mod_3 &lt;- bayesglm(vehiculo ~ sexojefe + nivelaprob + decil + sexojefe:nivelaprob + decil:nivelaprob, data = dat_ing, prior.scale = 2.5, family = &#39;binomial&#39;) #&gt; Error in bayesglm(vehiculo ~ sexojefe + nivelaprob + decil + sexojefe:nivelaprob + : no se pudo encontrar la función &quot;bayesglm&quot; display(mod_3) #&gt; Error in display(mod_3): no se pudo encontrar la función &quot;display&quot; mod_3$aic #&gt; Error in eval(expr, envir, enclos): objeto &#39;mod_3&#39; no encontrado Ahora vemos las probabilidades estimadas del modelo 2: # creamos una base con todas las combinaciones de niveles de las variables grid_1 &lt;- expand.grid(list(sexojefe = unique(dat_ing$sexojefe), nivelaprob = unique(dat_ing$nivelaprob), decil = unique(dat_ing$decil)), stringsAsFactors = FALSE) #&gt; Error in unique(dat_ing$sexojefe): objeto &#39;dat_ing&#39; no encontrado # calculamos la probabilidad para cada caso usando predict grid_1$prob &lt;- predict(mod_2, grid_1, type = &#39;response&#39;) #&gt; Error in predict(mod_2, grid_1, type = &quot;response&quot;): objeto &#39;mod_2&#39; no encontrado grid_1$metodo &lt;- &quot;logística&quot; #&gt; Error in grid_1$metodo &lt;- &quot;logística&quot;: objeto &#39;grid_1&#39; no encontrado # obtenemos la siguietnte base de datos head(grid_1) #&gt; Error in head(grid_1): objeto &#39;grid_1&#39; no encontrado # y unimos con proporciones (MLE) para comparar dat_res$metodo &lt;- &quot;proporción&quot; #&gt; Error in dat_res$metodo &lt;- &quot;proporción&quot;: objeto &#39;dat_res&#39; no encontrado probs_est &lt;- filter(dat_res, vehiculo == TRUE) %&gt;% dplyr::select(sexojefe, nivelaprob, decil, prob = prop, metodo) %&gt;% rbind(grid_1) %&gt;% filter(nivelaprob != &quot;No esp&quot;) #&gt; Error in filter(dat_res, vehiculo == TRUE): objeto &#39;dat_res&#39; no encontrado ggplot(probs_est, aes(x = nivelaprob, y = prob, colour = decil, group = decil)) + geom_line() + facet_grid(metodo ~ sexojefe) + theme(axis.text.x=element_text(angle = 45, hjust = 1)) #&gt; Error in ggplot(probs_est, aes(x = nivelaprob, y = prob, colour = decil, : objeto &#39;probs_est&#39; no encontrado Y podemos incluir intervalos de probabilidad. # realizamos simulaciones de los parámetros sims &lt;- sim(mod_2, 100) #&gt; Error in sim(mod_2, 100): no se pudo encontrar la función &quot;sim&quot; str(sims) #&gt; Error in str(sims): objeto &#39;sims&#39; no encontrado # y los utilizamos en la función predict mod_2$coefficients &lt;- sims@coef[3, ] #&gt; Error in eval(expr, envir, enclos): objeto &#39;sims&#39; no encontrado grid_1$prob &lt;- predict(mod_2, grid_1, type=&#39;response&#39;) #&gt; Error in predict(mod_2, grid_1, type = &quot;response&quot;): objeto &#39;mod_2&#39; no encontrado # repetimos este procedimiento para cada conjunto de coeficientes simulados dat_sims &lt;- ldply(1:100, function(i){ mod_2$coefficients &lt;- sims@coef[i, ] grid_1$prob &lt;- predict(mod_2, grid_1, type=&#39;response&#39;) grid_1$sim_no &lt;- i grid_1 }) #&gt; Error in FUN(X[[i]], ...): objeto &#39;sims&#39; no encontrado # calculamos los cuantiles a partir de las probabilidades simuladas dat_sims_1 &lt;- dat_sims %&gt;% group_by(sexojefe, nivelaprob, decil) %&gt;% summarise( media = mean(prob), q_10 = quantile(prob, 0.1), q_90 = quantile(prob,0.9) ) %&gt;% filter(nivelaprob != &#39;No esp&#39;) #&gt; Error in eval(lhs, parent, parent): objeto &#39;dat_sims&#39; no encontrado ggplot(dat_sims_1, aes(x = nivelaprob, y = media, colour = decil, group = decil, ymin = q_10, ymax = q_90)) + geom_point() + geom_line() + facet_wrap(~ sexojefe) + geom_linerange()+ theme(axis.text.x = element_text(angle = 45, hjust = 1)) #&gt; Error in ggplot(dat_sims_1, aes(x = nivelaprob, y = media, colour = decil, : objeto &#39;dat_sims_1&#39; no encontrado Finalmente checamos la calibración del modelo con los datos (las probabilidades estimadas reflejan probabilidades empíricas: library(Hmisc) # función cut2 #&gt; Loading required package: lattice #&gt; Loading required package: survival #&gt; #&gt; Attaching package: &#39;survival&#39; #&gt; The following object is masked from &#39;package:rpart&#39;: #&gt; #&gt; solder #&gt; Loading required package: Formula #&gt; #&gt; Attaching package: &#39;Hmisc&#39; #&gt; The following objects are masked from &#39;package:plyr&#39;: #&gt; #&gt; is.discrete, summarize #&gt; The following objects are masked from &#39;package:dplyr&#39;: #&gt; #&gt; src, summarize #&gt; The following objects are masked from &#39;package:base&#39;: #&gt; #&gt; format.pval, units mod_2 &lt;- bayesglm(vehiculo ~ sexojefe + nivelaprob + decil + sexojefe:decil, data = dat_ing, prior.scale = 2.5, family = &#39;binomial&#39;) #&gt; Error in bayesglm(vehiculo ~ sexojefe + nivelaprob + decil + sexojefe:decil, : no se pudo encontrar la función &quot;bayesglm&quot; # predecimos para las observaciones en la base de datos dat_ing$prob &lt;- predict(mod_2, type = &#39;response&#39;) #&gt; Error in predict(mod_2, type = &quot;response&quot;): objeto &#39;mod_2&#39; no encontrado dat_cal &lt;- dat_ing_f %&gt;% mutate( prob = predict(mod_2, type = &#39;response&#39;), grupo_prob = cut2(prob, g = 20, levels.mean = TRUE) ) %&gt;% group_by(grupo_prob) %&gt;% summarise( num = n(), total_vehiculo = sum(vehiculo == TRUE) ) %&gt;% mutate( prob_emp = total_vehiculo / num, grupo_prob_n = as.numeric(as.character(grupo_prob)) ) #&gt; Error in eval(lhs, parent, parent): objeto &#39;dat_ing_f&#39; no encontrado ggplot(dat_cal, aes(x = grupo_prob_n, y = prob_emp)) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;) + geom_point() + xlab(&quot;Probabilidades empíricas&quot;) + ylab(&quot;Probabilidades estimadas&quot;) #&gt; Error in ggplot(dat_cal, aes(x = grupo_prob_n, y = prob_emp)): objeto &#39;dat_cal&#39; no encontrado Y obtenemos la tabla de la probabilidad condicional, grid_1 #&gt; Error in eval(expr, envir, enclos): objeto &#39;grid_1&#39; no encontrado que incluimos a nuestro modelo local en la red: fit_enigh &lt;- bn.fit(net_enigh, data = dat_ing_f, method = &#39;mle&#39;) #&gt; Error in bn.fit(net_enigh, data = dat_ing_f, method = &quot;mle&quot;): no se pudo encontrar la función &quot;bn.fit&quot; fit_enigh[[&#39;vehiculo&#39;]] #&gt; Error in eval(expr, envir, enclos): objeto &#39;fit_enigh&#39; no encontrado grid_1$vehiculo &lt;- &#39;TRUE&#39; #&gt; Error in grid_1$vehiculo &lt;- &quot;TRUE&quot;: objeto &#39;grid_1&#39; no encontrado grid_2 &lt;- grid_1 #&gt; Error in eval(expr, envir, enclos): objeto &#39;grid_1&#39; no encontrado grid_2$prob &lt;- 1-grid_2$prob #&gt; Error in eval(expr, envir, enclos): objeto &#39;grid_2&#39; no encontrado grid_2$vehiculo &lt;- &#39;FALSE&#39; #&gt; Error in grid_2$vehiculo &lt;- &quot;FALSE&quot;: objeto &#39;grid_2&#39; no encontrado grid_3 &lt;- rbind(grid_1, grid_2) #&gt; Error in rbind(grid_1, grid_2): objeto &#39;grid_1&#39; no encontrado tab_veh &lt;- xtabs(prob ~ vehiculo + decil + nivelaprob + decil + sexojefe, data = grid_3) #&gt; Error in terms.formula(formula, data = data): objeto &#39;grid_3&#39; no encontrado tab_veh #&gt; Error in eval(expr, envir, enclos): objeto &#39;tab_veh&#39; no encontrado fit_enigh_b[[&#39;vehiculo&#39;]] &lt;- tab_veh #&gt; Error in eval(expr, envir, enclos): objeto &#39;tab_veh&#39; no encontrado 2.3.5 Nodos multinomiales En el siguiente ejemplo veremos cómo hacer un modelo multinomial: modelamos decil dado marginación y nivelaprobado. Utilizaremos una combinación de regresión Ridge y Lasso con el fin de regularizar, para esto usamos el paquete glmnet. library(glmnet) #&gt; Error in library(glmnet): there is no package called &#39;glmnet&#39; mat_1 &lt;- model.matrix(~ -1 + marg + nivelaprob + marg:nivelaprob, data = dat_ing) #&gt; Error in terms.formula(object, data = data): objeto &#39;dat_ing&#39; no encontrado mod_decil &lt;- cv.glmnet(y = dat_ing$decil, x = mat_1, alpha = 0.5, family = &#39;multinomial&#39;) #&gt; Error in cv.glmnet(y = dat_ing$decil, x = mat_1, alpha = 0.5, family = &quot;multinomial&quot;): no se pudo encontrar la función &quot;cv.glmnet&quot; plot(mod_decil) #&gt; Error in plot(mod_decil): objeto &#39;mod_decil&#39; no encontrado Hacemos las predicciones: grid_pred &lt;- expand.grid(list(marg = unique(dat_ing$marg), nivelaprob = unique(dat_ing$nivelaprob)), stringsAsFactors = FALSE) #&gt; Error in unique(dat_ing$marg): objeto &#39;dat_ing&#39; no encontrado mat_pred &lt;- model.matrix(~ -1 + marg + nivelaprob + marg:nivelaprob, data = grid_pred) #&gt; Error in terms.formula(object, data = data): objeto &#39;grid_pred&#39; no encontrado mod_decil_pred &lt;- predict(mod_decil, s = exp(-4), type = &#39;response&#39;, newx = mat_pred)[, , 1] #&gt; Error in predict(mod_decil, s = exp(-4), type = &quot;response&quot;, newx = mat_pred): objeto &#39;mod_decil&#39; no encontrado dat_pred &lt;- cbind(grid_pred, mod_decil_pred) #&gt; Error in cbind(grid_pred, mod_decil_pred): objeto &#39;grid_pred&#39; no encontrado head(dat_pred) #&gt; Error in head(dat_pred): objeto &#39;dat_pred&#39; no encontrado Y ahora podemos examinar cómo están las predicciones del modelo. dat_pred_l &lt;- gather(dat_pred, nivel_decil, prob, 3:12) #&gt; Error in gather(dat_pred, nivel_decil, prob, 3:12): objeto &#39;dat_pred&#39; no encontrado ggplot(dat_pred_l, aes(x = nivelaprob, y = prob, colour = marg, group = marg)) + geom_point() + geom_line() + facet_wrap(~ nivel_decil, nrow=2) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) #&gt; Error in ggplot(dat_pred_l, aes(x = nivelaprob, y = prob, colour = marg, : objeto &#39;dat_pred_l&#39; no encontrado colnames(dat_pred_l)[3] &lt;- &quot;decil&quot; #&gt; Error in colnames(dat_pred_l)[3] &lt;- &quot;decil&quot;: objeto &#39;dat_pred_l&#39; no encontrado tab_decil &lt;- xtabs(prob ~ decil + marg + nivelaprob, data = dat_pred_l) #&gt; Error in terms.formula(formula, data = data): objeto &#39;dat_pred_l&#39; no encontrado tab_veh #&gt; Error in eval(expr, envir, enclos): objeto &#39;tab_veh&#39; no encontrado fit_enigh_b[[&#39;decil&#39;]] &lt;- tab_decil #&gt; Error in eval(expr, envir, enclos): objeto &#39;tab_decil&#39; no encontrado Exporta la red a SAMIAM y compara con la red que usó MLE. #&gt; Error in library(bnlearn): there is no package called &#39;bnlearn&#39; #&gt; Error in library(gRbase): there is no package called &#39;gRbase&#39; #&gt; Error in library(igraph): there is no package called &#39;igraph&#39; Hasta ahora hemos considerado ajuste de modelos locales para estructuras gráficas ya dadas. Aunque en algunos casos la estructura de la red está dada por algún experto o restricciones naturales del fenómeno que nos interesa, también es común que tengamos que aprender la estructura a partir de los datos. Vale la pena considerar los escenarios bajo los cuales se busca aprender una red. Buscamos construir un modelo que nos permita responder queries probabilísticos generales (mismo objetivo que si elicito la red con conocimiento experto). Buscamos predecir nuevas observaciones. Predecir variables objetivo \\(y\\) (vector) a partir de observaciones. Un ejemplo es en clasificación de imágenes o procesamiento de lenguaje. No nos interesa una tarea de inferencia particular, sino descubrir conocimiento o estructura: distinguir entre dependencias directas e indirectas, posibles direccionalidades de los arcos. Los objetivos anteriores se pueden satisfacer usando otras técnicas, algunas de las razones o situaciones por las que se utilizan modelos gráficos son: i) se busca predicción de objetos estructurados (explotar las correlaciones sobre varias variables), ii) se desea incorporar conocimiento experto al modelo, iii) tenemos un modelo unificado para múltiples variables, iv) es un marco para descubrir conocimiento. Ahora, para aprender estructura existen dos tipos generales de algoritmos: Aprendizaje basado en restricciones: algoritmos basados en pruebas de hipótesis de independencia entre variables. En este caso, el algoritmo se enfoca en explicar las relaciones de independencia y dependencia. Aprendizaje basado en scores: estos algoritmos consideran las posibles estructuras gráficas como distintos modelos, de tal manera que el problema se convierte en uno de maximizar algún score que califica los distintos modelos. Es decir: definimos primero \\(score({\\mathcal G},p)\\), donde \\({\\mathcal G}\\) es una gráfica y \\(p\\) una distribución de probabilidad conjunta que se factoriza sobre \\({\\mathcal G}\\), e intentamos resolver (o aproximar una solución) al problema \\[\\max_{\\mathcal G, p} score(\\mathcal G,p)\\] En estas notas nos concentramos en aprendizaje basado en scores. Para esto, tendremos que definir una función apropiada de score, y una manera de aproximar la solución del problema de maximización mostrado arriba. Nuestro enfoque será heurístico, pues el problema de encontrar una solución exacta (máximo global) rápidamente se vuelve intratable conforme el número de nodos crece. Si tenemos \\(k\\) variables, y consideramos un solo ordenamiento \\(X_1,\\ldots, X_k\\), entonces hay un total de \\(2^1(2^2)\\cdots (2^{k-1})=2^{k(k-1)/2}\\) redes distintas que satisfacen el ordenamiento. "],
["scores-de-estructura.html", "2.4 Scores de estructura", " 2.4 Scores de estructura 2.4.1 Máxima verosimilitud Un posible score es la verosimilitud. Podríamos escoger un modelo, de entre todas las estructuras y parámetros posibles, usando máxima verosimilitud. Sin embargo, este enfoque no es apropiado para selección de modelos pues la verosimilitud siempre aumenta con la complejidad del modelo (aunque puede ser apropiado para estimar parámetros cuando la estructura es fija), y dado que el espacio de modelos con el que tratamos aquí generalmente es muy grande, es fácil sobreajustar los datos. Cuando sobreajustamos terminamos con modelos grandes, poco parsimoniosos y ruidosos que son difíciles de interpretar y que son malos en el pronóstico o la estimación de probabilidades condicionales. Para entender esto recordemos máxima verosimilitud, supongamos que tenemos la muestra \\[{\\mathcal L}= \\{x^{(1)},x^{(2)}, \\ldots, x^{(N)} \\},\\] donde cada \\(x^{(i)}\\) es una observación conjunta de las \\(k\\) variables \\(X_1,X_2,\\ldots, X_k\\): \\[x^{(i)}=(x^{(i)}_1,\\ldots, x^{(i)}_k).\\] Ejemplo. library(plyr) library(dplyr) adm &lt;- read.csv(&quot;datos/admisiones.csv&quot;, stringsAsFactors = FALSE) #&gt; Warning in file(file, &quot;rt&quot;): no fue posible abrir el archivo &#39;datos/ #&gt; admisiones.csv&#39;: No such file or directory #&gt; Error in file(file, &quot;rt&quot;): no se puede abrir la conexión head(adm) #&gt; Error in head(adm): objeto &#39;adm&#39; no encontrado adm_sub &lt;- filter(adm, Dept %in% c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)) #&gt; Error in filter(adm, Dept %in% c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)): objeto &#39;adm&#39; no encontrado En este ejemplo \\(N=4,526\\) y \\(k=3\\). Cada \\(x^{(i)}\\) es un renglón de la tabla. Sea \\({\\mathcal G}\\) una gráfica sobre los nodos \\(X_1,\\ldots, X_k\\), y \\(p\\) una conjunta que se factoriza sobre \\({\\mathcal G}\\). La verosimilitud de la red \\(({\\mathcal G}, p)\\) es la probabilidad de observar los datos de entrenamiento \\(\\mathcal L\\) dado el modelo \\(({\\mathcal G}, p),\\) y la denotamos por \\[L({\\mathcal G}, p; {\\mathcal L}).\\] Recordamos que si \\(\\mathcal L\\) es una muestra, entonces \\[L({\\mathcal G}, p; {\\mathcal L})=\\prod_{i=1}^N p(x^{(i)}). \\] Entonces, buscamos maximizar esta verosimilitud sobre estructuras \\({\\mathcal G}\\) junto con una conjunta \\(p\\) que se factoriza sobre \\({\\mathcal G}\\), es decir resolver \\[\\max_{({\\mathcal G}, p)} L({\\mathcal G}, p; {\\mathcal L})= \\max_{\\mathcal G} \\max_{p\\in M({\\mathcal G})} \\prod_{i=1}^N p(x^{(i)}) \\] Este problema es paramétrico, y podemos parametrizarlo usando los modelos locales que produce la factorización de \\(p\\) sobre \\(\\mathcal G\\). Ejemplo. Consideremos el modelo Gender -&gt; Admit. Ambas variables tienen dos niveles, así que la conjunta se parametriza con 3 probabilidades. Como \\(p\\) se factoriza sobre la gráfica Gender -&gt; Admit tenemos: \\[p(Gender,Admit)=p(Gender)p(Admit|Gender),\\] podemos parametrizar con \\[\\theta_1=p(Female), \\theta_2=p(Admitted|Female), \\theta_3=p(Admitted|Male),\\] el resto de las probabilidades del modelo se calculan complementando estas tres. Escribimos la verosimilitud haciendo explícitos los parámetros mediante \\[L( {\\mathcal G},\\theta_{\\mathcal G};{\\mathcal L} ),\\] donde \\(\\theta_{\\mathcal G}\\) representa los parámetros necesarios para obtener la conjunta \\(p\\) que se factorizan sobre la estructura \\(\\mathcal G\\). Con esta nueva notación, escribimos también: \\[L( {\\mathcal G},\\theta_{\\mathcal G};{\\mathcal L} )= \\prod_{i=1}^N p(x^{(i)};\\theta_{\\mathcal G})\\] donde $ p(x^{(i)};_{G})$ es la probabilidad conjunta de la observación \\(x^{(i)}\\) dados los parámetros \\(\\theta_{\\mathcal G}\\). Ahora escribimos en términos de la factorización sobre \\(\\mathcal G\\): \\[p(x^{(i)},\\theta_{\\mathcal G})=\\prod_{j=1}^k p(x^{i}_j|x^{(i)};\\theta_{\\mathcal G}).\\] Y finalmente, observamos que en el \\(j\\)-ésimo factor \\(p(x^{i}_j|x^{(i)};\\theta_{\\mathcal G})\\), esta probabilidad sólo depende de las entradas de \\(x^{(i)}\\) que están en el conjunto de padres de \\(X_j\\), y además, que sólo depende de los parámetros en \\(\\theta_{\\mathcal G}\\) que se refieren a la parametrización del modelo local de \\(X_j\\). Ejemplo En nuestro ejemplo anterior, tenemos que, para cualquier dato \\(x^{(i)}=(a^{i}, g^{i})\\), podríamos escribir \\[p(a^{i};\\theta_1)p(g^{i}|a^{i};\\theta_2, \\theta_3).\\] El primer factor sólo depende de la primera coordenada \\(a^{(i)}\\) de \\(x^{(i)}\\) y del parámetro \\(\\theta_1\\). El segundo factor depende de ambas coordenadas de \\(x^{(i)}\\) pero solamente de \\(\\theta_2, \\theta_3.\\) Por lo tanto, la verosimilitud es: \\[L(Gender-&gt;Admit,(\\theta_1,\\theta_2,\\theta_3);{\\mathcal L})=\\prod_{i=1}^N p(a^{i};\\theta_1)p(g^{i}|a^{i};\\theta_2, \\theta_3),\\] Una vez que analizamos el ejemplo es fácil ver que tenemos el siguiente resultado: La verosimilitud de una conjunta \\(p\\) que se factoriza sobre \\(\\mathcal G\\) tiene una descomposición global en factores, donde en cada factor sólo intervienen los datos necesarios para los modelos locales y los parámetros correspondientes a cada modelo local. Este resultado implica en particular que dada una gráfica \\(\\mathcal G\\), la solución de máxima verosimilitud se puede calcular maximizando individualmente cada factor o modelo local, que es precisamente lo que explicamos en la clase anterior (usando tablas de frecuencias). Usualmente trabajaremos con la log-verosimilitud, que está dada por \\[loglik( {\\mathcal G},\\theta_{\\mathcal G};{\\mathcal L} )= \\sum_{j=1}^k \\sum_{i=1}^N \\log p(x^{i}_j|x^{(i)};\\theta_{\\mathcal G}).\\] Muchas veces trabajamos también con la devianza, que es más útil para comparar modelos a lo largo de conjuntos de datos con distinto tamaño \\(N\\). La devianza se define como sigue: \\[Dev =-\\frac{2}{N}loglik( {\\mathcal G},\\theta_{\\mathcal G};{\\mathcal L} )= -\\frac{2}{N}\\sum_{j=1}^k \\sum_{i=1}^N \\log p(x^{(i)},\\theta_{\\mathcal G})\\] Nótese que maximizar la verosimilitud es equivalente a maximizar la log-verosimilitud, y estas dos son equivalentes a minimizar la devianza. Ejemplo. Si fijamos \\(\\mathcal G\\) como la red con una sola arista que va de Gender a Admit, y dejamos sin aristas a Dept, tenemos que estimar 2 parámetros para la marginal de Dept, 1 parámetro para la marginal de Gender, y 2 parámetros para la condicional de Admit dado Gender. Así que \\(\\theta_G\\) es un vector de longitud 5. Podemos construir manualmente la función de verosimilitud como mostramos en el código de abajo. En este ejemplo, usamos una parametrización tipo logístico apropiada para minimizar la devianza sin restricciones. Por ejemplo, en lugar de parametrizar la como \\((p_1,p_2)\\to (p_1,p_2,1-p_1-p_2)\\) la distribución sobre una variable que toma tres valores, usamos \\[(\\theta_1,\\theta_2) \\to \\frac{1}{1+e^\\theta_1+e^\\theta_2}(e^\\theta_1, e^\\theta_2,1),\\] y así los parámetros están libres. logVerosimilitud &lt;- function(datos) { # logVerosimilitud recibe como parámetro los datos y devuelve la función # de verosimilitud function(theta){ p_1 &lt;- exp(c(theta[1], 0)) / (1 + exp(theta[1])) p_2 &lt;- exp(c(theta[2], theta[3], 0)) / (1 + exp(theta[2]) + exp(theta[3])) p_3 &lt;- c(exp(c(theta[4], 0)) / (1 + exp(theta[4])), exp(c(theta[5], 0)) / (1 + exp(theta[5]))) factor_1 &lt;- data.frame(Gender = c(&#39;Male&#39;, &#39;Female&#39;), prob_1 = p_1, stringsAsFactors = FALSE) factor_2 &lt;- data.frame(Dept = c(&#39;A&#39;, &#39;B&#39;, &#39;C&#39;), prob_2 = p_2, stringsAsFactors = FALSE) factor_3 &lt;- data.frame( Admit = c(&#39;Admitted&#39;, &#39;Rejected&#39;, &#39;Admitted&#39;, &#39;Rejected&#39;), Gender=c(&#39;Male&#39;, &#39;Male&#39;, &#39;Female&#39;, &#39;Female&#39;), prob_3 = p_3, stringsAsFactors = FALSE) # producto cartesiano de los niveles grid &lt;- expand.grid( Gender=c(&#39;Male&#39;,&#39;Female&#39;), Admit=c(&#39;Admitted&#39;,&#39;Rejected&#39;), Dept=c(&#39;A&#39;,&#39;B&#39;,&#39;C&#39;), stringsAsFactors = FALSE) %&gt;% left_join(factor_1, by = &quot;Gender&quot;) %&gt;% # agregamos probabilidades left_join(factor_2, by = &#39;Dept&#39; ) %&gt;% left_join(factor_3, by = c(&#39;Admit&#39;, &#39;Gender&#39;)) dat_p &lt;- left_join(datos, grid, by = c(&#39;Gender&#39;, &#39;Dept&#39;, &#39;Admit&#39;)) # log-verosimilitud -sum(log(dat_p$prob_1) + log(dat_p$prob_2) + log(dat_p$prob_3)) } } logVer_1 &lt;- logVerosimilitud(adm_sub) class(logVer_1) #&gt; [1] &quot;function&quot; logVer_1(rep(log(0.1), 5)) #&gt; Error in left_join(datos, grid, by = c(&quot;Gender&quot;, &quot;Dept&quot;, &quot;Admit&quot;)): objeto &#39;adm_sub&#39; no encontrado Si optimizamos numéricamente, obtenemos: salida_1 &lt;- optim(rep(0.1, 5), logVer_1) #&gt; Warning in left_join(datos, grid, by = c(&quot;Gender&quot;, &quot;Dept&quot;, &quot;Admit&quot;)): #&gt; reiniciar evaluación premisa interrumpida #&gt; Error in left_join(datos, grid, by = c(&quot;Gender&quot;, &quot;Dept&quot;, &quot;Admit&quot;)): objeto &#39;adm_sub&#39; no encontrado (salida_1$par) #&gt; Error in eval(expr, envir, enclos): objeto &#39;salida_1&#39; no encontrado exp(salida_1$par[1]) / (1 + exp(salida_1$par[1])) #&gt; Error in eval(expr, envir, enclos): objeto &#39;salida_1&#39; no encontrado exp(salida_1$par[2]) / (1 + exp(salida_1$par[2]) + exp(salida_1$par[3])) #&gt; Error in eval(expr, envir, enclos): objeto &#39;salida_1&#39; no encontrado exp(salida_1$par[3]) / (1 + exp(salida_1$par[2]) + exp(salida_1$par[3])) #&gt; Error in eval(expr, envir, enclos): objeto &#39;salida_1&#39; no encontrado exp(salida_1$par[4]) / (1 + exp(salida_1$par[4])) #&gt; Error in eval(expr, envir, enclos): objeto &#39;salida_1&#39; no encontrado exp(salida_1$par[5]) / (1 + exp(salida_1$par[5])) #&gt; Error in eval(expr, envir, enclos): objeto &#39;salida_1&#39; no encontrado Como habíamos explicado, estas probabilidades son precisamente las estimaciones que se obtienen de las tablas de frecuencias (máxima verosimilitud en cada factor): prop.table(table(adm_sub$Gender)) #&gt; Error in table(adm_sub$Gender): objeto &#39;adm_sub&#39; no encontrado prop.table(table(adm_sub$Dept)) #&gt; Error in table(adm_sub$Dept): objeto &#39;adm_sub&#39; no encontrado prop.table(table(adm_sub$Admit, adm_sub$Gender), 2) #&gt; Error in table(adm_sub$Admit, adm_sub$Gender): objeto &#39;adm_sub&#39; no encontrado La verosimilitud alcanzada es -salida_1$value #&gt; Error in eval(expr, envir, enclos): objeto &#39;salida_1&#39; no encontrado Repetimos el cálculo usando las función bn.fit de bnlearn con el fin de verificar que obtenemos el mismo resultado: adm_sub_1 &lt;- adm_sub %&gt;% select(-id) %&gt;% mutate_each(funs(as.factor)) #&gt; Error in eval(lhs, parent, parent): objeto &#39;adm_sub&#39; no encontrado graf_adm_1 &lt;- empty.graph(c(&#39;Admit&#39;,&#39;Gender&#39;,&#39;Dept&#39;)) #&gt; Error in empty.graph(c(&quot;Admit&quot;, &quot;Gender&quot;, &quot;Dept&quot;)): no se pudo encontrar la función &quot;empty.graph&quot; arcs(graf_adm_1) &lt;- matrix(c(&#39;Gender&#39;, &#39;Admit&#39;), ncol = 2) #&gt; Error in arcs(graf_adm_1) &lt;- matrix(c(&quot;Gender&quot;, &quot;Admit&quot;), ncol = 2): objeto &#39;graf_adm_1&#39; no encontrado fit_1 &lt;- bn.fit(graf_adm_1, data = adm_sub_1) #&gt; Error in bn.fit(graf_adm_1, data = adm_sub_1): no se pudo encontrar la función &quot;bn.fit&quot; fit_1 #&gt; Error in eval(expr, envir, enclos): objeto &#39;fit_1&#39; no encontrado logLik(fit_1, data = adm_sub_1) #&gt; Error in logLik(fit_1, data = adm_sub_1): objeto &#39;fit_1&#39; no encontrado 2.4.2 Máxima verosimilitud y sobreajuste En muchos casos, utilizar máxima verosimilitud para estimar modelos complejos con datos relativamente ralos es mala idea, debido a que al intentar maximizar el ajuste podemos acabar ajustando ruido como si fuera estructura. Veamos que pasa si evaluamos distintas estructuras en nuestro ejemplo de admisiones: set.seed(6391572) adm_f &lt;- adm %&gt;% mutate_each(funs(factor), Admit, Gender, Dept) #&gt; Error in eval(lhs, parent, parent): objeto &#39;adm&#39; no encontrado # datos de entrenamiento adm_ent &lt;- sample_n(adm_f, 300) #&gt; Error in sample_n(adm_f, 300): objeto &#39;adm_f&#39; no encontrado #datos de validación adm_val &lt;- anti_join(adm_f, adm_ent, by = &quot;id&quot;) #&gt; Error in anti_join(adm_f, adm_ent, by = &quot;id&quot;): objeto &#39;adm_f&#39; no encontrado Comparamos 3 modelos: modelo_0 &lt;- empty.graph(c(&#39;Gender&#39;, &#39;Dept&#39;, &#39;Admit&#39;)) #&gt; Error in empty.graph(c(&quot;Gender&quot;, &quot;Dept&quot;, &quot;Admit&quot;)): no se pudo encontrar la función &quot;empty.graph&quot; modelo_1 &lt;- modelo_0 #&gt; Error in eval(expr, envir, enclos): objeto &#39;modelo_0&#39; no encontrado arcs(modelo_1) &lt;- matrix(c(&#39;Gender&#39;, &#39;Dept&#39;), ncol = 2, byrow = T) #&gt; Error in arcs(modelo_1) &lt;- matrix(c(&quot;Gender&quot;, &quot;Dept&quot;), ncol = 2, byrow = T): objeto &#39;modelo_1&#39; no encontrado modelo_2 &lt;- modelo_0 #&gt; Error in eval(expr, envir, enclos): objeto &#39;modelo_0&#39; no encontrado arcs(modelo_2) &lt;- matrix(c(&#39;Gender&#39;, &#39;Dept&#39;, &#39;Dept&#39;, &#39;Admit&#39;), ncol = 2, byrow = T) #&gt; Error in arcs(modelo_2) &lt;- matrix(c(&quot;Gender&quot;, &quot;Dept&quot;, &quot;Dept&quot;, &quot;Admit&quot;), : objeto &#39;modelo_2&#39; no encontrado modelo_3 &lt;- modelo_0 #&gt; Error in eval(expr, envir, enclos): objeto &#39;modelo_0&#39; no encontrado arcs(modelo_3) &lt;- matrix(c(&#39;Gender&#39;, &#39;Dept&#39;, &#39;Dept&#39;, &#39;Admit&#39;, &#39;Gender&#39;, &#39;Admit&#39;), ncol = 2, byrow = T) #&gt; Error in arcs(modelo_3) &lt;- matrix(c(&quot;Gender&quot;, &quot;Dept&quot;, &quot;Dept&quot;, &quot;Admit&quot;, : objeto &#39;modelo_3&#39; no encontrado El modelo más sencillo corresponde a independencia, adm_ent &lt;- select(adm_ent, -id) #&gt; Error in select(adm_ent, -id): objeto &#39;adm_ent&#39; no encontrado plot(modelo_0, radius = 220) #&gt; Error in plot(modelo_0, radius = 220): objeto &#39;modelo_0&#39; no encontrado fit_0 &lt;- bn.fit(modelo_0, data = adm_ent) #&gt; Error in bn.fit(modelo_0, data = adm_ent): no se pudo encontrar la función &quot;bn.fit&quot; devianza_0 &lt;- -2 * logLik(fit_0, data = adm_ent) / nrow(adm_ent) #&gt; Error in logLik(fit_0, data = adm_ent): objeto &#39;fit_0&#39; no encontrado devianza_0 #&gt; Error in eval(expr, envir, enclos): objeto &#39;devianza_0&#39; no encontrado Ahora consideramos un arco de Gender a Dept, notamos que se reduce la devianza: plot(modelo_1, radius = 220) #&gt; Error in plot(modelo_1, radius = 220): objeto &#39;modelo_1&#39; no encontrado fit_1 &lt;- bn.fit(modelo_1, data = adm_ent) #&gt; Error in bn.fit(modelo_1, data = adm_ent): no se pudo encontrar la función &quot;bn.fit&quot; devianza_1 &lt;- -2 * logLik(fit_1, data = adm_ent) / nrow(adm_ent) #&gt; Error in logLik(fit_1, data = adm_ent): objeto &#39;fit_1&#39; no encontrado devianza_1 #&gt; Error in eval(expr, envir, enclos): objeto &#39;devianza_1&#39; no encontrado Agregamos un arco de Dept a Admit, plot(modelo_2, radius = 220) #&gt; Error in plot(modelo_2, radius = 220): objeto &#39;modelo_2&#39; no encontrado fit_2 &lt;- bn.fit(modelo_2, data = adm_ent) #&gt; Error in bn.fit(modelo_2, data = adm_ent): no se pudo encontrar la función &quot;bn.fit&quot; devianza_2 &lt;- -2 * logLik(fit_2, data = adm_ent) / nrow(adm_ent) #&gt; Error in logLik(fit_2, data = adm_ent): objeto &#39;fit_2&#39; no encontrado devianza_2 #&gt; Error in eval(expr, envir, enclos): objeto &#39;devianza_2&#39; no encontrado Y finalmente agregamos un arco más de Gender a Admit: plot(modelo_3, radius = 220) #&gt; Error in plot(modelo_3, radius = 220): objeto &#39;modelo_3&#39; no encontrado fit_3 &lt;- bn.fit(modelo_3, data = adm_ent) #&gt; Error in bn.fit(modelo_3, data = adm_ent): no se pudo encontrar la función &quot;bn.fit&quot; devianza_3 &lt;- -2 * logLik(fit_3, data = adm_ent) / nrow(adm_ent) #&gt; Error in logLik(fit_3, data = adm_ent): objeto &#39;fit_3&#39; no encontrado devianza_3 #&gt; Error in eval(expr, envir, enclos): objeto &#39;devianza_3&#39; no encontrado En todos estos casos, la devianza se redujo, como esperábamos. Sin embargo, ¿qué pasa si observamos un nuevo conjunto de datos generado por el mismo fenómeno? ¿Cuál se desempeño de cada modelo, ¿Cuál explica mejor los nuevos datos? Calcularemos entonces la devianza con una muestra de validación, esta es una muestra independiente de la que se usó para ajustar los modelos. library(tidyr) library(ggplot2) adm_val &lt;- dplyr::select(adm_val, -id) #&gt; Error in dplyr::select(adm_val, -id): objeto &#39;adm_val&#39; no encontrado modelos &lt;- list(fit_0, fit_1, fit_2, fit_3) #&gt; Error in eval(expr, envir, enclos): objeto &#39;fit_0&#39; no encontrado resultados &lt;- ldply(1:4, function(i){ data.frame(modelo = i, dev_ent = -2 * logLik(modelos[[i]], data = adm_ent) / nrow(adm_ent), dev_val = -2 * logLik(modelos[[i]], data = adm_val) / nrow(adm_val)) }) #&gt; Error in logLik(modelos[[i]], data = adm_ent): objeto &#39;modelos&#39; no encontrado res_m &lt;- gather(resultados, muestra, devianza, dev_ent:dev_val) #&gt; Error in gather(resultados, muestra, devianza, dev_ent:dev_val): objeto &#39;resultados&#39; no encontrado ggplot(res_m, aes(x = modelo, y = devianza, colour = muestra, group = muestra)) + geom_point() + geom_line() #&gt; Error in ggplot(res_m, aes(x = modelo, y = devianza, colour = muestra, : objeto &#39;res_m&#39; no encontrado Al evaluar con una nueva muestra, vemos entonces que el modelo de tres arcos se desempeña peor o de manera similarque el modelo más simple con dos aristas. Esto sugiere que el modelo más parsimonioso es superior al que tiene tres aristas. El problema es que máxima verosimilitud siempre califica mejor a los modelos más complejos pues el ajuste a los datos de entrenamiento siempre es mejor con modelos más complejos. Sin embargo, la muestra de validación sugiere que esta ganancia en ajuste sólo es cierta para la muestra de entrenamiento, y no es replicable para otras muestras del mismo fenómeno. A su vez, esto indica que esa mejora en ajuste se debe a que el modelo más complejo mejoró porque está explicando variación muestral, o características de la muestra particular que usamos para entrenar. Pero estos resultados no son generalizables o replicables. Es posible seleccionar modelos usando muestras de validación (y es un enfoque muy robusto desde el punto de vista teórico), como hicimos arriba. Sin embargo, cuando no tenemos muchos datos, el modelo seleccionado puede ser uno relativamente malo en comparación a lo que obtendríamos con toda la muestra. En realidad no estamos desaprovechando datos (unos se usan para estimar parámetros y otros para seleccionar modelos), pero en casos donde hay muchas variables preferiremos hacer aproximaciones, en lugar de usar muestras de validación, para seleccionar modelos ajustados con la totalidad de los datos. 2.4.3 Penalización por complejidad y score AIC Una solución al problema de selección de modelos es cambiar la función de score por una que penalice la verosimilitud según el número de parámetros en el modelo. Una medida popular de este es el AIC (Aikaike information criterion). El AIC se define como El score AIC de un modelo se define como \\[AIC({\\mathcal G}, \\theta_{\\mathcal G}) = -\\frac{2}{N}loglik + \\frac{2d}{N}=Dev + \\frac{2d}{N},\\] donde \\(d\\) es el número de parámetros en \\(\\theta_{\\mathcal G}.\\) Nótemos que bajo este score, agregar una arista no necesariamente representa una mejora, pues aunque \\(loglik\\) no aumenta o disminuye, \\(d\\) definitivamente aumenta (añadimos variables en los modelos locales). Es decir, el AIC es una combinación de una medida de ajuste del modelo con una penalización por complejidad, donde medimos complejidad por el número de parámetros del modelo. El score AIC es una aproximación asintótica (\\(N\\) grande) al valor esperado de la devianza sobre datos de prueba, independientes de la muestra de entrenamiento o ajuste que utilizamos. Tiene sentido intentar minimizar este valor esperado: esto indica buen desempeño para observaciones fuera de nuestra muestra, que es en realidad lo que queremos lograr, e ignorar mejoras que sólo se deben a particularidades de nuestra muestra de entrenamiento. Nota: en algunos casos, el AIC se define en términos de log-verosimilitud como: \\[AIC_1 = loglik - d.\\] En este caso, buscamos maximizar \\(AIC_1\\), en lugar de minimizar \\(AIC\\). En el ejmplo de admisiones podemos ver que, loglike_2 &lt;- logLik(modelos[[2]], data = adm_ent) #&gt; Error in logLik(modelos[[2]], data = adm_ent): objeto &#39;modelos&#39; no encontrado aic_2 &lt;- AIC(modelos[[2]], data = adm_ent) #&gt; Error in AIC(modelos[[2]], data = adm_ent): objeto &#39;modelos&#39; no encontrado loglike_2 #&gt; Error in eval(expr, envir, enclos): objeto &#39;loglike_2&#39; no encontrado aic_2 #&gt; Error in eval(expr, envir, enclos): objeto &#39;aic_2&#39; no encontrado loglike_2 - aic_2 #&gt; Error in eval(expr, envir, enclos): objeto &#39;loglike_2&#39; no encontrado Efectivamente, el modelo 2 tiene 12 parámetros: modelos[[2]] #&gt; Error in eval(expr, envir, enclos): objeto &#39;modelos&#39; no encontrado ¿Qué modelo debemos elegir de acuerdo al AIC? resultados &lt;- ldply(1:4, function(i){ data.frame(modelo = i, dev_ent = -2 * logLik(modelos[[i]], data = adm_ent) / nrow(adm_ent), dev_val = -2 * logLik(modelos[[i]], data = adm_val) / nrow(adm_val), aic = -2 * AIC(modelos[[i]], data = adm_val) / nrow(adm_val)) }) #&gt; Error in logLik(modelos[[i]], data = adm_ent): objeto &#39;modelos&#39; no encontrado res_m &lt;- gather(resultados, muestra, devianza, dev_ent:aic) #&gt; Error in gather(resultados, muestra, devianza, dev_ent:aic): objeto &#39;resultados&#39; no encontrado ggplot(res_m, aes(x = modelo, y = devianza, colour = muestra, group = muestra)) + geom_point() + geom_line() #&gt; Error in ggplot(res_m, aes(x = modelo, y = devianza, colour = muestra, : objeto &#39;res_m&#39; no encontrado No hay garantía de escoger el modelo óptimo usando el AIC (según la experiencia tiende a escoger modelos quizá demasiado complejos), pero es una guía útil para controlar complejidad. Otra alternativa útil es el BIC, que también es un tipo de verosimilitud penalizada: Hay otros scores que se utilizan. Un ejemplo es el BIC (Bayesian Information Criterion), que en lugar de penalizar por \\(d\\), penaliza por \\(\\frac{\\log(N)}{2}d\\). Este criterio resulta en modelos más simples (ver referencia de Koller, 18.3.2). #&gt; Error in dag(c(&quot;D&quot;, &quot;A&quot;), c(&quot;D&quot;, &quot;B&quot;), c(&quot;D&quot;, &quot;C&quot;)): no se pudo encontrar la función &quot;dag&quot; #&gt; Error in graphviz.plot(as.bn(G_star), main = &quot;G*&quot;): no se pudo encontrar la función &quot;graphviz.plot&quot; #&gt; Error in dag(c(&quot;A&quot;), c(&quot;D&quot;, &quot;B&quot;), c(&quot;D&quot;, &quot;C&quot;)): no se pudo encontrar la función &quot;dag&quot; #&gt; Error in graphviz.plot(as.bn(G_1), main = &quot;G_1&quot;): no se pudo encontrar la función &quot;graphviz.plot&quot; #&gt; Error in dag(c(&quot;D&quot;, &quot;A&quot;), c(&quot;B&quot;, &quot;A&quot;), c(&quot;D&quot;, &quot;B&quot;), c(&quot;D&quot;, &quot;C&quot;)): no se pudo encontrar la función &quot;dag&quot; #&gt; Error in graphviz.plot(as.bn(G_2), main = &quot;G_2&quot;): no se pudo encontrar la función &quot;graphviz.plot&quot; Considera \\(\\mathcal G^*\\) la verdadera red y \\(\\mathcal G_1\\), \\(\\mathcal G_2\\) redes aprendidas. Definamos \\(p*\\) tal que \\(\\mathcal G^*\\) es un mapeo perfecto de \\(\\mathcal G*\\) (\\(I(\\mathcal G^*)=I(p^*)\\)) Entonces, \\(\\mathcal G_1\\) y \\(\\mathcal G_2\\) se pueden usar para aprender \\(\\mathcal p^*\\) de manera correcta. \\(\\mathcal G_1\\) se puede usar para aprender \\(p^*\\) de manera correcta pero \\(\\mathcal G_2\\) no. \\(\\mathcal G_2\\) se puede usar para aprender \\(p^*\\) de manera correcta pero \\(\\mathcal G_1\\) no. Ninguna se puede usar para aprender \\(p^*\\) de manera correcta. En la práctica se utilizan AIC y BIC. El AIC tiende a producir modelos más complejos con algún sobreajuste, mientras que el BIC tiende a producir modelos más simples y a veces con falta de ajuste. No hay acuerdo en qué medida es mejor en general, pero el balance se puede considerar como sigue: cuando es importante predecir o hacer inferencia, y no nos preocupa tanto obtener algunas aristas espurias, preferimos el AIC. Cuando buscamos la parte más robusta de la estructura de variación de las variables, aún cuando perdamos algunas dependencias débiles, puede ser mejor usar el BIC. "],
["procedimiento-de-busqueda.html", "2.5 Procedimiento de búsqueda", " 2.5 Procedimiento de búsqueda Nuestro siguiente paso es describir la heurística de búsqueda para minimizar el score, que en lo que sigue suponemos que es el AIC. Hay dos decisiones de diseño para decidir el algoritmo de aprendizaje de estructura: Técnicas de busqueda. * Hill-climbing * Recocido simulado * Algoritmos genéticos Operadores de búsqueda Locales * Agregar arista * Eliminar arista * Cambiar dirección de arista Globales (ej. cambiar un nodo de lugar, más costoso) Aunque hay varios algoritmos, uno utilizado comunmente es el de hill climbing. 2.5.1 Hill-climbing Iniciamos con una gráfica dada: Gráfica vacía Gráfica aleatoria Conocimiento experto En cada iteración: Consideramos el score para cada operador de búsqueda local (agregar, eliminar o cambiar la dirección de una arista) Aplicamos el cambio que resulta en un mayor incremento en el score. Si tenemos empates elijo una operación al azar. Parar cuando ningún cambio resulte en mejoras del score. Ejemplo. Eliminación de aristas Consideremos datos simulados de una red en forma de diamante: set.seed(28) n &lt;- 600 # número de observaciones a &lt;- (rbinom(n, 1, 0.3)) # nodo raíz b &lt;- (rbinom(n, 1, a * 0.1 + (1 - a) * 0.8)) c &lt;- (rbinom(n, 1, a * 0.2 + (1 - a) * 0.9)) d &lt;- (rbinom(n, 1, b * c * 0.9 + (1 - b * c) * 0.1)) dat &lt;- data.frame(a = factor(a), b = factor(b), c = factor(c), d = factor(d)) head(dat) #&gt; a b c d #&gt; 1 0 1 1 1 #&gt; 2 0 1 1 1 #&gt; 3 0 1 1 1 #&gt; 4 1 0 0 0 #&gt; 5 0 1 1 1 #&gt; 6 1 0 0 0 Y supongamos que comenzamos el proceso con una gráfica vacía: aic &lt;- function(fit, data){ -2 * AIC(fit, data = data) / nrow(data) } grafica_0 &lt;- empty.graph(c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;)) #&gt; Error in empty.graph(c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;)): no se pudo encontrar la función &quot;empty.graph&quot; fit_0 &lt;- bn.fit(grafica_0, dat) #&gt; Error in bn.fit(grafica_0, dat): no se pudo encontrar la función &quot;bn.fit&quot; logLik(fit_0, data = dat) #&gt; Error in logLik(fit_0, data = dat): objeto &#39;fit_0&#39; no encontrado AIC(fit_0, data = dat) # cuatro parámetros #&gt; Error in AIC(fit_0, data = dat): objeto &#39;fit_0&#39; no encontrado aic(fit_0, data = dat) #&gt; Error in AIC(fit, data = data): objeto &#39;fit_0&#39; no encontrado Consideramos agregar \\(a\\to d\\), la nueva arista que mejora el AIC, y escogemos este cambio. Notemos que esta arista no existe en el modelo que genera los datos, grafica_1 &lt;- grafica_0 #&gt; Error in eval(expr, envir, enclos): objeto &#39;grafica_0&#39; no encontrado arcs(grafica_1) &lt;- matrix(c(&#39;a&#39;, &#39;d&#39;), ncol = 2, byrow = T) #&gt; Error in arcs(grafica_1) &lt;- matrix(c(&quot;a&quot;, &quot;d&quot;), ncol = 2, byrow = T): objeto &#39;grafica_1&#39; no encontrado fit_1 &lt;- bn.fit(grafica_1, dat) #&gt; Error in bn.fit(grafica_1, dat): no se pudo encontrar la función &quot;bn.fit&quot; logLik(fit_1, data = dat) #&gt; Error in logLik(fit_1, data = dat): objeto &#39;fit_1&#39; no encontrado aic(fit_1, data = dat) #&gt; Error in AIC(fit, data = data): objeto &#39;fit_1&#39; no encontrado graphviz.plot(grafica_1) #&gt; Error in graphviz.plot(grafica_1): no se pudo encontrar la función &quot;graphviz.plot&quot; Ahora agregamos \\(a\\to b\\), que también mejora el AIC: grafica_2 &lt;- grafica_0 #&gt; Error in eval(expr, envir, enclos): objeto &#39;grafica_0&#39; no encontrado arcs(grafica_2) &lt;- matrix(c(&#39;a&#39;,&#39;d&#39;,&#39;a&#39;,&#39;b&#39;), ncol = 2, byrow = T) #&gt; Error in arcs(grafica_2) &lt;- matrix(c(&quot;a&quot;, &quot;d&quot;, &quot;a&quot;, &quot;b&quot;), ncol = 2, byrow = T): objeto &#39;grafica_2&#39; no encontrado fit_2 &lt;- bn.fit(grafica_2, dat) #&gt; Error in bn.fit(grafica_2, dat): no se pudo encontrar la función &quot;bn.fit&quot; logLik(fit_2, data = dat) #&gt; Error in logLik(fit_2, data = dat): objeto &#39;fit_2&#39; no encontrado aic(fit_2, data = dat) #&gt; Error in AIC(fit, data = data): objeto &#39;fit_2&#39; no encontrado graphviz.plot(grafica_2) #&gt; Error in graphviz.plot(grafica_2): no se pudo encontrar la función &quot;graphviz.plot&quot; Igualmente, agregar \\(a\\to c\\) merjoar el AIC: grafica_3 &lt;- grafica_0 #&gt; Error in eval(expr, envir, enclos): objeto &#39;grafica_0&#39; no encontrado arcs(grafica_3) &lt;- matrix(c(&#39;a&#39;,&#39;d&#39;,&#39;a&#39;,&#39;b&#39;,&#39;a&#39;,&#39;c&#39;), ncol = 2, byrow = T) #&gt; Error in arcs(grafica_3) &lt;- matrix(c(&quot;a&quot;, &quot;d&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;c&quot;), ncol = 2, : objeto &#39;grafica_3&#39; no encontrado fit_3 &lt;- bn.fit(grafica_3, dat) #&gt; Error in bn.fit(grafica_3, dat): no se pudo encontrar la función &quot;bn.fit&quot; logLik(fit_3, data = dat ) #&gt; Error in logLik(fit_3, data = dat): objeto &#39;fit_3&#39; no encontrado aic(fit_3, data = dat) #&gt; Error in AIC(fit, data = data): objeto &#39;fit_3&#39; no encontrado graphviz.plot(grafica_3) #&gt; Error in graphviz.plot(grafica_3): no se pudo encontrar la función &quot;graphviz.plot&quot; Agregamos \\(b\\to d\\) y \\(c\\to d\\): grafica_4 &lt;- grafica_0 #&gt; Error in eval(expr, envir, enclos): objeto &#39;grafica_0&#39; no encontrado arcs(grafica_4) &lt;- matrix(c(&#39;a&#39;,&#39;d&#39;,&#39;a&#39;,&#39;b&#39;,&#39;a&#39;,&#39;c&#39;,&#39;b&#39;,&#39;d&#39;), ncol = 2, byrow = T) #&gt; Error in arcs(grafica_4) &lt;- matrix(c(&quot;a&quot;, &quot;d&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;c&quot;, &quot;b&quot;, : objeto &#39;grafica_4&#39; no encontrado fit_4 &lt;- bn.fit(grafica_4, dat) #&gt; Error in bn.fit(grafica_4, dat): no se pudo encontrar la función &quot;bn.fit&quot; logLik(fit_4, data = dat ) #&gt; Error in logLik(fit_4, data = dat): objeto &#39;fit_4&#39; no encontrado aic(fit_4, data = dat) #&gt; Error in AIC(fit, data = data): objeto &#39;fit_4&#39; no encontrado grafica_4 &lt;- grafica_0 #&gt; Error in eval(expr, envir, enclos): objeto &#39;grafica_0&#39; no encontrado arcs(grafica_4) &lt;- matrix(c(&#39;a&#39;,&#39;d&#39;,&#39;a&#39;,&#39;b&#39;,&#39;a&#39;,&#39;c&#39;,&#39;b&#39;,&#39;d&#39;,&#39;c&#39;,&#39;d&#39;), ncol = 2, byrow = T) #&gt; Error in arcs(grafica_4) &lt;- matrix(c(&quot;a&quot;, &quot;d&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;c&quot;, &quot;b&quot;, : objeto &#39;grafica_4&#39; no encontrado fit_4 &lt;- bn.fit(grafica_4, dat) #&gt; Error in bn.fit(grafica_4, dat): no se pudo encontrar la función &quot;bn.fit&quot; logLik(fit_4, data = dat ) #&gt; Error in logLik(fit_4, data = dat): objeto &#39;fit_4&#39; no encontrado aic(fit_4, data = dat) #&gt; Error in AIC(fit, data = data): objeto &#39;fit_4&#39; no encontrado graphviz.plot(grafica_4) #&gt; Error in graphviz.plot(grafica_4): no se pudo encontrar la función &quot;graphviz.plot&quot; Ahora nótese que podemos eliminar \\(a\\to d\\), y mejoramos el AIC: grafica_5 &lt;- grafica_0 #&gt; Error in eval(expr, envir, enclos): objeto &#39;grafica_0&#39; no encontrado arcs(grafica_5) &lt;- matrix(c(&#39;a&#39;,&#39;b&#39;,&#39;a&#39;,&#39;c&#39;,&#39;b&#39;,&#39;d&#39;,&#39;c&#39;,&#39;d&#39;), ncol = 2, byrow = T) #&gt; Error in arcs(grafica_5) &lt;- matrix(c(&quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;c&quot;, &quot;b&quot;, &quot;d&quot;, &quot;c&quot;, : objeto &#39;grafica_5&#39; no encontrado fit_5 &lt;- bn.fit(grafica_5, dat) #&gt; Error in bn.fit(grafica_5, dat): no se pudo encontrar la función &quot;bn.fit&quot; logLik(fit_5, data = dat ) #&gt; Error in logLik(fit_5, data = dat): objeto &#39;fit_5&#39; no encontrado aic(fit_5, data = dat) #&gt; Error in AIC(fit, data = data): objeto &#39;fit_5&#39; no encontrado graphviz.plot(grafica_5) #&gt; Error in graphviz.plot(grafica_5): no se pudo encontrar la función &quot;graphviz.plot&quot; Este última gráfica es el modelo original. La eliminación de arcos nos permitió recuperar el modelo original a pesar de nuestra decisión inicial temporalmente incorrecta de agregar \\(a\\to d\\). El algoritmo de hill climbing como está implementado en bn.learn resulta en: graf_hc &lt;- hc(dat, score=&#39;aic&#39;) #&gt; Error in hc(dat, score = &quot;aic&quot;): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(graf_hc) #&gt; Error in graphviz.plot(graf_hc): no se pudo encontrar la función &quot;graphviz.plot&quot; Ejemplo: Cambios de dirección Consideramos un ejemplo simple con un colisionador: set.seed(28) n &lt;- 600 b &lt;- (rbinom(n, 1, 0.4)) c &lt;- (rbinom(n, 1, 0.7)) d &lt;- (rbinom(n, 1, b*c*0.9+ (1-b*c)*0.1 )) dat &lt;- data.frame(factor(b),factor(c),factor(d)) names(dat) &lt;- c(&#39;b&#39;,&#39;c&#39;,&#39;d&#39;) Supongamos que comenzamos agregando la arista \\(d\\to c\\) (sentido incorrecto). grafica_0 &lt;- empty.graph(c(&#39;b&#39;,&#39;c&#39;,&#39;d&#39;)) #&gt; Error in empty.graph(c(&quot;b&quot;, &quot;c&quot;, &quot;d&quot;)): no se pudo encontrar la función &quot;empty.graph&quot; arcs(grafica_0) &lt;- matrix(c(&#39;d&#39;,&#39;c&#39;), ncol=2, byrow=T) #&gt; Error in arcs(grafica_0) &lt;- matrix(c(&quot;d&quot;, &quot;c&quot;), ncol = 2, byrow = T): objeto &#39;grafica_0&#39; no encontrado graphviz.plot(grafica_0) #&gt; Error in graphviz.plot(grafica_0): no se pudo encontrar la función &quot;graphviz.plot&quot; En el primer paso, agregamos \\(b \\to d\\), que muestra una mejora grande: graf_x &lt;- hc(dat, start= grafica_0, score=&#39;aic&#39;, max.iter=1) #&gt; Error in hc(dat, start = grafica_0, score = &quot;aic&quot;, max.iter = 1): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(graf_x) #&gt; Error in graphviz.plot(graf_x): no se pudo encontrar la función &quot;graphviz.plot&quot; Pero en el siguiente paso nos damos cuenta que podemos mejorar considerablemente si construimos el modelo local de \\(d\\) a partir no sólo de \\(b\\) sino también de \\(c\\), y cambiamos dirección: graf_x &lt;- hc(dat, start= grafica_0, score=&#39;aic&#39;, max.iter=2) #&gt; Error in hc(dat, start = grafica_0, score = &quot;aic&quot;, max.iter = 2): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(graf_x) #&gt; Error in graphviz.plot(graf_x): no se pudo encontrar la función &quot;graphviz.plot&quot; Podemos examinar cada paso del algoritmo: hc(dat, start = grafica_0, score=&#39;aic&#39;, debug=T) #&gt; Error in hc(dat, start = grafica_0, score = &quot;aic&quot;, debug = T): no se pudo encontrar la función &quot;hc&quot; Ejemplo simulado. Comenzamos con una muestra relativamente chica, y utilizamos el BIC: set.seed(280572) n &lt;- 300 a &lt;- (rbinom(n, 1, 0.2)) b &lt;- (rbinom(n, 1, a*0.1+(1-a)*0.8)) c &lt;- (rbinom(n, 1, a*0.2+(1-a)*0.9)) d &lt;- (rbinom(n, 1, b*c*0.9+ (1-b*c)*0.1 )) e &lt;- rbinom(n, 1, 0.4) f &lt;- rbinom(n, 1, e*0.3+(1-e)*0.6) g &lt;- rbinom(n, 1, f*0.2+(1-f)*0.8) dat &lt;- data.frame(factor(a),factor(b),factor(c),factor(d), factor(e), factor(f), factor(g)) names(dat) &lt;- c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;,&#39;g&#39;) grafica.1 &lt;- hc(dat, score=&#39;bic&#39;) #&gt; Error in hc(dat, score = &quot;bic&quot;): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(grafica.1) #&gt; Error in graphviz.plot(grafica.1): no se pudo encontrar la función &quot;graphviz.plot&quot; set.seed(280572) n &lt;- 300 a &lt;- (rbinom(n, 1, 0.3)) b &lt;- (rbinom(n, 1, a*0.1+(1-a)*0.8)) c &lt;- (rbinom(n, 1, a*0.2+(1-a)*0.9)) d &lt;- (rbinom(n, 1, b*c*0.9+ (1-b*c)*0.1 )) e &lt;- rbinom(n, 1, 0.4) f &lt;- rbinom(n, 1, e*0.3+(1-e)*0.6) g &lt;- rbinom(n, 1, f*0.2+(1-f)*0.8) dat &lt;- data.frame(factor(a),factor(b),factor(c),factor(d), factor(e), factor(f), factor(g)) names(dat) &lt;- c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;,&#39;g&#39;) grafica.1 &lt;- hc(dat, score=&#39;aic&#39;) #&gt; Error in hc(dat, score = &quot;aic&quot;): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(grafica.1) #&gt; Error in graphviz.plot(grafica.1): no se pudo encontrar la función &quot;graphviz.plot&quot; En este ejemplo, con el AIC obtenemos algunas aristas espurias, que en todo caso muestran relaciones aparentes débiles en los datos de entrenamiento. Nótese que AIC captura las relaciones importantes, y erra en cautela en cuanto a qué independencias están presentes en los datos. 2.5.2 Incorporando información acerca de la estructura En algunos casos, tenemos información adicional de las posibles estructuras gráficas que son aceptables o deseables en los modelos que buscamos ajustar. Esta información es muy valiosa cuando tenemos pocos datos o muchas variables (incluso puede ser crucial para obtener un modelo de buena calidad), y puede incorporarse en prohibiciones acerca de qué estructuras puede explorar el algoritmo. Consideremos nuestro ejemplo anterior con considerablemente menos datos: set.seed(28) n &lt;- 100 a &lt;- (rbinom(n, 1, 0.2)) b &lt;- (rbinom(n, 1, a*0.1+(1-a)*0.8)) c &lt;- (rbinom(n, 1, a*0.2+(1-a)*0.9)) d &lt;- (rbinom(n, 1, b*c*0.9+ (1-b*c)*0.1 )) e &lt;- rbinom(n, 1, 0.4) f &lt;- rbinom(n, 1, e*0.3+(1-e)*0.6) g &lt;- rbinom(n, 1, f*0.2+(1-f)*0.8) dat &lt;- data.frame(factor(a),factor(b),factor(c),factor(d), factor(e), factor(f), factor(g)) names(dat) &lt;- c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;,&#39;g&#39;) grafica.1 &lt;- hc(dat, score=&#39;bic&#39;) #&gt; Error in hc(dat, score = &quot;bic&quot;): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(grafica.1) #&gt; Error in graphviz.plot(grafica.1): no se pudo encontrar la función &quot;graphviz.plot&quot; Nótese que en este ejemplo BIC falla en identificar una dependencia, y afirma que hay una independencia condicional entre a y d dado c. AIC sin embargo captura la dependencia con un modelo demasiado complejo (tres flechas espurias): grafica.1 &lt;- hc(dat, score=&#39;aic&#39;) #&gt; Error in hc(dat, score = &quot;aic&quot;): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(grafica.1) #&gt; Error in graphviz.plot(grafica.1): no se pudo encontrar la función &quot;graphviz.plot&quot; Sin embargo, si sabemos, por ejemplo, que no debe haber una flecha de c a f, y tiene que haber una de a a c, podemos mejorar nuestros modelos: b.list &lt;- data.frame(from=c(&#39;c&#39;,&#39;f&#39;), to=c(&#39;f&#39;,&#39;c&#39;)) w.list &lt;- data.frame(from=c(&#39;a&#39;), to=c(&#39;c&#39;)) grafica.bic &lt;- hc(dat, score=&#39;bic&#39;, blacklist=b.list, whitelist=w.list) #&gt; Error in hc(dat, score = &quot;bic&quot;, blacklist = b.list, whitelist = w.list): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(grafica.bic) #&gt; Error in graphviz.plot(grafica.bic): no se pudo encontrar la función &quot;graphviz.plot&quot; grafica.aic &lt;- hc(dat, score=&#39;aic&#39;, blacklist=b.list, whitelist=w.list) #&gt; Error in hc(dat, score = &quot;aic&quot;, blacklist = b.list, whitelist = w.list): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(grafica.aic) #&gt; Error in graphviz.plot(grafica.aic): no se pudo encontrar la función &quot;graphviz.plot&quot; En este ejemplo estamos seguros de las aristas que forzamos. Muchas veces este no es el caso, y debemos tener cuidado: Forzar la inclusión de una arista cuando esto no es necesario puede resultar en modelos demasiado complicados que incluyen estructuras espurias. Exclusión de muchas aristas puede provocar también modelos que ajustan mal y no explican los datos. set.seed(28) n &lt;- 600 b &lt;- (rbinom(n, 1, 0.4)) c &lt;- (rbinom(n, 1, 0.7)) d &lt;- (rbinom(n, 1, b*c*0.9+ (1-b*c)*0.1 )) dat.x &lt;- data.frame(factor(b),factor(c),factor(d)) names(dat.x) &lt;- c(&#39;b&#39;,&#39;c&#39;,&#39;d&#39;) Supongamos que comenzamos agregando la arista \\(d\\to b\\) (sentido incorrecto). graphviz.plot(hc(dat.x, score=&#39;bic&#39;, whitelist=data.frame(from=c(&#39;d&#39;), to=c(&#39;b&#39;)))) #&gt; Error in graphviz.plot(hc(dat.x, score = &quot;bic&quot;, whitelist = data.frame(from = c(&quot;d&quot;), : no se pudo encontrar la función &quot;graphviz.plot&quot; Y no aprendimos nada, pues cualquier conjunta se factoriza de esta manera. 2.5.3 Sentido de las aristas Los métodos de score a lo más que pueden aspirar es a capturar la clase de equivalencia Markoviana de la conjunta que nos interesa (es decir, gráficas que tienen las mismas independencias, y que cubren a exactamente las mismas conjuntas que se factorizan sobre ellas). Esto implica que hay cierta arbitrariedad en la selección de algunas flechas. En la siguiente gráfica, por ejemplo, ¿qué pasa si cambiamos el sentido de la flecha entre e y f? set.seed(28) n &lt;- 500 a &lt;- (rbinom(n, 1, 0.2)) b &lt;- (rbinom(n, 1, a*0.1+(1-a)*0.8)) c &lt;- (rbinom(n, 1, a*0.2+(1-a)*0.9)) d &lt;- (rbinom(n, 1, b*c*0.9+ (1-b*c)*0.1 )) e &lt;- rbinom(n, 1, 0.4) f &lt;- rbinom(n, 1, e*0.3+(1-e)*0.6) g &lt;- rbinom(n, 1, f*0.2+(1-f)*0.8) dat &lt;- data.frame(factor(a),factor(b),factor(c),factor(d), factor(e), factor(f), factor(g)) names(dat) &lt;- c(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;,&#39;e&#39;,&#39;f&#39;,&#39;g&#39;) grafica.bic &lt;- hc(dat, score=&#39;bic&#39;) #&gt; Error in hc(dat, score = &quot;bic&quot;): no se pudo encontrar la función &quot;hc&quot; graphviz.plot(grafica.bic) #&gt; Error in graphviz.plot(grafica.bic): no se pudo encontrar la función &quot;graphviz.plot&quot; arcos &lt;- grafica.bic$arcs #&gt; Error in eval(expr, envir, enclos): objeto &#39;grafica.bic&#39; no encontrado arcos #&gt; Error in eval(expr, envir, enclos): objeto &#39;arcos&#39; no encontrado arcos[3,] &lt;- c(&#39;g&#39;,&#39;f&#39;) #&gt; Error in arcos[3, ] &lt;- c(&quot;g&quot;, &quot;f&quot;): objeto &#39;arcos&#39; no encontrado arcos[6,] &lt;- c(&#39;f&#39;,&#39;e&#39;) #&gt; Error in arcos[6, ] &lt;- c(&quot;f&quot;, &quot;e&quot;): objeto &#39;arcos&#39; no encontrado grafica.2 &lt;- grafica.bic #&gt; Error in eval(expr, envir, enclos): objeto &#39;grafica.bic&#39; no encontrado arcs(grafica.2) &lt;- arcos #&gt; Error in eval(expr, envir, enclos): objeto &#39;arcos&#39; no encontrado graphviz.plot(grafica.2) #&gt; Error in graphviz.plot(grafica.2): no se pudo encontrar la función &quot;graphviz.plot&quot; graphviz.plot(grafica.bic) #&gt; Error in graphviz.plot(grafica.bic): no se pudo encontrar la función &quot;graphviz.plot&quot; Vemos que no cambia la log-verosimilitud, ni ninguno de nuestros scores. logLik(grafica.bic, data=dat) #&gt; Error in logLik(grafica.bic, data = dat): objeto &#39;grafica.bic&#39; no encontrado logLik(grafica.2, data=dat) #&gt; Error in logLik(grafica.2, data = dat): objeto &#39;grafica.2&#39; no encontrado BIC(grafica.bic, data=dat) #&gt; Error in BIC(grafica.bic, data = dat): objeto &#39;grafica.bic&#39; no encontrado BIC(grafica.2, data=dat) #&gt; Error in BIC(grafica.2, data = dat): objeto &#39;grafica.2&#39; no encontrado AIC(grafica.bic, data=dat) #&gt; Error in AIC(grafica.bic, data = dat): objeto &#39;grafica.bic&#39; no encontrado AIC(grafica.2, data=dat) #&gt; Error in AIC(grafica.2, data = dat): objeto &#39;grafica.2&#39; no encontrado Esto implica que la dirección de estas flechas no puede determinarse solamente usando los datos. Podemos seleccionar la dirección de estas flechas por otras consideraciones, como explicaciones causales, temporales, o de interpretación. Los modelos son equivalentes, pero tienen una parametrización destinta. Mostrar que cambiar el sentido de una flecha que colisiona en \\(d\\) (que es un colisionador no protegido) no da scores equivalentes. 2.5.4 Variaciones de Hill-climbing ¿Cuál(es) de las siguientes opciones puede ser un problema para aprender la estructura de la red? a. Máximos locales. b. Pasos discretos en los scores cuando se perturba la estructura. c. Eliminar un arco no se puede expresar como una operación atómica en la estructura. d. Perturbaciones chicas en la estructura de la gráfica producen cambios muy chicos o nulos en el score (plateaux). ¿Por que consideramos el operador de cambiar dirección como candidato en cada iteración si es el resultado de elminar un arco y añadir un arco? Eliminar un arco en hill-climbing tiende a disminuir el score de tal manera que el paso inicial de eliminar el arco no se tomará. Revertir la dirección es una manera de evitar máximos locales. Algunas modificaciones de hill-climbing consisten en incluir estrategias: Inicios aleatorios: Si estamos en un plateaux, tomamos un número de pasos aleatorios y comenzamos a escalar nuevamente. Tabu: Guardar una lista de los k pasos más recientes y la búsqueda no puede revertir estos pasos. "],
["algunos-ejemplos-reales.html", "2.6 Algunos ejemplos reales", " 2.6 Algunos ejemplos reales Predicción cuando no hay conocimiento experto Descubrir conocimiento "],
["referencias.html", "Referencias", " Referencias "]
]
